{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm  # Import tqdm for Jupyter Notebook\n",
    "from src.optimizee import *\n",
    "from src.torch_utils import *\n",
    "import shutil\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from optimizer_concurrent import *\n",
    "# from train_concurrent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMConcurrent(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM-based optimizer as described in the paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_optims, hidden_size=20, preproc=True, preproc_factor=10):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.preproc = preproc\n",
    "        self.preproc_factor = torch.tensor(preproc_factor)\n",
    "        self.preproc_threshold = float(torch.exp(-self.preproc_factor))\n",
    "        \n",
    "        self.input_size = 2*num_optims if preproc else 1*num_optims\n",
    "        self.lstm = nn.LSTM(self.input_size, hidden_size, 2, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        \"\"\"\n",
    "        Forward pass of the LSTM optimizer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, sequence_length, input_size).\n",
    "            hidden_state (tuple): Hidden state of the LSTM (h, c).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output updates of shape (batch_size, sequence_length, 1).\n",
    "            tuple: Updated hidden state.\n",
    "        \"\"\"\n",
    "        if self.preproc: x = self.preprocess_gradients(x)\n",
    "        # print(\"Gradients\", x)\n",
    "        # print(\"Preprocess Shape\", x.shape)\n",
    "        out, hidden_state = self.lstm(x, hidden_state)\n",
    "        out = self.output_layer(out)\n",
    "\n",
    "        return out, hidden_state\n",
    "\n",
    "\n",
    "\n",
    "    def preprocess_gradients(self, gradients):\n",
    "        \"\"\" Applies log transformation & sign extraction to gradients, moving to CUDA if available. \"\"\"\n",
    "\n",
    "        gradients = gradients.data  # Extract raw gradient data\n",
    "        # print(\"Gradients Shape\", gradients.shape)\n",
    "        if len(gradients.size()) == 1: gradients = gradients.unsqueeze(-1)\n",
    "        \n",
    "        param_size = gradients.size(0)\n",
    "        num_optims = gradients.size(1)\n",
    "\n",
    "        preprocessed = torch.zeros(param_size, 2*num_optims)\n",
    "\n",
    "        for i in range(num_optims):\n",
    "            gradient = gradients[:,i]\n",
    "            keep_grads = (torch.abs(gradient) >= self.preproc_threshold)\n",
    "        \n",
    "            # Log transformation for large gradients\n",
    "        \n",
    "            preprocessed[keep_grads, 2*i] = (torch.log(torch.abs(gradient[keep_grads]) + 1e-8) / self.preproc_factor)\n",
    "            preprocessed[keep_grads, 2*i+1] = torch.sign(gradient[keep_grads])\n",
    "\n",
    "            # Direct scaling for small gradients\n",
    "            preprocessed[~keep_grads, 2*i] = -1\n",
    "            preprocessed[~keep_grads, 2*i+1] = (float(torch.exp(self.preproc_factor)) * gradient[~keep_grads])\n",
    "\n",
    "        # print(preprocessed.shape)\n",
    "        return torch.tensor(preprocessed).to(gradients.device)\n",
    "    \n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        # Initialize hidden & cell states for LSTM (one per parameter)\n",
    "        self.h0 = to_cuda(torch.zeros(2, self.hidden_size))\n",
    "        # self.h0 = torch.randn(2, self.hidden_size)\n",
    "        self.c0 = to_cuda(torch.zeros(2, self.hidden_size))\n",
    "        # self.c0 = torch.randn(2, self.hidden_size)\n",
    "        return (self.h0, self.c0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_optimizees(optimizee_cls, optimizee_kwargs, num_optimizees=10, noise='equal'):\n",
    "    optimizees = []\n",
    "    for i in range(num_optimizees):\n",
    "        if noise == 'equal':\n",
    "            optim = optimizee_cls(**optimizee_kwargs)\n",
    "            optim.train()\n",
    "            optimizees.append(optim)\n",
    "        else:\n",
    "            optimizee_kwargs['noise_std'] = 0.01 * (i+1)\n",
    "            optim = optimizee_cls(**optimizee_kwargs)\n",
    "            optim.train()\n",
    "            optimizees.append(optim)\n",
    "    return optimizees\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_LSTM(lstm_optimizer, meta_optimizer, optimizee_class, optimizee_kwargs, num_optimizees=1, num_epochs=500, time_horizon=200, discount=1, scheduler = None, noise='equal', writer=None):\n",
    "    lstm_optimizer.train()\n",
    "    if scheduler is None:\n",
    "        scheduler = torch.optim.lr_scheduler.ConstantLR(meta_optimizer, factor=1.0, total_iters=num_epochs)\n",
    "\n",
    "    \n",
    "    with tqdm(range(num_epochs), desc=\"Training Progress\") as pbar:\n",
    "        for epoch in pbar:\n",
    "            # Initialize optimizee parameters\n",
    "            optimizees = initialize_optimizees(optimizee_class, optimizee_kwargs, num_optimizees, noise=noise)\n",
    "            optimizees[0].set_params()\n",
    "            params = optimizees[0].all_parameters()\n",
    "            print(\"Param Shape\", params.shape)\n",
    "\n",
    "            # hidden_state = lstm_optimizer.initialize_hidden_state()\n",
    "\n",
    "            cumulative_loss = None             \n",
    "            for t in range(time_horizon):\n",
    "                gradients = []\n",
    "                hidden_state = lstm_optimizer.initialize_hidden_state()\n",
    "                for i in range(num_optimizees):\n",
    "                    optimizee = optimizees[i]\n",
    "                    loss, grad_params = optimizee.compute_loss(params, return_grad=True)\n",
    "                    if i == 0 and discount: cumulative_loss = loss*discount**(time_horizon-1) if cumulative_loss is None else cumulative_loss + loss*discount**(time_horizon-t-1)\n",
    "                    elif i==0: cumulative_loss = loss\n",
    "                    gradients.append(grad_params.squeeze())\n",
    "                    if writer and i==0 and epoch==1: writer.add_scalar(\"Grad\", grad_params.squeeze().mean(), t)\n",
    "\n",
    "                # Stack gradients\n",
    "                grad_params = torch.stack(gradients).T\n",
    "                # print(\"Grads\", grad_params.shape)\n",
    "                update, hidden_state = lstm_optimizer(grad_params, hidden_state)\n",
    "                # print(\"Update\", update.shape)\n",
    "                # print(\"Params\", params.shape)\n",
    "                # with torch.no_grad():\n",
    "                params = params + update\n",
    "                if writer and epoch==1: writer.add_scalar(\"Update\", update.mean(), t)\n",
    "                # print(\"Update\", update)\n",
    "                optimizees[0].set_params(params)\n",
    "\n",
    "            \n",
    "            print(\"Cumulative Loss\", cumulative_loss)\n",
    "            # Backpropagation through time (BPTT)\n",
    "            if writer: writer.add_scalar(\"Loss\", cumulative_loss, epoch)\n",
    "            meta_optimizer.zero_grad()\n",
    "            cumulative_loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(lstm_optimizer.parameters(), 1)\n",
    "            # Print gradients\n",
    "            print(\"Gradients\", lstm_optimizer.lstm.weight_ih_l0.grad)\n",
    "            print(\"Gradients\", lstm_optimizer.lstm.weight_hh_l0.grad)\n",
    "            print(\"Gradients\", lstm_optimizer.output_layer.weight.grad)\n",
    "            meta_optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix(loss=cumulative_loss.item())\n",
    "            if (epoch + 1) % 1 == 0:\n",
    "                current_lr = meta_optimizer.param_groups[0]['lr']\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Cumulative Loss: {cumulative_loss.item():.4f}, LR: {current_lr:.3e}\")\n",
    "                print(f\"Final parameters: {params.detach().numpy().T}\")\n",
    "                \n",
    "    print(\"\\nTraining complete!\")\n",
    "    return lstm_optimizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_LSTM(lstm_optimizer, optimizee_class, optimizee_kwargs, num_optimizees=1, time_horizon=200, noise='equal', writer=None):\n",
    "    lstm_optimizer.eval()\n",
    "    optimizees = initialize_optimizees(optimizee_class, optimizee_kwargs, num_optimizees, noise=noise)    \n",
    "    optimizees[0].set_params()\n",
    "    params = optimizees[0].all_parameters()\n",
    "    hidden_state = lstm_optimizer.initialize_hidden_state()\n",
    "    for t in range(time_horizon):\n",
    "        gradients = []\n",
    "        for i in range(num_optimizees):\n",
    "            optimizee = optimizees[i]\n",
    "            loss, grad_params = optimizee.compute_loss(params)\n",
    "            if writer and i==0: writer.add_scalar(\"Loss\", loss, t)\n",
    "            gradients.append(grad_params.squeeze())\n",
    "        \n",
    "        grad_params = torch.stack(gradients).T\n",
    "        # if len(grad_params.shape)==1: grad_params = grad_params.unsqueeze(-1)\n",
    "\n",
    "        # print(grad_params.shape)\n",
    "        updates, hidden_state = lstm_optimizer(grad_params, hidden_state)\n",
    "        params = params - updates \n",
    "        optimizees[0].set_params(params)\n",
    "\n",
    "    # print(f\"Final parameters: {params.detach().numpy().T}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Optimizee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticOptimizee(Optimizee):\n",
    "    \"\"\"\n",
    "    Class for the quadratic function described in the paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, W, theta0, noise_std=0.01):\n",
    "        \"\"\"\n",
    "        Initialize the quadratic function.\n",
    "\n",
    "        Args:\n",
    "            W (np.ndarray): 10x10 matrix.\n",
    "            theta0 (np.ndarray): 10x1 vector (true parameters).\n",
    "            noise_std (float): Standard deviation of the noise term.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.W = torch.tensor(W, dtype=torch.float32)\n",
    "        self.theta0 = torch.tensor(theta0, dtype=torch.float32)\n",
    "        self.noise_std = noise_std\n",
    "        self.theta = None\n",
    "\n",
    "        # Generate noisy observations y = W @ theta0 + eps\n",
    "        self.y = self.W @ self.theta0 + self.noise_std * torch.randn_like(self.theta0)\n",
    "\n",
    "    def set_params(self, params=None):\n",
    "        \"\"\"\n",
    "        Returns initial parameters for optimization (random initialization).\n",
    "        \"\"\"\n",
    "        self.theta = torch.randn_like(self.theta0, requires_grad=True) if params is None else params\n",
    "\n",
    "    def compute_loss(self, params, return_grad=True):\n",
    "        \"\"\"\n",
    "        Computes the loss ||W @ params - y||^2.\n",
    "        \"\"\"\n",
    "        if return_grad:\n",
    "            loss = torch.norm((self.W.matmul(params) - self.y) ** 2)\n",
    "            grads = torch.autograd.grad(loss, params, create_graph=True)[0]\n",
    "            detached_grads = torch.tensor(grads.detach().numpy(), requires_grad=True)\n",
    "            return loss, detached_grads\n",
    "        else:\n",
    "            return torch.norm((self.W.matmul(params) - self.y) ** 2)\n",
    "    \n",
    "    def all_parameters(self):\n",
    "        \"\"\"\n",
    "        Returns all parameters of the optimizee, as a tensor of shape (d,1).\n",
    "        \"\"\"\n",
    "        return self.theta\n",
    "    \n",
    "    # Implement train and eval:\n",
    "    def train(self):\n",
    "        pass\n",
    "    \n",
    "    def eval(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983acb9b75bf40f894ff11efed33472b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Shape torch.Size([10, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_14784\\690785197.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(preprocessed).to(gradients.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Loss tensor(1262458.7500, grad_fn=<AddBackward0>)\n",
      "Gradients tensor([[ 2.3469e+04,  4.1002e+04],\n",
      "        [-1.1192e+04, -2.1484e+04],\n",
      "        [ 2.1924e+04,  3.3216e+04],\n",
      "        [ 7.9870e+03,  1.2955e+04],\n",
      "        [-3.5454e+03, -6.4426e+03],\n",
      "        [-7.2477e+03, -1.8500e+04],\n",
      "        [-2.3202e+04, -4.1242e+04],\n",
      "        [ 3.6760e+04,  5.7413e+04],\n",
      "        [-1.4673e+04, -1.6919e+04],\n",
      "        [-1.3279e+04, -2.5857e+04],\n",
      "        [ 1.8897e+04,  4.1900e+04],\n",
      "        [-3.0597e+04, -4.0078e+04],\n",
      "        [ 9.9187e+03,  1.3222e+04],\n",
      "        [ 3.9425e+03,  9.3196e+03],\n",
      "        [ 1.2765e+04,  1.6516e+04],\n",
      "        [-1.7572e+03, -5.6349e+03],\n",
      "        [ 3.9869e+03,  8.3535e+03],\n",
      "        [ 1.1893e+04,  3.5488e+04],\n",
      "        [ 3.6488e+03,  5.5316e+03],\n",
      "        [ 8.4787e+02,  1.2364e+03],\n",
      "        [ 1.3055e+04,  1.8349e+04],\n",
      "        [-5.8825e+03, -7.4623e+03],\n",
      "        [ 1.2662e+04,  1.6251e+04],\n",
      "        [ 5.9425e+03,  8.1076e+03],\n",
      "        [-2.0189e+03, -2.9820e+03],\n",
      "        [-3.1815e+03, -4.3911e+03],\n",
      "        [-1.2412e+04, -1.5913e+04],\n",
      "        [ 2.1686e+04,  2.6303e+04],\n",
      "        [-1.4135e+04, -2.0433e+04],\n",
      "        [-6.4458e+03, -8.8154e+03],\n",
      "        [ 1.3261e+04,  1.7040e+04],\n",
      "        [-1.7537e+04, -2.2277e+04],\n",
      "        [ 6.2950e+03,  7.7301e+03],\n",
      "        [ 2.1129e+03,  2.8845e+03],\n",
      "        [ 8.7380e+03,  1.1417e+04],\n",
      "        [-1.3772e+03, -1.8444e+03],\n",
      "        [ 2.3972e+03,  3.1126e+03],\n",
      "        [ 4.7911e+03,  6.7426e+03],\n",
      "        [ 3.0806e+03,  4.5111e+03],\n",
      "        [-2.9579e+01,  6.9290e+01],\n",
      "        [ 1.3776e+05,  2.0464e+05],\n",
      "        [ 6.9657e+04,  8.7755e+04],\n",
      "        [-1.6904e+05, -2.3536e+05],\n",
      "        [-5.3828e+04, -7.8935e+04],\n",
      "        [ 4.0509e+04,  6.2296e+04],\n",
      "        [-2.0094e+05, -2.8627e+05],\n",
      "        [-3.1437e+05, -4.3830e+05],\n",
      "        [-1.3834e+05, -1.8294e+05],\n",
      "        [ 4.6311e+05,  6.8414e+05],\n",
      "        [ 1.4357e+05,  2.0269e+05],\n",
      "        [ 3.6460e+05,  5.4261e+05],\n",
      "        [-2.5905e+05, -3.8920e+05],\n",
      "        [ 1.1981e+05,  1.6566e+05],\n",
      "        [-8.4163e+04, -1.1992e+05],\n",
      "        [-2.6875e+05, -3.7630e+05],\n",
      "        [-7.8107e+04, -1.0452e+05],\n",
      "        [ 4.3934e+04,  6.1134e+04],\n",
      "        [-3.0549e+05, -4.1349e+05],\n",
      "        [ 4.1775e+04,  6.4517e+04],\n",
      "        [ 4.5154e+04,  8.4539e+04],\n",
      "        [ 2.2702e+04,  3.8576e+04],\n",
      "        [-8.5469e+03, -1.3823e+04],\n",
      "        [ 2.3071e+04,  3.3529e+04],\n",
      "        [ 1.0141e+04,  1.8229e+04],\n",
      "        [-4.4676e+03, -7.8437e+03],\n",
      "        [-6.0856e+03, -1.3264e+04],\n",
      "        [-2.0464e+04, -3.4066e+04],\n",
      "        [ 3.9370e+04,  5.7335e+04],\n",
      "        [-2.3304e+04, -3.4064e+04],\n",
      "        [-8.2622e+03, -1.4426e+04],\n",
      "        [ 2.0210e+04,  3.5756e+04],\n",
      "        [-3.5413e+04, -5.0142e+04],\n",
      "        [ 1.1051e+04,  1.4914e+04],\n",
      "        [ 3.7569e+03,  7.6532e+03],\n",
      "        [ 1.2981e+04,  1.8762e+04],\n",
      "        [-2.7536e+03, -6.4361e+03],\n",
      "        [ 3.2272e+03,  5.7183e+03],\n",
      "        [ 8.1242e+03,  1.8276e+04],\n",
      "        [ 4.1786e+03,  7.6417e+03],\n",
      "        [ 9.0519e+02,  8.0845e+02]])\n",
      "Gradients tensor([[ 3.5373e+03, -2.8193e+03, -2.3805e+03,  ..., -5.2487e+02,\n",
      "          2.6904e+03,  1.0970e+02],\n",
      "        [-1.4890e+03,  1.2524e+03,  9.8772e+02,  ...,  3.4269e+02,\n",
      "         -1.0155e+03, -6.4418e+01],\n",
      "        [ 3.0279e+03, -2.4032e+03, -2.0691e+03,  ..., -4.2757e+02,\n",
      "          2.3069e+03,  8.8366e+01],\n",
      "        ...,\n",
      "        [ 1.5151e+03, -1.3385e+03, -8.4742e+02,  ..., -5.7745e+02,\n",
      "          8.8173e+02,  1.3795e+02],\n",
      "        [ 8.6155e+02, -6.3303e+02, -5.9582e+02,  ..., -2.3457e+01,\n",
      "          7.6124e+02,  3.9682e+00],\n",
      "        [ 2.2266e+02, -1.5183e+02, -1.4681e+02,  ...,  8.6565e+00,\n",
      "          2.1187e+02,  2.9877e+00]])\n",
      "Gradients tensor([[  726301.2500, -1491168.3750,  1873205.2500,  2105634.0000,\n",
      "          -779780.0625, -3740080.7500, -2665797.7500,   265817.7188,\n",
      "         -1779765.8750, -3146751.5000, -3010800.5000, -1346651.5000,\n",
      "           684830.3125,  3148979.5000,   161070.6875, -3219704.2500,\n",
      "          -850732.1250,  -585983.0000, -3031109.5000,  1739102.8750]])\n",
      "Epoch [1/50], Cumulative Loss: 1262458.7500, LR: 1.000e-02\n",
      "Final parameters: [[53.494446 48.072525 43.492584 40.030308 37.33338  34.6196   35.140385\n",
      "  30.920193 31.772436 31.465525]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Cumulative Loss tensor(142604.0625, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m meta_optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(lstm_optimizer\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m     11\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m lstm_optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_LSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQuadraticOptimizee\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtheta0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta0\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m params \u001b[38;5;241m=\u001b[39m test_LSTM(lstm_optimizer, QuadraticOptimizee, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m: W, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheta0\u001b[39m\u001b[38;5;124m\"\u001b[39m: theta0}, time_horizon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "Cell \u001b[1;32mIn[60], line 63\u001b[0m, in \u001b[0;36mtrain_LSTM\u001b[1;34m(lstm_optimizer, meta_optimizer, optimizee_class, optimizee_kwargs, num_optimizees, num_epochs, time_horizon, discount, scheduler, noise, writer)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m writer: writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m, cumulative_loss, epoch)\n\u001b[0;32m     62\u001b[0m meta_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 63\u001b[0m \u001b[43mcumulative_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# torch.nn.utils.clip_grad_norm_(lstm_optimizer.parameters(), 1)\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Print gradients\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradients\u001b[39m\u001b[38;5;124m\"\u001b[39m, lstm_optimizer\u001b[38;5;241m.\u001b[39mlstm\u001b[38;5;241m.\u001b[39mweight_ih_l0\u001b[38;5;241m.\u001b[39mgrad)\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\envs\\MLAI\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\envs\\MLAI\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "n = 10\n",
    "W = np.random.randn(n, n)\n",
    "theta0 = np.ones((n, 1))\n",
    "# print(\"W\", W)\n",
    "\n",
    "lstm_optimizer = LSTMConcurrent(num_optims=1)\n",
    "meta_optimizer = optim.Adam(lstm_optimizer.parameters(), lr=0.01)\n",
    "writer = SummaryWriter(\"test\")\n",
    "lstm_optimizer = train_LSTM(lstm_optimizer, meta_optimizer, QuadraticOptimizee, {\"W\": W, \"theta0\": theta0}, num_epochs=50, time_horizon=500, discount=0.9, writer=writer)\n",
    "params = test_LSTM(lstm_optimizer, QuadraticOptimizee, {\"W\": W, \"theta0\": theta0}, time_horizon=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b0d9ed34894a288b44e1c221301b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Shape torch.Size([10, 1])\n",
      "Update tensor([[0.2111],\n",
      "        [0.2268],\n",
      "        [0.1715],\n",
      "        [0.1267],\n",
      "        [0.0972],\n",
      "        [0.0857],\n",
      "        [0.0737],\n",
      "        [0.0714],\n",
      "        [0.0653],\n",
      "        [0.0597]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0562],\n",
      "        [0.0547],\n",
      "        [0.0540],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0595],\n",
      "        [0.0585],\n",
      "        [0.0623],\n",
      "        [0.0598],\n",
      "        [0.0565]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0544],\n",
      "        [0.0537],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0594],\n",
      "        [0.0584],\n",
      "        [0.0622],\n",
      "        [0.0597],\n",
      "        [0.0565]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0544],\n",
      "        [0.0538],\n",
      "        [0.0535],\n",
      "        [0.0533],\n",
      "        [0.0534],\n",
      "        [0.0594],\n",
      "        [0.0584],\n",
      "        [0.0622],\n",
      "        [0.0597],\n",
      "        [0.0565]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0545],\n",
      "        [0.0538],\n",
      "        [0.0536],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0594],\n",
      "        [0.0585],\n",
      "        [0.0621],\n",
      "        [0.0597],\n",
      "        [0.0565]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0545],\n",
      "        [0.0539],\n",
      "        [0.0536],\n",
      "        [0.0534],\n",
      "        [0.0535],\n",
      "        [0.0594],\n",
      "        [0.0585],\n",
      "        [0.0621],\n",
      "        [0.0597],\n",
      "        [0.0565]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0545],\n",
      "        [0.0540],\n",
      "        [0.0537],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0594],\n",
      "        [0.0586],\n",
      "        [0.0621],\n",
      "        [0.0596],\n",
      "        [0.0565]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0545],\n",
      "        [0.0542],\n",
      "        [0.0539],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0594],\n",
      "        [0.0587],\n",
      "        [0.0622],\n",
      "        [0.0596],\n",
      "        [0.0564]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0546],\n",
      "        [0.0547],\n",
      "        [0.0542],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0594],\n",
      "        [0.0590],\n",
      "        [0.0623],\n",
      "        [0.0597],\n",
      "        [0.0564]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0546],\n",
      "        [0.0594],\n",
      "        [0.0578],\n",
      "        [0.0552],\n",
      "        [0.0537],\n",
      "        [0.0588],\n",
      "        [0.0632],\n",
      "        [0.0654],\n",
      "        [0.0608],\n",
      "        [0.0562]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0540],\n",
      "        [0.0583],\n",
      "        [0.0569],\n",
      "        [0.0544],\n",
      "        [0.0531],\n",
      "        [0.0583],\n",
      "        [0.0627],\n",
      "        [0.0651],\n",
      "        [0.0610],\n",
      "        [0.0563]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0593],\n",
      "        [0.0622],\n",
      "        [0.0588],\n",
      "        [0.0547],\n",
      "        [0.0527],\n",
      "        [0.0574],\n",
      "        [0.0617],\n",
      "        [0.0642],\n",
      "        [0.0652],\n",
      "        [0.0596]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0604],\n",
      "        [0.0621],\n",
      "        [0.0633],\n",
      "        [0.0582],\n",
      "        [0.0540],\n",
      "        [0.0572],\n",
      "        [0.0608],\n",
      "        [0.0630],\n",
      "        [0.0640],\n",
      "        [0.0587]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0596],\n",
      "        [0.0615],\n",
      "        [0.0628],\n",
      "        [0.0579],\n",
      "        [0.0542],\n",
      "        [0.0574],\n",
      "        [0.0608],\n",
      "        [0.0581],\n",
      "        [0.0600],\n",
      "        [0.0568]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0592],\n",
      "        [0.0620],\n",
      "        [0.0636],\n",
      "        [0.0588],\n",
      "        [0.0602],\n",
      "        [0.0622],\n",
      "        [0.0633],\n",
      "        [0.0586],\n",
      "        [0.0596],\n",
      "        [0.0563]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0586],\n",
      "        [0.0614],\n",
      "        [0.0631],\n",
      "        [0.0584],\n",
      "        [0.0598],\n",
      "        [0.0619],\n",
      "        [0.0632],\n",
      "        [0.0585],\n",
      "        [0.0596],\n",
      "        [0.0563]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0587],\n",
      "        [0.0615],\n",
      "        [0.0633],\n",
      "        [0.0585],\n",
      "        [0.0599],\n",
      "        [0.0620],\n",
      "        [0.0633],\n",
      "        [0.0585],\n",
      "        [0.0596],\n",
      "        [0.0564]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0588],\n",
      "        [0.0616],\n",
      "        [0.0633],\n",
      "        [0.0586],\n",
      "        [0.0600],\n",
      "        [0.0621],\n",
      "        [0.0634],\n",
      "        [0.0585],\n",
      "        [0.0597],\n",
      "        [0.0565]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0589],\n",
      "        [0.0616],\n",
      "        [0.0634],\n",
      "        [0.0587],\n",
      "        [0.0600],\n",
      "        [0.0621],\n",
      "        [0.0634],\n",
      "        [0.0586],\n",
      "        [0.0597],\n",
      "        [0.0565]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0589],\n",
      "        [0.0617],\n",
      "        [0.0634],\n",
      "        [0.0587],\n",
      "        [0.0600],\n",
      "        [0.0621],\n",
      "        [0.0635],\n",
      "        [0.0586],\n",
      "        [0.0597],\n",
      "        [0.0566]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0589],\n",
      "        [0.0617],\n",
      "        [0.0635],\n",
      "        [0.0588],\n",
      "        [0.0601],\n",
      "        [0.0622],\n",
      "        [0.0635],\n",
      "        [0.0586],\n",
      "        [0.0597],\n",
      "        [0.0566]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0590],\n",
      "        [0.0617],\n",
      "        [0.0635],\n",
      "        [0.0588],\n",
      "        [0.0601],\n",
      "        [0.0622],\n",
      "        [0.0635],\n",
      "        [0.0586],\n",
      "        [0.0598],\n",
      "        [0.0566]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0590],\n",
      "        [0.0618],\n",
      "        [0.0635],\n",
      "        [0.0588],\n",
      "        [0.0601],\n",
      "        [0.0622],\n",
      "        [0.0635],\n",
      "        [0.0586],\n",
      "        [0.0598],\n",
      "        [0.0567]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0590],\n",
      "        [0.0618],\n",
      "        [0.0635],\n",
      "        [0.0589],\n",
      "        [0.0601],\n",
      "        [0.0622],\n",
      "        [0.0636],\n",
      "        [0.0587],\n",
      "        [0.0598],\n",
      "        [0.0567]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0591],\n",
      "        [0.0618],\n",
      "        [0.0636],\n",
      "        [0.0589],\n",
      "        [0.0602],\n",
      "        [0.0623],\n",
      "        [0.0636],\n",
      "        [0.0587],\n",
      "        [0.0598],\n",
      "        [0.0567]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0591],\n",
      "        [0.0618],\n",
      "        [0.0636],\n",
      "        [0.0589],\n",
      "        [0.0602],\n",
      "        [0.0623],\n",
      "        [0.0636],\n",
      "        [0.0587],\n",
      "        [0.0598],\n",
      "        [0.0568]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0591],\n",
      "        [0.0619],\n",
      "        [0.0636],\n",
      "        [0.0590],\n",
      "        [0.0602],\n",
      "        [0.0623],\n",
      "        [0.0636],\n",
      "        [0.0587],\n",
      "        [0.0599],\n",
      "        [0.0568]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0591],\n",
      "        [0.0619],\n",
      "        [0.0636],\n",
      "        [0.0590],\n",
      "        [0.0603],\n",
      "        [0.0623],\n",
      "        [0.0637],\n",
      "        [0.0587],\n",
      "        [0.0599],\n",
      "        [0.0568]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0592],\n",
      "        [0.0619],\n",
      "        [0.0636],\n",
      "        [0.0591],\n",
      "        [0.0603],\n",
      "        [0.0624],\n",
      "        [0.0637],\n",
      "        [0.0587],\n",
      "        [0.0599],\n",
      "        [0.0569]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0592],\n",
      "        [0.0619],\n",
      "        [0.0637],\n",
      "        [0.0592],\n",
      "        [0.0604],\n",
      "        [0.0624],\n",
      "        [0.0637],\n",
      "        [0.0587],\n",
      "        [0.0599],\n",
      "        [0.0569]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0592],\n",
      "        [0.0619],\n",
      "        [0.0637],\n",
      "        [0.0593],\n",
      "        [0.0604],\n",
      "        [0.0624],\n",
      "        [0.0637],\n",
      "        [0.0587],\n",
      "        [0.0599],\n",
      "        [0.0569]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0592],\n",
      "        [0.0619],\n",
      "        [0.0637],\n",
      "        [0.0595],\n",
      "        [0.0605],\n",
      "        [0.0625],\n",
      "        [0.0637],\n",
      "        [0.0587],\n",
      "        [0.0598],\n",
      "        [0.0569]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0592],\n",
      "        [0.0619],\n",
      "        [0.0637],\n",
      "        [0.0646],\n",
      "        [0.0647],\n",
      "        [0.0645],\n",
      "        [0.0643],\n",
      "        [0.0585],\n",
      "        [0.0592],\n",
      "        [0.0562]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0585],\n",
      "        [0.0613],\n",
      "        [0.0632],\n",
      "        [0.0641],\n",
      "        [0.0644],\n",
      "        [0.0644],\n",
      "        [0.0642],\n",
      "        [0.0585],\n",
      "        [0.0593],\n",
      "        [0.0563]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0586],\n",
      "        [0.0614],\n",
      "        [0.0632],\n",
      "        [0.0642],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0643],\n",
      "        [0.0585],\n",
      "        [0.0593],\n",
      "        [0.0565]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0587],\n",
      "        [0.0614],\n",
      "        [0.0632],\n",
      "        [0.0642],\n",
      "        [0.0645],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0586],\n",
      "        [0.0594],\n",
      "        [0.0566]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0588],\n",
      "        [0.0615],\n",
      "        [0.0633],\n",
      "        [0.0642],\n",
      "        [0.0645],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0586],\n",
      "        [0.0594],\n",
      "        [0.0569]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0590],\n",
      "        [0.0616],\n",
      "        [0.0633],\n",
      "        [0.0642],\n",
      "        [0.0645],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0586],\n",
      "        [0.0594],\n",
      "        [0.0616]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0629],\n",
      "        [0.0634],\n",
      "        [0.0637],\n",
      "        [0.0638],\n",
      "        [0.0638],\n",
      "        [0.0637],\n",
      "        [0.0636],\n",
      "        [0.0580],\n",
      "        [0.0589],\n",
      "        [0.0611]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0625],\n",
      "        [0.0633],\n",
      "        [0.0636],\n",
      "        [0.0638],\n",
      "        [0.0638],\n",
      "        [0.0638],\n",
      "        [0.0637],\n",
      "        [0.0581],\n",
      "        [0.0589],\n",
      "        [0.0612]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0626],\n",
      "        [0.0633],\n",
      "        [0.0637],\n",
      "        [0.0639],\n",
      "        [0.0639],\n",
      "        [0.0638],\n",
      "        [0.0638],\n",
      "        [0.0581],\n",
      "        [0.0590],\n",
      "        [0.0612]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0626],\n",
      "        [0.0634],\n",
      "        [0.0638],\n",
      "        [0.0639],\n",
      "        [0.0640],\n",
      "        [0.0639],\n",
      "        [0.0638],\n",
      "        [0.0582],\n",
      "        [0.0590],\n",
      "        [0.0612]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0626],\n",
      "        [0.0634],\n",
      "        [0.0638],\n",
      "        [0.0640],\n",
      "        [0.0640],\n",
      "        [0.0639],\n",
      "        [0.0639],\n",
      "        [0.0582],\n",
      "        [0.0591],\n",
      "        [0.0612]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0627],\n",
      "        [0.0635],\n",
      "        [0.0639],\n",
      "        [0.0640],\n",
      "        [0.0641],\n",
      "        [0.0640],\n",
      "        [0.0639],\n",
      "        [0.0583],\n",
      "        [0.0591],\n",
      "        [0.0613]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0627],\n",
      "        [0.0635],\n",
      "        [0.0639],\n",
      "        [0.0641],\n",
      "        [0.0641],\n",
      "        [0.0640],\n",
      "        [0.0640],\n",
      "        [0.0583],\n",
      "        [0.0591],\n",
      "        [0.0613]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0627],\n",
      "        [0.0635],\n",
      "        [0.0639],\n",
      "        [0.0641],\n",
      "        [0.0641],\n",
      "        [0.0641],\n",
      "        [0.0640],\n",
      "        [0.0583],\n",
      "        [0.0591],\n",
      "        [0.0613]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0627],\n",
      "        [0.0635],\n",
      "        [0.0640],\n",
      "        [0.0641],\n",
      "        [0.0642],\n",
      "        [0.0641],\n",
      "        [0.0640],\n",
      "        [0.0583],\n",
      "        [0.0592],\n",
      "        [0.0613]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0628],\n",
      "        [0.0636],\n",
      "        [0.0640],\n",
      "        [0.0642],\n",
      "        [0.0642],\n",
      "        [0.0641],\n",
      "        [0.0641],\n",
      "        [0.0584],\n",
      "        [0.0592],\n",
      "        [0.0613]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0628],\n",
      "        [0.0636],\n",
      "        [0.0640],\n",
      "        [0.0642],\n",
      "        [0.0642],\n",
      "        [0.0642],\n",
      "        [0.0641],\n",
      "        [0.0584],\n",
      "        [0.0592],\n",
      "        [0.0613]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0628],\n",
      "        [0.0636],\n",
      "        [0.0640],\n",
      "        [0.0642],\n",
      "        [0.0643],\n",
      "        [0.0642],\n",
      "        [0.0641],\n",
      "        [0.0584],\n",
      "        [0.0592],\n",
      "        [0.0614]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0628],\n",
      "        [0.0636],\n",
      "        [0.0641],\n",
      "        [0.0642],\n",
      "        [0.0643],\n",
      "        [0.0642],\n",
      "        [0.0641],\n",
      "        [0.0584],\n",
      "        [0.0593],\n",
      "        [0.0614]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0628],\n",
      "        [0.0637],\n",
      "        [0.0641],\n",
      "        [0.0643],\n",
      "        [0.0643],\n",
      "        [0.0642],\n",
      "        [0.0642],\n",
      "        [0.0585],\n",
      "        [0.0593],\n",
      "        [0.0614]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0629],\n",
      "        [0.0637],\n",
      "        [0.0641],\n",
      "        [0.0643],\n",
      "        [0.0643],\n",
      "        [0.0643],\n",
      "        [0.0642],\n",
      "        [0.0585],\n",
      "        [0.0593],\n",
      "        [0.0614]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0629],\n",
      "        [0.0637],\n",
      "        [0.0641],\n",
      "        [0.0643],\n",
      "        [0.0644],\n",
      "        [0.0643],\n",
      "        [0.0642],\n",
      "        [0.0585],\n",
      "        [0.0593],\n",
      "        [0.0614]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0629],\n",
      "        [0.0637],\n",
      "        [0.0641],\n",
      "        [0.0643],\n",
      "        [0.0644],\n",
      "        [0.0643],\n",
      "        [0.0642],\n",
      "        [0.0585],\n",
      "        [0.0593],\n",
      "        [0.0614]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0629],\n",
      "        [0.0637],\n",
      "        [0.0642],\n",
      "        [0.0644],\n",
      "        [0.0644],\n",
      "        [0.0643],\n",
      "        [0.0642],\n",
      "        [0.0585],\n",
      "        [0.0593],\n",
      "        [0.0614]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0629],\n",
      "        [0.0637],\n",
      "        [0.0642],\n",
      "        [0.0644],\n",
      "        [0.0644],\n",
      "        [0.0644],\n",
      "        [0.0643],\n",
      "        [0.0586],\n",
      "        [0.0594],\n",
      "        [0.0615]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0629],\n",
      "        [0.0638],\n",
      "        [0.0642],\n",
      "        [0.0644],\n",
      "        [0.0644],\n",
      "        [0.0644],\n",
      "        [0.0643],\n",
      "        [0.0586],\n",
      "        [0.0594],\n",
      "        [0.0615]], grad_fn=<AddmmBackward0>)\n",
      "Update "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_26284\\3111178144.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(preprocessed).to(gradients.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0629],\n",
      "        [0.0638],\n",
      "        [0.0642],\n",
      "        [0.0644],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0643],\n",
      "        [0.0586],\n",
      "        [0.0594],\n",
      "        [0.0615]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0630],\n",
      "        [0.0638],\n",
      "        [0.0642],\n",
      "        [0.0644],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0643],\n",
      "        [0.0586],\n",
      "        [0.0594],\n",
      "        [0.0615]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0630],\n",
      "        [0.0638],\n",
      "        [0.0642],\n",
      "        [0.0644],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0643],\n",
      "        [0.0586],\n",
      "        [0.0594],\n",
      "        [0.0615]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0630],\n",
      "        [0.0638],\n",
      "        [0.0643],\n",
      "        [0.0645],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0644],\n",
      "        [0.0586],\n",
      "        [0.0594],\n",
      "        [0.0615]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0630],\n",
      "        [0.0638],\n",
      "        [0.0643],\n",
      "        [0.0645],\n",
      "        [0.0645],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0586],\n",
      "        [0.0594],\n",
      "        [0.0615]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0630],\n",
      "        [0.0638],\n",
      "        [0.0643],\n",
      "        [0.0645],\n",
      "        [0.0645],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0587],\n",
      "        [0.0595],\n",
      "        [0.0615]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0630],\n",
      "        [0.0639],\n",
      "        [0.0643],\n",
      "        [0.0645],\n",
      "        [0.0646],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0587],\n",
      "        [0.0595],\n",
      "        [0.0615]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0630],\n",
      "        [0.0639],\n",
      "        [0.0643],\n",
      "        [0.0645],\n",
      "        [0.0646],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0587],\n",
      "        [0.0595],\n",
      "        [0.0616]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0630],\n",
      "        [0.0639],\n",
      "        [0.0643],\n",
      "        [0.0645],\n",
      "        [0.0646],\n",
      "        [0.0645],\n",
      "        [0.0644],\n",
      "        [0.0587],\n",
      "        [0.0595],\n",
      "        [0.0616]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0630],\n",
      "        [0.0639],\n",
      "        [0.0643],\n",
      "        [0.0645],\n",
      "        [0.0646],\n",
      "        [0.0645],\n",
      "        [0.0645],\n",
      "        [0.0587],\n",
      "        [0.0595],\n",
      "        [0.0616]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0631],\n",
      "        [0.0639],\n",
      "        [0.0644],\n",
      "        [0.0646],\n",
      "        [0.0646],\n",
      "        [0.0646],\n",
      "        [0.0645],\n",
      "        [0.0587],\n",
      "        [0.0595],\n",
      "        [0.0616]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0631],\n",
      "        [0.0639],\n",
      "        [0.0644],\n",
      "        [0.0646],\n",
      "        [0.0646],\n",
      "        [0.0646],\n",
      "        [0.0645],\n",
      "        [0.0587],\n",
      "        [0.0595],\n",
      "        [0.0616]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0631],\n",
      "        [0.0639],\n",
      "        [0.0644],\n",
      "        [0.0646],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0645],\n",
      "        [0.0588],\n",
      "        [0.0595],\n",
      "        [0.0616]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0631],\n",
      "        [0.0639],\n",
      "        [0.0644],\n",
      "        [0.0646],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0645],\n",
      "        [0.0588],\n",
      "        [0.0595],\n",
      "        [0.0616]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0631],\n",
      "        [0.0640],\n",
      "        [0.0644],\n",
      "        [0.0646],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0645],\n",
      "        [0.0588],\n",
      "        [0.0595],\n",
      "        [0.0616]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0631],\n",
      "        [0.0640],\n",
      "        [0.0644],\n",
      "        [0.0646],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0645],\n",
      "        [0.0588],\n",
      "        [0.0596],\n",
      "        [0.0616]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0631],\n",
      "        [0.0640],\n",
      "        [0.0644],\n",
      "        [0.0646],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0646],\n",
      "        [0.0588],\n",
      "        [0.0596],\n",
      "        [0.0616]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0631],\n",
      "        [0.0640],\n",
      "        [0.0644],\n",
      "        [0.0646],\n",
      "        [0.0647],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0588],\n",
      "        [0.0596],\n",
      "        [0.0616]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0631],\n",
      "        [0.0640],\n",
      "        [0.0645],\n",
      "        [0.0647],\n",
      "        [0.0647],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0588],\n",
      "        [0.0596],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0631],\n",
      "        [0.0640],\n",
      "        [0.0645],\n",
      "        [0.0647],\n",
      "        [0.0647],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0588],\n",
      "        [0.0596],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0631],\n",
      "        [0.0640],\n",
      "        [0.0645],\n",
      "        [0.0647],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0588],\n",
      "        [0.0596],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0640],\n",
      "        [0.0645],\n",
      "        [0.0647],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0588],\n",
      "        [0.0596],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0640],\n",
      "        [0.0645],\n",
      "        [0.0647],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0589],\n",
      "        [0.0596],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0640],\n",
      "        [0.0645],\n",
      "        [0.0647],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0589],\n",
      "        [0.0596],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0640],\n",
      "        [0.0645],\n",
      "        [0.0647],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0646],\n",
      "        [0.0589],\n",
      "        [0.0596],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0641],\n",
      "        [0.0645],\n",
      "        [0.0647],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0647],\n",
      "        [0.0589],\n",
      "        [0.0596],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0641],\n",
      "        [0.0645],\n",
      "        [0.0647],\n",
      "        [0.0648],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0589],\n",
      "        [0.0596],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0641],\n",
      "        [0.0645],\n",
      "        [0.0648],\n",
      "        [0.0648],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0589],\n",
      "        [0.0597],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0641],\n",
      "        [0.0645],\n",
      "        [0.0648],\n",
      "        [0.0648],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0589],\n",
      "        [0.0597],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0641],\n",
      "        [0.0646],\n",
      "        [0.0648],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0589],\n",
      "        [0.0597],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0641],\n",
      "        [0.0646],\n",
      "        [0.0648],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0589],\n",
      "        [0.0597],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0641],\n",
      "        [0.0646],\n",
      "        [0.0648],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0589],\n",
      "        [0.0597],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0641],\n",
      "        [0.0646],\n",
      "        [0.0648],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0589],\n",
      "        [0.0597],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0641],\n",
      "        [0.0646],\n",
      "        [0.0648],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0589],\n",
      "        [0.0597],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0641],\n",
      "        [0.0646],\n",
      "        [0.0648],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0647],\n",
      "        [0.0589],\n",
      "        [0.0597],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0641],\n",
      "        [0.0646],\n",
      "        [0.0648],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0648],\n",
      "        [0.0590],\n",
      "        [0.0597],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0641],\n",
      "        [0.0646],\n",
      "        [0.0648],\n",
      "        [0.0649],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0590],\n",
      "        [0.0597],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0641],\n",
      "        [0.0646],\n",
      "        [0.0648],\n",
      "        [0.0649],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0590],\n",
      "        [0.0597],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0646],\n",
      "        [0.0649],\n",
      "        [0.0649],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0590],\n",
      "        [0.0597],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0646],\n",
      "        [0.0649],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0590],\n",
      "        [0.0597],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0646],\n",
      "        [0.0649],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0590],\n",
      "        [0.0597],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0649],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0590],\n",
      "        [0.0597],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0649],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0590],\n",
      "        [0.0597],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0649],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0590],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0649],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0590],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0649],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0590],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0649],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0648],\n",
      "        [0.0590],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0649],\n",
      "        [0.0650],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0590],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0649],\n",
      "        [0.0650],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0590],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0649],\n",
      "        [0.0650],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0590],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0650],\n",
      "        [0.0650],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0590],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0642],\n",
      "        [0.0647],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0647],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0647],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0649],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0650],\n",
      "        [0.0651],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0650],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0591],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0648],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0649],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0649],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0650],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0652],\n",
      "        [0.0650],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0652],\n",
      "        [0.0650],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0651],\n",
      "        [0.0652],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0651],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0651],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0651],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0652],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0654],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0654],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0654],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0635],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0654],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0654],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0599],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0654],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0654],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0654],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0592],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0654],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0619]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0654],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0654],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0644],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0654],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0591],\n",
      "        [0.0598],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0634],\n",
      "        [0.0643],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0654],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0591],\n",
      "        [0.0597],\n",
      "        [0.0618]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0643],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0590],\n",
      "        [0.0597],\n",
      "        [0.0617]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0633],\n",
      "        [0.0643],\n",
      "        [0.0649],\n",
      "        [0.0652],\n",
      "        [0.0653],\n",
      "        [0.0653],\n",
      "        [0.0651],\n",
      "        [0.0589],\n",
      "        [0.0595],\n",
      "        [0.0616]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0632],\n",
      "        [0.0642],\n",
      "        [0.0648],\n",
      "        [0.0651],\n",
      "        [0.0653],\n",
      "        [0.0606],\n",
      "        [0.0610],\n",
      "        [0.0570],\n",
      "        [0.0592],\n",
      "        [0.0620]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0639],\n",
      "        [0.0650],\n",
      "        [0.0656],\n",
      "        [0.0658],\n",
      "        [0.0659],\n",
      "        [0.0608],\n",
      "        [0.0612],\n",
      "        [0.0573],\n",
      "        [0.0594],\n",
      "        [0.0622]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0641],\n",
      "        [0.0652],\n",
      "        [0.0657],\n",
      "        [0.0659],\n",
      "        [0.0659],\n",
      "        [0.0607],\n",
      "        [0.0612],\n",
      "        [0.0573],\n",
      "        [0.0594],\n",
      "        [0.0623]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0641],\n",
      "        [0.0652],\n",
      "        [0.0657],\n",
      "        [0.0659],\n",
      "        [0.0660],\n",
      "        [0.0606],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0594],\n",
      "        [0.0623]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0642],\n",
      "        [0.0652],\n",
      "        [0.0657],\n",
      "        [0.0659],\n",
      "        [0.0660],\n",
      "        [0.0606],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0594],\n",
      "        [0.0623]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0642],\n",
      "        [0.0652],\n",
      "        [0.0657],\n",
      "        [0.0659],\n",
      "        [0.0660],\n",
      "        [0.0606],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0594],\n",
      "        [0.0623]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0642],\n",
      "        [0.0652],\n",
      "        [0.0658],\n",
      "        [0.0660],\n",
      "        [0.0660],\n",
      "        [0.0606],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0623]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0642],\n",
      "        [0.0653],\n",
      "        [0.0658],\n",
      "        [0.0660],\n",
      "        [0.0660],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0623]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0642],\n",
      "        [0.0653],\n",
      "        [0.0658],\n",
      "        [0.0660],\n",
      "        [0.0660],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0623]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0642],\n",
      "        [0.0653],\n",
      "        [0.0658],\n",
      "        [0.0660],\n",
      "        [0.0660],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0623]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0642],\n",
      "        [0.0653],\n",
      "        [0.0658],\n",
      "        [0.0660],\n",
      "        [0.0660],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0653],\n",
      "        [0.0658],\n",
      "        [0.0660],\n",
      "        [0.0660],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0653],\n",
      "        [0.0658],\n",
      "        [0.0660],\n",
      "        [0.0660],\n",
      "        [0.0605],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0653],\n",
      "        [0.0658],\n",
      "        [0.0660],\n",
      "        [0.0660],\n",
      "        [0.0605],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0653],\n",
      "        [0.0658],\n",
      "        [0.0660],\n",
      "        [0.0661],\n",
      "        [0.0605],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0653],\n",
      "        [0.0658],\n",
      "        [0.0660],\n",
      "        [0.0661],\n",
      "        [0.0605],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0653],\n",
      "        [0.0658],\n",
      "        [0.0660],\n",
      "        [0.0661],\n",
      "        [0.0605],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0653],\n",
      "        [0.0658],\n",
      "        [0.0660],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0653],\n",
      "        [0.0659],\n",
      "        [0.0660],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0595],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0643],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0624]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0661],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0654],\n",
      "        [0.0659],\n",
      "        [0.0661],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0610],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0654],\n",
      "        [0.0660],\n",
      "        [0.0661],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0654],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0644],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0573],\n",
      "        [0.0596],\n",
      "        [0.0625]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0596],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0662],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0661],\n",
      "        [0.0662],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0655],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0604],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0645],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0663],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0626]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0611],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0663],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0661],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0574],\n",
      "        [0.0597],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0574],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0574],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0574],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0574],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0656],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0574],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0574],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0574],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0574],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0574],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0664],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0646],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0664],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0662],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0627]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0657],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0605],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0606],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0606],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0606],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0606],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0606],\n",
      "        [0.0612],\n",
      "        [0.0575],\n",
      "        [0.0598],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0665],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0575],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0647],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0665],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0663],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0658],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0628]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0666],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0613],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0599],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0606],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0666],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0664],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0648],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0659],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0576],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0667],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0629]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0667],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0614],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0665],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0607],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0600],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0649],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0668],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0660],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0668],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0577],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0630]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0666],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0667],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0667],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0667],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0667],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0667],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0667],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0667],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0667],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0650],\n",
      "        [0.0661],\n",
      "        [0.0667],\n",
      "        [0.0669],\n",
      "        [0.0669],\n",
      "        [0.0608],\n",
      "        [0.0615],\n",
      "        [0.0578],\n",
      "        [0.0601],\n",
      "        [0.0631]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/500], Cumulative Loss: 747611.3125, LR: 1.000e-03\n",
      "Final parameters: [[31.855953 33.48319  33.22974  32.58021  31.841679 31.375471 32.790844\n",
      "  29.157654 30.33128  30.265963]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Update tensor([[-0.0364],\n",
      "        [-0.0495],\n",
      "        [-0.0048],\n",
      "        [ 0.0196],\n",
      "        [ 0.0303],\n",
      "        [ 0.0409],\n",
      "        [ 0.0425],\n",
      "        [ 0.0428],\n",
      "        [ 0.0433],\n",
      "        [ 0.0439]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0443],\n",
      "        [0.0447],\n",
      "        [0.0451],\n",
      "        [0.0454],\n",
      "        [0.0456],\n",
      "        [0.0511],\n",
      "        [0.0498],\n",
      "        [0.0480],\n",
      "        [0.0469],\n",
      "        [0.0463]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0458],\n",
      "        [0.0457],\n",
      "        [0.0457],\n",
      "        [0.0457],\n",
      "        [0.0458],\n",
      "        [0.0512],\n",
      "        [0.0499],\n",
      "        [0.0481],\n",
      "        [0.0469],\n",
      "        [0.0463]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0458],\n",
      "        [0.0457],\n",
      "        [0.0457],\n",
      "        [0.0458],\n",
      "        [0.0458],\n",
      "        [0.0513],\n",
      "        [0.0499],\n",
      "        [0.0481],\n",
      "        [0.0469],\n",
      "        [0.0464]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0459],\n",
      "        [0.0457],\n",
      "        [0.0458],\n",
      "        [0.0458],\n",
      "        [0.0459],\n",
      "        [0.0513],\n",
      "        [0.0499],\n",
      "        [0.0481],\n",
      "        [0.0469],\n",
      "        [0.0464]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0459],\n",
      "        [0.0457],\n",
      "        [0.0458],\n",
      "        [0.0458],\n",
      "        [0.0459],\n",
      "        [0.0513],\n",
      "        [0.0499],\n",
      "        [0.0481],\n",
      "        [0.0470],\n",
      "        [0.0464]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0459],\n",
      "        [0.0458],\n",
      "        [0.0458],\n",
      "        [0.0458],\n",
      "        [0.0459],\n",
      "        [0.0513],\n",
      "        [0.0499],\n",
      "        [0.0481],\n",
      "        [0.0470],\n",
      "        [0.0464]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0459],\n",
      "        [0.0458],\n",
      "        [0.0458],\n",
      "        [0.0458],\n",
      "        [0.0459],\n",
      "        [0.0513],\n",
      "        [0.0499],\n",
      "        [0.0481],\n",
      "        [0.0470],\n",
      "        [0.0465]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0459],\n",
      "        [0.0458],\n",
      "        [0.0458],\n",
      "        [0.0458],\n",
      "        [0.0459],\n",
      "        [0.0513],\n",
      "        [0.0499],\n",
      "        [0.0481],\n",
      "        [0.0470],\n",
      "        [0.0465]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0460],\n",
      "        [0.0458],\n",
      "        [0.0459],\n",
      "        [0.0459],\n",
      "        [0.0459],\n",
      "        [0.0513],\n",
      "        [0.0499],\n",
      "        [0.0481],\n",
      "        [0.0471],\n",
      "        [0.0465]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0460],\n",
      "        [0.0459],\n",
      "        [0.0459],\n",
      "        [0.0459],\n",
      "        [0.0459],\n",
      "        [0.0513],\n",
      "        [0.0499],\n",
      "        [0.0481],\n",
      "        [0.0471],\n",
      "        [0.0465]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0460],\n",
      "        [0.0459],\n",
      "        [0.0459],\n",
      "        [0.0459],\n",
      "        [0.0460],\n",
      "        [0.0513],\n",
      "        [0.0499],\n",
      "        [0.0481],\n",
      "        [0.0472],\n",
      "        [0.0466]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0460],\n",
      "        [0.0459],\n",
      "        [0.0459],\n",
      "        [0.0459],\n",
      "        [0.0460],\n",
      "        [0.0513],\n",
      "        [0.0499],\n",
      "        [0.0481],\n",
      "        [0.0472],\n",
      "        [0.0466]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0461],\n",
      "        [0.0459],\n",
      "        [0.0460],\n",
      "        [0.0459],\n",
      "        [0.0460],\n",
      "        [0.0513],\n",
      "        [0.0499],\n",
      "        [0.0481],\n",
      "        [0.0473],\n",
      "        [0.0467]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0461],\n",
      "        [0.0460],\n",
      "        [0.0460],\n",
      "        [0.0460],\n",
      "        [0.0460],\n",
      "        [0.0513],\n",
      "        [0.0499],\n",
      "        [0.0482],\n",
      "        [0.0473],\n",
      "        [0.0468]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0462],\n",
      "        [0.0460],\n",
      "        [0.0460],\n",
      "        [0.0460],\n",
      "        [0.0460],\n",
      "        [0.0513],\n",
      "        [0.0500],\n",
      "        [0.0482],\n",
      "        [0.0475],\n",
      "        [0.0468]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0462],\n",
      "        [0.0461],\n",
      "        [0.0460],\n",
      "        [0.0460],\n",
      "        [0.0461],\n",
      "        [0.0513],\n",
      "        [0.0500],\n",
      "        [0.0482],\n",
      "        [0.0476],\n",
      "        [0.0469]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0463],\n",
      "        [0.0461],\n",
      "        [0.0461],\n",
      "        [0.0460],\n",
      "        [0.0461],\n",
      "        [0.0513],\n",
      "        [0.0500],\n",
      "        [0.0483],\n",
      "        [0.0479],\n",
      "        [0.0471]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0464],\n",
      "        [0.0462],\n",
      "        [0.0461],\n",
      "        [0.0461],\n",
      "        [0.0461],\n",
      "        [0.0512],\n",
      "        [0.0500],\n",
      "        [0.0484],\n",
      "        [0.0493],\n",
      "        [0.0481]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0468],\n",
      "        [0.0463],\n",
      "        [0.0461],\n",
      "        [0.0460],\n",
      "        [0.0460],\n",
      "        [0.0511],\n",
      "        [0.0500],\n",
      "        [0.0487],\n",
      "        [0.0522],\n",
      "        [0.0500]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0470],\n",
      "        [0.0456],\n",
      "        [0.0450],\n",
      "        [0.0450],\n",
      "        [0.0451],\n",
      "        [0.0503],\n",
      "        [0.0495],\n",
      "        [0.0526],\n",
      "        [0.0546],\n",
      "        [0.0504]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0463],\n",
      "        [0.0445],\n",
      "        [0.0438],\n",
      "        [0.0441],\n",
      "        [0.0444],\n",
      "        [0.0497],\n",
      "        [0.0539],\n",
      "        [0.0553],\n",
      "        [0.0551],\n",
      "        [0.0497]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0451],\n",
      "        [0.0433],\n",
      "        [0.0428],\n",
      "        [0.0480],\n",
      "        [0.0470],\n",
      "        [0.0499],\n",
      "        [0.0524],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0486]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0444],\n",
      "        [0.0430],\n",
      "        [0.0426],\n",
      "        [0.0475],\n",
      "        [0.0467],\n",
      "        [0.0498],\n",
      "        [0.0524],\n",
      "        [0.0536],\n",
      "        [0.0537],\n",
      "        [0.0488]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0447],\n",
      "        [0.0440],\n",
      "        [0.0434],\n",
      "        [0.0478],\n",
      "        [0.0469],\n",
      "        [0.0498],\n",
      "        [0.0523],\n",
      "        [0.0535],\n",
      "        [0.0536],\n",
      "        [0.0488]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0450],\n",
      "        [0.0477],\n",
      "        [0.0459],\n",
      "        [0.0483],\n",
      "        [0.0463],\n",
      "        [0.0487],\n",
      "        [0.0511],\n",
      "        [0.0524],\n",
      "        [0.0526],\n",
      "        [0.0481]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0449],\n",
      "        [0.0475],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0462],\n",
      "        [0.0486],\n",
      "        [0.0510],\n",
      "        [0.0523],\n",
      "        [0.0526],\n",
      "        [0.0481]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0487],\n",
      "        [0.0501],\n",
      "        [0.0468],\n",
      "        [0.0478],\n",
      "        [0.0452],\n",
      "        [0.0474],\n",
      "        [0.0498],\n",
      "        [0.0516],\n",
      "        [0.0518],\n",
      "        [0.0473]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0479],\n",
      "        [0.0494],\n",
      "        [0.0503],\n",
      "        [0.0506],\n",
      "        [0.0461],\n",
      "        [0.0470],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0475],\n",
      "        [0.0456]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0479],\n",
      "        [0.0502],\n",
      "        [0.0514],\n",
      "        [0.0517],\n",
      "        [0.0471],\n",
      "        [0.0479],\n",
      "        [0.0496],\n",
      "        [0.0463],\n",
      "        [0.0478],\n",
      "        [0.0460]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0482],\n",
      "        [0.0504],\n",
      "        [0.0515],\n",
      "        [0.0519],\n",
      "        [0.0473],\n",
      "        [0.0481],\n",
      "        [0.0497],\n",
      "        [0.0464],\n",
      "        [0.0478],\n",
      "        [0.0462]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0483],\n",
      "        [0.0505],\n",
      "        [0.0516],\n",
      "        [0.0519],\n",
      "        [0.0474],\n",
      "        [0.0482],\n",
      "        [0.0498],\n",
      "        [0.0464],\n",
      "        [0.0479],\n",
      "        [0.0467]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0486],\n",
      "        [0.0506],\n",
      "        [0.0517],\n",
      "        [0.0520],\n",
      "        [0.0475],\n",
      "        [0.0482],\n",
      "        [0.0498],\n",
      "        [0.0463],\n",
      "        [0.0478],\n",
      "        [0.0501]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0512],\n",
      "        [0.0514],\n",
      "        [0.0513],\n",
      "        [0.0511],\n",
      "        [0.0467],\n",
      "        [0.0474],\n",
      "        [0.0490],\n",
      "        [0.0456],\n",
      "        [0.0472],\n",
      "        [0.0496]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0508],\n",
      "        [0.0512],\n",
      "        [0.0512],\n",
      "        [0.0510],\n",
      "        [0.0509],\n",
      "        [0.0506],\n",
      "        [0.0503],\n",
      "        [0.0455],\n",
      "        [0.0464],\n",
      "        [0.0485]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0497],\n",
      "        [0.0503],\n",
      "        [0.0505],\n",
      "        [0.0505],\n",
      "        [0.0505],\n",
      "        [0.0503],\n",
      "        [0.0501],\n",
      "        [0.0454],\n",
      "        [0.0464],\n",
      "        [0.0485]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0498],\n",
      "        [0.0504],\n",
      "        [0.0506],\n",
      "        [0.0506],\n",
      "        [0.0506],\n",
      "        [0.0504],\n",
      "        [0.0502],\n",
      "        [0.0455],\n",
      "        [0.0465],\n",
      "        [0.0486]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0499],\n",
      "        [0.0504],\n",
      "        [0.0507],\n",
      "        [0.0507],\n",
      "        [0.0506],\n",
      "        [0.0505],\n",
      "        [0.0503],\n",
      "        [0.0456],\n",
      "        [0.0466],\n",
      "        [0.0486]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0499],\n",
      "        [0.0505],\n",
      "        [0.0507],\n",
      "        [0.0508],\n",
      "        [0.0507],\n",
      "        [0.0506],\n",
      "        [0.0504],\n",
      "        [0.0457],\n",
      "        [0.0466],\n",
      "        [0.0487]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0500],\n",
      "        [0.0506],\n",
      "        [0.0508],\n",
      "        [0.0508],\n",
      "        [0.0508],\n",
      "        [0.0507],\n",
      "        [0.0505],\n",
      "        [0.0457],\n",
      "        [0.0467],\n",
      "        [0.0487]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0500],\n",
      "        [0.0506],\n",
      "        [0.0509],\n",
      "        [0.0509],\n",
      "        [0.0508],\n",
      "        [0.0507],\n",
      "        [0.0506],\n",
      "        [0.0458],\n",
      "        [0.0467],\n",
      "        [0.0488]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0500],\n",
      "        [0.0507],\n",
      "        [0.0509],\n",
      "        [0.0510],\n",
      "        [0.0509],\n",
      "        [0.0508],\n",
      "        [0.0506],\n",
      "        [0.0458],\n",
      "        [0.0468],\n",
      "        [0.0488]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0501],\n",
      "        [0.0507],\n",
      "        [0.0510],\n",
      "        [0.0510],\n",
      "        [0.0509],\n",
      "        [0.0508],\n",
      "        [0.0507],\n",
      "        [0.0459],\n",
      "        [0.0468],\n",
      "        [0.0488]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0501],\n",
      "        [0.0508],\n",
      "        [0.0510],\n",
      "        [0.0510],\n",
      "        [0.0510],\n",
      "        [0.0509],\n",
      "        [0.0507],\n",
      "        [0.0459],\n",
      "        [0.0468],\n",
      "        [0.0489]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0501],\n",
      "        [0.0508],\n",
      "        [0.0510],\n",
      "        [0.0511],\n",
      "        [0.0510],\n",
      "        [0.0509],\n",
      "        [0.0508],\n",
      "        [0.0459],\n",
      "        [0.0469],\n",
      "        [0.0489]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0502],\n",
      "        [0.0508],\n",
      "        [0.0511],\n",
      "        [0.0511],\n",
      "        [0.0511],\n",
      "        [0.0510],\n",
      "        [0.0508],\n",
      "        [0.0460],\n",
      "        [0.0469],\n",
      "        [0.0489]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0502],\n",
      "        [0.0508],\n",
      "        [0.0511],\n",
      "        [0.0512],\n",
      "        [0.0511],\n",
      "        [0.0510],\n",
      "        [0.0508],\n",
      "        [0.0460],\n",
      "        [0.0469],\n",
      "        [0.0489]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0502],\n",
      "        [0.0509],\n",
      "        [0.0511],\n",
      "        [0.0512],\n",
      "        [0.0511],\n",
      "        [0.0510],\n",
      "        [0.0509],\n",
      "        [0.0460],\n",
      "        [0.0470],\n",
      "        [0.0490]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0502],\n",
      "        [0.0509],\n",
      "        [0.0512],\n",
      "        [0.0512],\n",
      "        [0.0512],\n",
      "        [0.0511],\n",
      "        [0.0509],\n",
      "        [0.0461],\n",
      "        [0.0470],\n",
      "        [0.0490]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0503],\n",
      "        [0.0509],\n",
      "        [0.0512],\n",
      "        [0.0513],\n",
      "        [0.0512],\n",
      "        [0.0511],\n",
      "        [0.0509],\n",
      "        [0.0461],\n",
      "        [0.0470],\n",
      "        [0.0490]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0503],\n",
      "        [0.0509],\n",
      "        [0.0512],\n",
      "        [0.0513],\n",
      "        [0.0512],\n",
      "        [0.0511],\n",
      "        [0.0510],\n",
      "        [0.0461],\n",
      "        [0.0470],\n",
      "        [0.0490]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0503],\n",
      "        [0.0510],\n",
      "        [0.0512],\n",
      "        [0.0513],\n",
      "        [0.0513],\n",
      "        [0.0512],\n",
      "        [0.0510],\n",
      "        [0.0461],\n",
      "        [0.0470],\n",
      "        [0.0490]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0503],\n",
      "        [0.0510],\n",
      "        [0.0513],\n",
      "        [0.0513],\n",
      "        [0.0513],\n",
      "        [0.0512],\n",
      "        [0.0510],\n",
      "        [0.0462],\n",
      "        [0.0471],\n",
      "        [0.0490]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0503],\n",
      "        [0.0510],\n",
      "        [0.0513],\n",
      "        [0.0514],\n",
      "        [0.0513],\n",
      "        [0.0512],\n",
      "        [0.0511],\n",
      "        [0.0462],\n",
      "        [0.0471],\n",
      "        [0.0491]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0504],\n",
      "        [0.0510],\n",
      "        [0.0513],\n",
      "        [0.0514],\n",
      "        [0.0514],\n",
      "        [0.0512],\n",
      "        [0.0511],\n",
      "        [0.0462],\n",
      "        [0.0471],\n",
      "        [0.0491]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0504],\n",
      "        [0.0510],\n",
      "        [0.0513],\n",
      "        [0.0514],\n",
      "        [0.0514],\n",
      "        [0.0513],\n",
      "        [0.0511],\n",
      "        [0.0462],\n",
      "        [0.0471],\n",
      "        [0.0491]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0504],\n",
      "        [0.0511],\n",
      "        [0.0513],\n",
      "        [0.0514],\n",
      "        [0.0514],\n",
      "        [0.0513],\n",
      "        [0.0511],\n",
      "        [0.0462],\n",
      "        [0.0471],\n",
      "        [0.0491]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0504],\n",
      "        [0.0511],\n",
      "        [0.0514],\n",
      "        [0.0514],\n",
      "        [0.0514],\n",
      "        [0.0513],\n",
      "        [0.0512],\n",
      "        [0.0463],\n",
      "        [0.0471],\n",
      "        [0.0491]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0504],\n",
      "        [0.0511],\n",
      "        [0.0514],\n",
      "        [0.0515],\n",
      "        [0.0514],\n",
      "        [0.0513],\n",
      "        [0.0512],\n",
      "        [0.0463],\n",
      "        [0.0472],\n",
      "        [0.0491]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0504],\n",
      "        [0.0511],\n",
      "        [0.0514],\n",
      "        [0.0515],\n",
      "        [0.0515],\n",
      "        [0.0514],\n",
      "        [0.0512],\n",
      "        [0.0463],\n",
      "        [0.0472],\n",
      "        [0.0491]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0504],\n",
      "        [0.0511],\n",
      "        [0.0514],\n",
      "        [0.0515],\n",
      "        [0.0515],\n",
      "        [0.0514],\n",
      "        [0.0512],\n",
      "        [0.0463],\n",
      "        [0.0472],\n",
      "        [0.0491]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0511],\n",
      "        [0.0514],\n",
      "        [0.0515],\n",
      "        [0.0515],\n",
      "        [0.0514],\n",
      "        [0.0512],\n",
      "        [0.0463],\n",
      "        [0.0472],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0512],\n",
      "        [0.0515],\n",
      "        [0.0515],\n",
      "        [0.0515],\n",
      "        [0.0514],\n",
      "        [0.0512],\n",
      "        [0.0463],\n",
      "        [0.0472],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0512],\n",
      "        [0.0515],\n",
      "        [0.0516],\n",
      "        [0.0515],\n",
      "        [0.0514],\n",
      "        [0.0513],\n",
      "        [0.0463],\n",
      "        [0.0472],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0512],\n",
      "        [0.0515],\n",
      "        [0.0516],\n",
      "        [0.0516],\n",
      "        [0.0515],\n",
      "        [0.0513],\n",
      "        [0.0464],\n",
      "        [0.0472],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0512],\n",
      "        [0.0515],\n",
      "        [0.0516],\n",
      "        [0.0516],\n",
      "        [0.0515],\n",
      "        [0.0513],\n",
      "        [0.0464],\n",
      "        [0.0472],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0512],\n",
      "        [0.0515],\n",
      "        [0.0516],\n",
      "        [0.0516],\n",
      "        [0.0515],\n",
      "        [0.0513],\n",
      "        [0.0464],\n",
      "        [0.0472],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0512],\n",
      "        [0.0515],\n",
      "        [0.0516],\n",
      "        [0.0516],\n",
      "        [0.0515],\n",
      "        [0.0513],\n",
      "        [0.0464],\n",
      "        [0.0472],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0512],\n",
      "        [0.0515],\n",
      "        [0.0516],\n",
      "        [0.0516],\n",
      "        [0.0515],\n",
      "        [0.0513],\n",
      "        [0.0464],\n",
      "        [0.0473],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0512],\n",
      "        [0.0515],\n",
      "        [0.0516],\n",
      "        [0.0516],\n",
      "        [0.0515],\n",
      "        [0.0514],\n",
      "        [0.0464],\n",
      "        [0.0473],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0512],\n",
      "        [0.0516],\n",
      "        [0.0517],\n",
      "        [0.0517],\n",
      "        [0.0516],\n",
      "        [0.0514],\n",
      "        [0.0464],\n",
      "        [0.0473],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0513],\n",
      "        [0.0516],\n",
      "        [0.0517],\n",
      "        [0.0517],\n",
      "        [0.0516],\n",
      "        [0.0514],\n",
      "        [0.0464],\n",
      "        [0.0473],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0516],\n",
      "        [0.0517],\n",
      "        [0.0517],\n",
      "        [0.0516],\n",
      "        [0.0514],\n",
      "        [0.0464],\n",
      "        [0.0473],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0516],\n",
      "        [0.0517],\n",
      "        [0.0517],\n",
      "        [0.0516],\n",
      "        [0.0514],\n",
      "        [0.0464],\n",
      "        [0.0473],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0516],\n",
      "        [0.0517],\n",
      "        [0.0517],\n",
      "        [0.0516],\n",
      "        [0.0514],\n",
      "        [0.0464],\n",
      "        [0.0473],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0516],\n",
      "        [0.0517],\n",
      "        [0.0517],\n",
      "        [0.0516],\n",
      "        [0.0514],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0493]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0516],\n",
      "        [0.0517],\n",
      "        [0.0517],\n",
      "        [0.0516],\n",
      "        [0.0514],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0493]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0516],\n",
      "        [0.0517],\n",
      "        [0.0517],\n",
      "        [0.0516],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0493]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0516],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0517],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0493]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0516],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0517],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0493]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0517],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0517],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0493]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0517],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0517],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0493]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0517],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0517],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0493]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0517],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0517],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0493]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0517],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0517],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0493]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0517],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0517],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0493]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0517],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0517],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0517],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0517],\n",
      "        [0.0518],\n",
      "        [0.0519],\n",
      "        [0.0518],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0473],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0506],\n",
      "        [0.0513],\n",
      "        [0.0517],\n",
      "        [0.0518],\n",
      "        [0.0519],\n",
      "        [0.0518],\n",
      "        [0.0515],\n",
      "        [0.0465],\n",
      "        [0.0472],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0513],\n",
      "        [0.0517],\n",
      "        [0.0518],\n",
      "        [0.0519],\n",
      "        [0.0518],\n",
      "        [0.0515],\n",
      "        [0.0464],\n",
      "        [0.0472],\n",
      "        [0.0492]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0513],\n",
      "        [0.0517],\n",
      "        [0.0518],\n",
      "        [0.0519],\n",
      "        [0.0518],\n",
      "        [0.0515],\n",
      "        [0.0464],\n",
      "        [0.0471],\n",
      "        [0.0491]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0505],\n",
      "        [0.0512],\n",
      "        [0.0516],\n",
      "        [0.0518],\n",
      "        [0.0518],\n",
      "        [0.0481],\n",
      "        [0.0486],\n",
      "        [0.0454],\n",
      "        [0.0475],\n",
      "        [0.0500]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0516],\n",
      "        [0.0523],\n",
      "        [0.0526],\n",
      "        [0.0526],\n",
      "        [0.0525],\n",
      "        [0.0482],\n",
      "        [0.0487],\n",
      "        [0.0456],\n",
      "        [0.0477],\n",
      "        [0.0502]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0518],\n",
      "        [0.0525],\n",
      "        [0.0527],\n",
      "        [0.0527],\n",
      "        [0.0526],\n",
      "        [0.0481],\n",
      "        [0.0487],\n",
      "        [0.0456],\n",
      "        [0.0477],\n",
      "        [0.0503]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0518],\n",
      "        [0.0525],\n",
      "        [0.0527],\n",
      "        [0.0527],\n",
      "        [0.0526],\n",
      "        [0.0481],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0477],\n",
      "        [0.0503]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0518],\n",
      "        [0.0525],\n",
      "        [0.0528],\n",
      "        [0.0527],\n",
      "        [0.0526],\n",
      "        [0.0480],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0477],\n",
      "        [0.0503]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0519],\n",
      "        [0.0526],\n",
      "        [0.0528],\n",
      "        [0.0528],\n",
      "        [0.0526],\n",
      "        [0.0480],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0477],\n",
      "        [0.0503]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0519],\n",
      "        [0.0526],\n",
      "        [0.0528],\n",
      "        [0.0528],\n",
      "        [0.0526],\n",
      "        [0.0480],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0478],\n",
      "        [0.0504]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0519],\n",
      "        [0.0526],\n",
      "        [0.0528],\n",
      "        [0.0528],\n",
      "        [0.0527],\n",
      "        [0.0480],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0478],\n",
      "        [0.0504]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0519],\n",
      "        [0.0526],\n",
      "        [0.0528],\n",
      "        [0.0528],\n",
      "        [0.0527],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0478],\n",
      "        [0.0504]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0519],\n",
      "        [0.0526],\n",
      "        [0.0528],\n",
      "        [0.0528],\n",
      "        [0.0527],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0478],\n",
      "        [0.0504]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0519],\n",
      "        [0.0526],\n",
      "        [0.0529],\n",
      "        [0.0528],\n",
      "        [0.0527],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0478],\n",
      "        [0.0504]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0519],\n",
      "        [0.0527],\n",
      "        [0.0529],\n",
      "        [0.0529],\n",
      "        [0.0527],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0478],\n",
      "        [0.0504]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0520],\n",
      "        [0.0527],\n",
      "        [0.0529],\n",
      "        [0.0529],\n",
      "        [0.0527],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0478],\n",
      "        [0.0504]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0520],\n",
      "        [0.0527],\n",
      "        [0.0529],\n",
      "        [0.0529],\n",
      "        [0.0527],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0478],\n",
      "        [0.0504]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0520],\n",
      "        [0.0527],\n",
      "        [0.0529],\n",
      "        [0.0529],\n",
      "        [0.0527],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0478],\n",
      "        [0.0504]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0520],\n",
      "        [0.0527],\n",
      "        [0.0529],\n",
      "        [0.0529],\n",
      "        [0.0528],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0478],\n",
      "        [0.0504]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0520],\n",
      "        [0.0527],\n",
      "        [0.0529],\n",
      "        [0.0529],\n",
      "        [0.0528],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0478],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0520],\n",
      "        [0.0527],\n",
      "        [0.0529],\n",
      "        [0.0529],\n",
      "        [0.0528],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0478],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0520],\n",
      "        [0.0527],\n",
      "        [0.0530],\n",
      "        [0.0529],\n",
      "        [0.0528],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0479],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0520],\n",
      "        [0.0527],\n",
      "        [0.0530],\n",
      "        [0.0529],\n",
      "        [0.0528],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0479],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0520],\n",
      "        [0.0527],\n",
      "        [0.0530],\n",
      "        [0.0529],\n",
      "        [0.0528],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0479],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0520],\n",
      "        [0.0528],\n",
      "        [0.0530],\n",
      "        [0.0530],\n",
      "        [0.0528],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0479],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0520],\n",
      "        [0.0528],\n",
      "        [0.0530],\n",
      "        [0.0530],\n",
      "        [0.0528],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0479],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0528],\n",
      "        [0.0530],\n",
      "        [0.0530],\n",
      "        [0.0528],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0479],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0528],\n",
      "        [0.0530],\n",
      "        [0.0530],\n",
      "        [0.0528],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0479],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0528],\n",
      "        [0.0530],\n",
      "        [0.0530],\n",
      "        [0.0529],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0479],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0528],\n",
      "        [0.0530],\n",
      "        [0.0530],\n",
      "        [0.0529],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0479],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0528],\n",
      "        [0.0530],\n",
      "        [0.0530],\n",
      "        [0.0529],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0479],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0528],\n",
      "        [0.0530],\n",
      "        [0.0530],\n",
      "        [0.0529],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0479],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0528],\n",
      "        [0.0530],\n",
      "        [0.0530],\n",
      "        [0.0529],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0479],\n",
      "        [0.0505]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0528],\n",
      "        [0.0531],\n",
      "        [0.0530],\n",
      "        [0.0529],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0479],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0528],\n",
      "        [0.0531],\n",
      "        [0.0530],\n",
      "        [0.0529],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0479],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0528],\n",
      "        [0.0531],\n",
      "        [0.0531],\n",
      "        [0.0529],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0479],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0528],\n",
      "        [0.0531],\n",
      "        [0.0531],\n",
      "        [0.0529],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0479],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0529],\n",
      "        [0.0531],\n",
      "        [0.0531],\n",
      "        [0.0529],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0480],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0529],\n",
      "        [0.0531],\n",
      "        [0.0531],\n",
      "        [0.0529],\n",
      "        [0.0479],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0480],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0521],\n",
      "        [0.0529],\n",
      "        [0.0531],\n",
      "        [0.0531],\n",
      "        [0.0530],\n",
      "        [0.0479],\n",
      "        [0.0487],\n",
      "        [0.0457],\n",
      "        [0.0480],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0529],\n",
      "        [0.0531],\n",
      "        [0.0531],\n",
      "        [0.0530],\n",
      "        [0.0479],\n",
      "        [0.0487],\n",
      "        [0.0457],\n",
      "        [0.0480],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0529],\n",
      "        [0.0531],\n",
      "        [0.0531],\n",
      "        [0.0530],\n",
      "        [0.0479],\n",
      "        [0.0487],\n",
      "        [0.0457],\n",
      "        [0.0480],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0529],\n",
      "        [0.0531],\n",
      "        [0.0531],\n",
      "        [0.0530],\n",
      "        [0.0479],\n",
      "        [0.0487],\n",
      "        [0.0457],\n",
      "        [0.0480],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0529],\n",
      "        [0.0531],\n",
      "        [0.0531],\n",
      "        [0.0530],\n",
      "        [0.0479],\n",
      "        [0.0487],\n",
      "        [0.0457],\n",
      "        [0.0480],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0529],\n",
      "        [0.0531],\n",
      "        [0.0531],\n",
      "        [0.0530],\n",
      "        [0.0479],\n",
      "        [0.0487],\n",
      "        [0.0457],\n",
      "        [0.0480],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0529],\n",
      "        [0.0531],\n",
      "        [0.0531],\n",
      "        [0.0530],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0457],\n",
      "        [0.0480],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0529],\n",
      "        [0.0532],\n",
      "        [0.0531],\n",
      "        [0.0530],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0457],\n",
      "        [0.0480],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0529],\n",
      "        [0.0532],\n",
      "        [0.0531],\n",
      "        [0.0530],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0480],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0529],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0530],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0480],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0529],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0530],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0480],\n",
      "        [0.0506]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0529],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0530],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0480],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0529],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0530],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0480],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0530],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0530],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0480],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0530],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0480],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0530],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0480],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0530],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0480],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0522],\n",
      "        [0.0530],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0480],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0530],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0530],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0530],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0530],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0530],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0530],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0487],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0530],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0488],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0530],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0488],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0530],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0488],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0530],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0488],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0530],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0531],\n",
      "        [0.0480],\n",
      "        [0.0488],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0530],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0480],\n",
      "        [0.0488],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0530],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0480],\n",
      "        [0.0488],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0531],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0480],\n",
      "        [0.0488],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0531],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0480],\n",
      "        [0.0488],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0507]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0531],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0480],\n",
      "        [0.0488],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0531],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0480],\n",
      "        [0.0488],\n",
      "        [0.0458],\n",
      "        [0.0481],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0531],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0480],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0481],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0531],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0480],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0481],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0523],\n",
      "        [0.0531],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0481],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0481],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0481],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0533],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0481],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0481],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0532],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0481],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0532],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0481],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0532],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0532],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0488],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0531],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0532],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0532],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0532],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0532],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0532],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0532],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0532],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0532],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0508]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0532],\n",
      "        [0.0534],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0532],\n",
      "        [0.0534],\n",
      "        [0.0535],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0524],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0533],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0481],\n",
      "        [0.0489],\n",
      "        [0.0459],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0489],\n",
      "        [0.0460],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0489],\n",
      "        [0.0460],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0489],\n",
      "        [0.0460],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0489],\n",
      "        [0.0460],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0489],\n",
      "        [0.0460],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0489],\n",
      "        [0.0460],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0489],\n",
      "        [0.0460],\n",
      "        [0.0482],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0489],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0489],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0489],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0489],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0489],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0535],\n",
      "        [0.0535],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0535],\n",
      "        [0.0536],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0535],\n",
      "        [0.0536],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0534],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0509]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0482],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0483],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0533],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0483],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0483],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0483],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0483],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0536],\n",
      "        [0.0536],\n",
      "        [0.0535],\n",
      "        [0.0483],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0536],\n",
      "        [0.0537],\n",
      "        [0.0535],\n",
      "        [0.0483],\n",
      "        [0.0490],\n",
      "        [0.0461],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0536],\n",
      "        [0.0537],\n",
      "        [0.0535],\n",
      "        [0.0483],\n",
      "        [0.0490],\n",
      "        [0.0461],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0536],\n",
      "        [0.0537],\n",
      "        [0.0535],\n",
      "        [0.0483],\n",
      "        [0.0490],\n",
      "        [0.0461],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0536],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0490],\n",
      "        [0.0461],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0490],\n",
      "        [0.0461],\n",
      "        [0.0483],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0526],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0510]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0534],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0537],\n",
      "        [0.0537],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0537],\n",
      "        [0.0538],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0537],\n",
      "        [0.0538],\n",
      "        [0.0536],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0537],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0537],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0537],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0483],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0537],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0537],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0461],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0484],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0527],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0538],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0539],\n",
      "        [0.0537],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0538],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0538],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0511]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0538],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0538],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0538],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0538],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0484],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0492],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0538],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0528],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0485],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0462],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0539],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0539],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0539],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0512]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0485],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0486],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0486],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0486],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0486],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0539],\n",
      "        [0.0486],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0493],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0529],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0486],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0487],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0487],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0487],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0487],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0463],\n",
      "        [0.0487],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0540],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0541],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0513]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0486],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0494],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0541],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0538],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0530],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0541],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0487],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0488],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0488],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Update tensor([[0.0531],\n",
      "        [0.0539],\n",
      "        [0.0542],\n",
      "        [0.0543],\n",
      "        [0.0542],\n",
      "        [0.0487],\n",
      "        [0.0495],\n",
      "        [0.0464],\n",
      "        [0.0488],\n",
      "        [0.0514]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/LSTMC_gamma_0.9\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m      9\u001b[0m meta_optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(lstm_optimizer\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m lstm_optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_LSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQuadraticOptimizee\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtheta0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta0\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/LSTMC_gamma_0.9\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m params \u001b[38;5;241m=\u001b[39m test_LSTM(lstm_optimizer, QuadraticOptimizee, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m: W, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheta0\u001b[39m\u001b[38;5;124m\"\u001b[39m: theta0}, time_horizon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, writer\u001b[38;5;241m=\u001b[39mwriter)\n",
      "Cell \u001b[1;32mIn[101], line 56\u001b[0m, in \u001b[0;36mtrain_LSTM\u001b[1;34m(lstm_optimizer, meta_optimizer, optimizee_class, optimizee_kwargs, num_optimizees, num_epochs, time_horizon, discount, scheduler, noise, writer)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m writer: writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m, cumulative_loss, epoch)\n\u001b[0;32m     55\u001b[0m meta_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 56\u001b[0m \u001b[43mcumulative_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# torch.nn.utils.clip_grad_norm_(lstm_optimizer.parameters(), 1)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Print gradients\u001b[39;00m\n\u001b[0;32m     59\u001b[0m meta_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\envs\\MLAI\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\envs\\MLAI\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "n = 10\n",
    "W = np.random.randn(n, n)\n",
    "theta0 = np.ones((n, 1))\n",
    "lstm_optimizer = LSTMConcurrent(num_optims=1)\n",
    "writer = SummaryWriter(\"train/LSTMC_gamma_0.9\") \n",
    "meta_optimizer = optim.Adam(lstm_optimizer.parameters(), lr=0.001)\n",
    "lstm_optimizer = train_LSTM(lstm_optimizer, meta_optimizer, QuadraticOptimizee, {\"W\": W, \"theta0\": theta0}, num_epochs=500, time_horizon=500, discount=0.9, writer=writer)\n",
    "writer = SummaryWriter(\"runs/LSTMC_gamma_0.9\")\n",
    "params = test_LSTM(lstm_optimizer, QuadraticOptimizee, {\"W\": W, \"theta0\": theta0}, time_horizon=1000, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a26274bf464feb9e72f226bd85f1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Shape torch.Size([10, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_26284\\3111178144.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(preprocessed).to(gradients.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Cumulative Loss: 86188.9375, LR: 1.000e-02\n",
      "Final parameters: [[31.855953 33.48319  33.22974  32.58021  31.841679 31.375471 32.790844\n",
      "  29.157654 30.33128  30.265963]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [2/500], Cumulative Loss: 35799.2578, LR: 1.000e-02\n",
      "Final parameters: [[-20.349451 -20.300594 -19.493969 -18.321798 -18.756596 -18.079155\n",
      "  -18.142967 -20.111877 -19.823696 -19.606356]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [3/500], Cumulative Loss: 10634.2646, LR: 1.000e-02\n",
      "Final parameters: [[-10.789026  -11.57954   -11.096596   -8.865726   -7.746987   -9.454046\n",
      "   -7.1986303 -10.252164  -14.621588  -12.600348 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [4/500], Cumulative Loss: 20.3428, LR: 1.000e-02\n",
      "Final parameters: [[ 0.47475934  2.2697022   2.1017098  -0.04158057 -1.129506   -1.1536789\n",
      "   1.8131113   0.4926201  -0.9938171   0.5147538 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [5/500], Cumulative Loss: 0.1866, LR: 1.000e-02\n",
      "Final parameters: [[0.8504492  0.83243    1.40349    1.0162997  0.713724   0.83900654\n",
      "  1.2859277  1.156668   0.7615006  1.2479255 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [6/500], Cumulative Loss: 0.4500, LR: 1.000e-02\n",
      "Final parameters: [[ 1.059195   -0.45202184  1.16623     0.97710526  2.6803677   2.1209183\n",
      "   0.64379656  1.5649978   1.9874305  -0.6719384 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [7/500], Cumulative Loss: 0.5404, LR: 1.000e-02\n",
      "Final parameters: [[1.2636749  1.0587332  0.4495077  0.9386288  1.5095491  1.3796889\n",
      "  0.6204478  0.9179998  1.4026829  0.67228687]]\n",
      "Param Shape torch.Size([10, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/LSTMC_gamma_0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m      9\u001b[0m meta_optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(lstm_optimizer\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m lstm_optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_LSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQuadraticOptimizee\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtheta0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta0\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/LSTMC_gamma_0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m params \u001b[38;5;241m=\u001b[39m test_LSTM(lstm_optimizer, QuadraticOptimizee, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m: W, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheta0\u001b[39m\u001b[38;5;124m\"\u001b[39m: theta0}, time_horizon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, writer\u001b[38;5;241m=\u001b[39mwriter)\n",
      "Cell \u001b[1;32mIn[57], line 44\u001b[0m, in \u001b[0;36mtrain_LSTM\u001b[1;34m(lstm_optimizer, meta_optimizer, optimizee_class, optimizee_kwargs, num_optimizees, num_epochs, time_horizon, discount, scheduler, noise, writer)\u001b[0m\n\u001b[0;32m     42\u001b[0m grad_params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(gradients)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# print(\"Grads\", grad_params.shape)\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m update, hidden_state \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# print(\"Update\", update.shape)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# print(\"Params\", params.shape)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m params \u001b[38;5;241m=\u001b[39m params \u001b[38;5;241m+\u001b[39m update\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\envs\\MLAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\envs\\MLAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[32], line 32\u001b[0m, in \u001b[0;36mLSTMConcurrent.forward\u001b[1;34m(self, x, hidden_state)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreproc: x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_gradients(x)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# print(\"Gradients\", x)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# print(\"Preprocess Shape\", x.shape)\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m out, hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(out)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out, hidden_state\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\envs\\MLAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\envs\\MLAI\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\envs\\MLAI\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "n = 10\n",
    "W = np.random.randn(n, n)\n",
    "theta0 = np.ones((n, 1))\n",
    "lstm_optimizer = LSTMConcurrent(num_optims=1)\n",
    "writer = SummaryWriter(\"train/LSTMC_gamma_0.1\") \n",
    "meta_optimizer = optim.Adam(lstm_optimizer.parameters(), lr=0.01)\n",
    "lstm_optimizer = train_LSTM(lstm_optimizer, meta_optimizer, QuadraticOptimizee, {\"W\": W, \"theta0\": theta0}, num_epochs=500, time_horizon=500, discount=0.1, writer=writer)\n",
    "writer = SummaryWriter(\"runs/LSTMC_gamma_0.1\")\n",
    "params = test_LSTM(lstm_optimizer, QuadraticOptimizee, {\"W\": W, \"theta0\": theta0}, time_horizon=1000, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2114df47e2f44caab366b2288b24f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Shape torch.Size([10, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_22104\\3647760373.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(preprocessed).to(gradients.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Cumulative Loss: 232685.3281, LR: 1.000e-03\n",
      "Final parameters: [[-56.50897  -53.47805  -52.255253 -51.560833 -51.361187 -45.479355\n",
      "  -51.359352 -51.721733 -57.24269  -58.77405 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [2/500], Cumulative Loss: 153203.7188, LR: 1.000e-03\n",
      "Final parameters: [[-47.433903 -42.08653  -42.588608 -41.05655  -37.881584 -36.20875\n",
      "  -42.903183 -41.539223 -48.43857  -48.30403 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [3/500], Cumulative Loss: 81233.2109, LR: 1.000e-03\n",
      "Final parameters: [[-35.26702  -31.748522 -29.824865 -28.165958 -25.296488 -26.418747\n",
      "  -30.976404 -31.502092 -38.265526 -37.463898]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [4/500], Cumulative Loss: 32433.4551, LR: 1.000e-03\n",
      "Final parameters: [[-23.400938 -19.127851 -17.509352 -14.425954 -13.55961  -14.45078\n",
      "  -21.089912 -20.442644 -26.89849  -25.322037]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [5/500], Cumulative Loss: 3792.1633, LR: 1.000e-03\n",
      "Final parameters: [[-10.182979   -6.414855   -3.258956   -2.8716278  -0.7790779  -1.4758364\n",
      "   -4.838936   -5.3778787 -12.401414  -12.342224 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [6/500], Cumulative Loss: 130.8751, LR: 1.000e-03\n",
      "Final parameters: [[ 0.22629637  4.87076     4.1842737   2.83242    -2.7268898  -2.876688\n",
      "  -2.0398078  -0.6240788  -3.6591864   0.23361254]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [7/500], Cumulative Loss: 25.3810, LR: 1.000e-03\n",
      "Final parameters: [[ 1.6273925  -1.3161285   1.7230146   0.29350257  0.58696634  2.4856238\n",
      "   1.5926781  -0.33263224  1.3720928   2.281254  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [8/500], Cumulative Loss: 4.5531, LR: 1.000e-03\n",
      "Final parameters: [[1.3416806  1.0722464  1.2628223  0.30991346 0.23254508 0.520597\n",
      "  1.0765777  1.0405027  0.0696686  2.17967   ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [9/500], Cumulative Loss: 1.5833, LR: 1.000e-03\n",
      "Final parameters: [[1.3756698  1.1263591  0.12404674 0.8123391  1.529354   1.0499794\n",
      "  1.1597167  0.4265393  1.1969936  1.3025913 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [10/500], Cumulative Loss: 0.2206, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1636206  -0.2855791   0.99043685  0.80824476  2.3019905   1.8792661\n",
      "   0.59113955  1.4532322   1.7951598  -0.23374772]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [11/500], Cumulative Loss: 52.6613, LR: 1.000e-03\n",
      "Final parameters: [[-1.5415815  -1.7724648   5.248803    3.2829893   0.12973984  1.0350559\n",
      "   2.573309    2.8606398   0.18846592  0.34584558]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [12/500], Cumulative Loss: 0.4356, LR: 1.000e-03\n",
      "Final parameters: [[1.3684317  1.9873594  0.28961027 1.0888596  0.9201572  0.90156996\n",
      "  0.6675812  0.5172636  1.0936155  1.4784753 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [13/500], Cumulative Loss: 0.2455, LR: 1.000e-03\n",
      "Final parameters: [[1.1289327  0.12376649 1.2846793  0.94178754 1.8912096  1.6709436\n",
      "  0.8292667  1.5130949  1.5515832  0.01971909]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [14/500], Cumulative Loss: 0.3980, LR: 1.000e-03\n",
      "Final parameters: [[1.0673269  0.18973362 1.2153585  0.9080164  1.6062704  1.449737\n",
      "  0.97148246 1.3731663  1.3554833  0.34854472]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [15/500], Cumulative Loss: 1.5185, LR: 1.000e-03\n",
      "Final parameters: [[1.452283   1.7597004  0.04902745 1.12442    1.5665984  1.4064806\n",
      "  0.51449263 0.5974318  1.5091763  0.9127514 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [16/500], Cumulative Loss: 0.3575, LR: 1.000e-03\n",
      "Final parameters: [[1.0391879  1.7319467  0.61873597 1.092123   0.71497977 0.810268\n",
      "  0.9277642  0.63887155 0.82005644 1.5038311 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [17/500], Cumulative Loss: 0.1203, LR: 1.000e-03\n",
      "Final parameters: [[1.0951802  1.9564446  0.42113608 1.0741045  0.59990406 0.69154966\n",
      "  0.8328917  0.4668464  0.8523715  1.6378282 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [18/500], Cumulative Loss: 0.1677, LR: 1.000e-03\n",
      "Final parameters: [[1.2105954  1.1900649  0.649145   1.0599124  1.4546717  1.3103585\n",
      "  0.63591254 0.85606587 1.3184817  0.5430663 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [19/500], Cumulative Loss: 0.0398, LR: 1.000e-03\n",
      "Final parameters: [[1.1079001  0.9859711  0.9019381  0.9721669  1.1049261  1.0277536\n",
      "  0.8407634  1.0077045  1.0957989  0.82951295]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [20/500], Cumulative Loss: 0.1413, LR: 1.000e-03\n",
      "Final parameters: [[ 0.97154075 -0.10959848  1.4864231   0.9520706   1.8400617   1.5952978\n",
      "   0.9944404   1.5472375   1.3945489  -0.05976852]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [21/500], Cumulative Loss: 0.0755, LR: 1.000e-03\n",
      "Final parameters: [[1.1179653  1.1777805  0.90491784 1.1088848  1.0834205  1.0874577\n",
      "  1.0800359  0.99986494 1.1519502  1.1717939 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [22/500], Cumulative Loss: 0.1382, LR: 1.000e-03\n",
      "Final parameters: [[1.0488195  1.976396   0.50437415 1.1805843  0.6538406  0.78108203\n",
      "  0.98772734 0.4656949  0.78885704 1.7286983 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [23/500], Cumulative Loss: 0.9305, LR: 1.000e-03\n",
      "Final parameters: [[0.8337372  0.27664804 1.2771457  0.88467693 1.2846562  1.1731029\n",
      "  1.0683066  1.3422391  1.127596   0.45752776]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [24/500], Cumulative Loss: 0.1808, LR: 1.000e-03\n",
      "Final parameters: [[1.2142439  2.608439   0.13679102 1.2170198  0.22432563 0.40277335\n",
      "  0.9406837  0.08932048 0.582433   2.2096415 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [25/500], Cumulative Loss: 0.1272, LR: 1.000e-03\n",
      "Final parameters: [[1.0130236  1.8220295  0.61235785 1.0267937  0.26828134 0.43300864\n",
      "  1.0514616  0.5423535  0.53897476 1.73342   ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [26/500], Cumulative Loss: 0.1836, LR: 1.000e-03\n",
      "Final parameters: [[0.94096047 0.14669116 1.3685569  0.84022504 1.395027   1.275673\n",
      "  1.0454841  1.4489626  1.235502   0.33309233]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [27/500], Cumulative Loss: 0.0699, LR: 1.000e-03\n",
      "Final parameters: [[0.9917396  1.3035996  0.99261844 1.1098094  0.8077275  0.83621275\n",
      "  1.155671   0.8848755  0.88569546 1.2778804 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [28/500], Cumulative Loss: 0.1314, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1824309   3.7978666  -0.20948261  1.2603904  -0.8472952  -0.34827143\n",
      "   0.96065986 -0.50516313 -0.06857429  3.1951494 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [29/500], Cumulative Loss: 0.2755, LR: 1.000e-03\n",
      "Final parameters: [[1.0067718  1.564304   0.66857177 1.0081944  0.66196316 0.6410889\n",
      "  0.8790375  0.56987643 0.746691   1.3464537 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [30/500], Cumulative Loss: 0.2541, LR: 1.000e-03\n",
      "Final parameters: [[0.9251978  0.26446223 1.3730924  0.94313157 1.6285743  1.3854436\n",
      "  0.9301861  1.3944306  1.3659508  0.30288297]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [31/500], Cumulative Loss: 0.9445, LR: 1.000e-03\n",
      "Final parameters: [[0.7488548  1.2309797  1.3657384  0.99378407 0.20594688 0.32957432\n",
      "  1.3691897  0.8906647  0.36883962 1.7215321 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [32/500], Cumulative Loss: 0.4324, LR: 1.000e-03\n",
      "Final parameters: [[ 0.9758885   2.4495676   0.5329991   1.1409692  -0.13093291  0.18000428\n",
      "   1.2217579   0.2979566   0.33995152  2.3891466 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [33/500], Cumulative Loss: 0.3421, LR: 1.000e-03\n",
      "Final parameters: [[ 0.8749991   1.9611704   0.8375528   1.0171874  -0.2634794   0.05302405\n",
      "   1.2214968   0.44634163  0.24005915  2.092285  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [34/500], Cumulative Loss: 0.2262, LR: 1.000e-03\n",
      "Final parameters: [[0.8165344  0.4171881  1.5930263  0.9502341  0.9544189  0.87894297\n",
      "  1.1572009  1.1618567  0.76444    0.5831814 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [35/500], Cumulative Loss: 0.3214, LR: 1.000e-03\n",
      "Final parameters: [[0.8794132  1.5838052  1.0463972  1.089167   0.3666973  0.55908346\n",
      "  1.222307   0.6607122  0.54520845 1.6468031 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [36/500], Cumulative Loss: 0.2033, LR: 1.000e-03\n",
      "Final parameters: [[0.8762055  1.567446   0.85614187 1.097644   0.52832717 0.59731984\n",
      "  1.0921168  0.64768744 0.6624789  1.5566496 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [37/500], Cumulative Loss: 0.0983, LR: 1.000e-03\n",
      "Final parameters: [[0.9991968  1.731195   0.7804133  1.0752722  0.47638762 0.50315183\n",
      "  0.988999   0.51486516 0.5110083  1.424193  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [38/500], Cumulative Loss: 1.1147, LR: 1.000e-03\n",
      "Final parameters: [[0.85490316 0.6516232  1.0584698  0.87925917 1.0254117  0.9216834\n",
      "  1.0341352  1.0470188  0.9671465  0.8287045 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [39/500], Cumulative Loss: 0.1681, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0475167   3.1166427  -0.08546878  1.0923023  -0.5094574  -0.08790839\n",
      "   0.99059314 -0.2480836   0.15128344  2.8595345 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [40/500], Cumulative Loss: 0.1038, LR: 1.000e-03\n",
      "Final parameters: [[0.8283469  0.920034   0.9892689  0.8927419  0.70757955 0.7940751\n",
      "  1.0038246  0.9206999  0.74542785 1.0186498 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [41/500], Cumulative Loss: 0.1185, LR: 1.000e-03\n",
      "Final parameters: [[1.1094767  2.0589752  0.49295118 1.0758748  0.2740846  0.4983108\n",
      "  1.0793083  0.5605359  0.65879923 1.903365  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [42/500], Cumulative Loss: 0.1152, LR: 1.000e-03\n",
      "Final parameters: [[0.9739382  0.9676042  0.8021276  0.86719    0.6879247  0.7981463\n",
      "  1.013603   0.95779276 0.8599652  1.1480193 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [43/500], Cumulative Loss: 0.1117, LR: 1.000e-03\n",
      "Final parameters: [[0.88245696 0.82043445 1.4386952  1.0180975  0.79346484 0.7758099\n",
      "  1.168744   1.0379628  0.74000055 1.0104848 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [44/500], Cumulative Loss: 0.0479, LR: 1.000e-03\n",
      "Final parameters: [[0.98213273 1.7786269  0.5304194  1.0324153  0.51529044 0.60152096\n",
      "  0.99832994 0.53513515 0.7840517  1.6972861 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [45/500], Cumulative Loss: 0.9473, LR: 1.000e-03\n",
      "Final parameters: [[ 0.75488555 -0.3804527   1.7425944   0.83409065  1.717391    1.3840942\n",
      "   1.0899339   1.6681979   1.1919918  -0.12618744]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [46/500], Cumulative Loss: 0.1514, LR: 1.000e-03\n",
      "Final parameters: [[ 9.8148978e-01  2.2324858e+00  2.2154009e-01  1.0295564e+00\n",
      "  -1.8666238e-03  2.6338306e-01  9.0450007e-01  2.1563689e-01\n",
      "   4.3225044e-01  1.9640625e+00]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [47/500], Cumulative Loss: 0.2386, LR: 1.000e-03\n",
      "Final parameters: [[ 1.2012877   3.4378793  -0.30412406  1.227936   -0.50408506 -0.067817\n",
      "   0.9650087  -0.3336656   0.19425705  3.0728922 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [48/500], Cumulative Loss: 0.1330, LR: 1.000e-03\n",
      "Final parameters: [[1.024939   0.5934761  1.161449   1.0709798  1.5748413  1.3621063\n",
      "  0.9878585  1.235031   1.3107854  0.39097124]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [49/500], Cumulative Loss: 0.2317, LR: 1.000e-03\n",
      "Final parameters: [[1.1085209  2.2665827  0.09187943 1.0067956  0.23133937 0.37895948\n",
      "  0.75228196 0.17006907 0.59738785 1.883669  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [50/500], Cumulative Loss: 0.4518, LR: 1.000e-03\n",
      "Final parameters: [[1.1205451  0.9062772  1.0233688  0.9258715  1.2090927  1.1624725\n",
      "  0.88993883 1.0915071  1.1665446  0.7488064 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [51/500], Cumulative Loss: 0.7464, LR: 1.000e-03\n",
      "Final parameters: [[0.82783103 0.23389944 1.4905933  0.9556769  1.236146   1.1740974\n",
      "  1.0897914  1.3511045  1.0242262  0.61235625]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [52/500], Cumulative Loss: 0.3603, LR: 1.000e-03\n",
      "Final parameters: [[0.9763286  1.8879588  0.54658955 1.0772009  0.12674111 0.39958864\n",
      "  0.9277646  0.37997118 0.4438967  1.796291  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [53/500], Cumulative Loss: 0.6302, LR: 1.000e-03\n",
      "Final parameters: [[0.954435   0.5000022  1.2210494  0.98807424 1.3677769  1.2916071\n",
      "  1.0639844  1.2893035  1.2034178  0.76192605]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [54/500], Cumulative Loss: 0.7543, LR: 1.000e-03\n",
      "Final parameters: [[1.0160494  1.7806973  0.8088786  1.0464659  0.38028824 0.52342\n",
      "  1.0710776  0.612516   0.57611513 1.8307426 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [55/500], Cumulative Loss: 0.1422, LR: 1.000e-03\n",
      "Final parameters: [[0.9970268  0.23070876 1.0156175  0.8411438  1.5007159  1.3094193\n",
      "  0.8123429  1.3362782  1.3379014  0.29449102]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [56/500], Cumulative Loss: 0.2472, LR: 1.000e-03\n",
      "Final parameters: [[0.99969006 1.5645003  0.6609942  1.1725773  0.79300404 0.87236124\n",
      "  0.99404776 0.67522043 0.91086316 1.4097279 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [57/500], Cumulative Loss: 0.4825, LR: 1.000e-03\n",
      "Final parameters: [[1.1114448  1.5456982  0.62195843 0.96725875 0.6327676  0.6961382\n",
      "  0.80095553 0.75454503 0.90955603 1.2957963 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [58/500], Cumulative Loss: 0.3386, LR: 1.000e-03\n",
      "Final parameters: [[1.1150122  0.7781527  1.0689543  0.86564255 1.1593151  1.2146119\n",
      "  0.9305428  1.280872   1.3448653  0.99056053]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [59/500], Cumulative Loss: 0.0570, LR: 1.000e-03\n",
      "Final parameters: [[0.94557375 1.461644   0.66941977 1.0312208  0.81755227 0.91367084\n",
      "  1.0302024  0.87210125 0.9577279  1.2872938 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [60/500], Cumulative Loss: 0.5574, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1691327   2.6206977   0.18796265  1.1216058  -0.12295897  0.20340978\n",
      "   0.9330082   0.19867848  0.4167517   2.3433824 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [61/500], Cumulative Loss: 0.6404, LR: 1.000e-03\n",
      "Final parameters: [[1.277214   1.4168353  0.688035   1.0297577  1.137471   1.1289709\n",
      "  0.83301157 0.84439725 1.0500457  1.090554  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [62/500], Cumulative Loss: 0.2036, LR: 1.000e-03\n",
      "Final parameters: [[1.1500541  2.1078463  0.1699239  1.0677537  0.528051   0.7155212\n",
      "  0.86753625 0.46538275 0.9005016  1.8792032 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [63/500], Cumulative Loss: 0.2223, LR: 1.000e-03\n",
      "Final parameters: [[0.99048173 1.9390912  0.25652623 1.0295607  0.45665297 0.65050864\n",
      "  0.6834637  0.32630163 0.6725796  1.5538042 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [64/500], Cumulative Loss: 0.6179, LR: 1.000e-03\n",
      "Final parameters: [[1.051768   1.0592953  0.88987    1.0299896  1.1211439  1.0700899\n",
      "  0.8956571  0.88941985 1.0268894  0.813168  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [65/500], Cumulative Loss: 0.0983, LR: 1.000e-03\n",
      "Final parameters: [[1.0131028  0.41442305 1.1589162  0.9613328  1.3734374  1.2162415\n",
      "  1.004117   1.2108779  1.0963712  0.5659528 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [66/500], Cumulative Loss: 0.4428, LR: 1.000e-03\n",
      "Final parameters: [[1.0389031  1.2780892  0.7155623  0.91053784 0.76127255 0.7930609\n",
      "  0.91584694 0.7169201  0.81478    1.1802613 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [67/500], Cumulative Loss: 0.2635, LR: 1.000e-03\n",
      "Final parameters: [[1.0869883  1.6086948  0.7728554  1.1523702  0.69977176 0.8405893\n",
      "  1.0668931  0.7310785  0.89978755 1.6306347 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [68/500], Cumulative Loss: 0.0443, LR: 1.000e-03\n",
      "Final parameters: [[ 0.80893755 -0.07315803  1.5661116   0.9108225   1.4947135   1.3440164\n",
      "   1.1095604   1.5272439   1.281037    0.38463026]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [69/500], Cumulative Loss: 0.0538, LR: 1.000e-03\n",
      "Final parameters: [[1.1039777  1.771845   0.60309386 1.0968783  0.5954232  0.61790913\n",
      "  0.8348249  0.47408706 0.57670313 1.3462583 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [70/500], Cumulative Loss: 0.2470, LR: 1.000e-03\n",
      "Final parameters: [[0.9630105 0.7705261 1.2028406 1.0176097 1.3423363 1.1199172 1.0790975\n",
      "  1.1282467 1.0331533 0.6856565]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [71/500], Cumulative Loss: 0.2270, LR: 1.000e-03\n",
      "Final parameters: [[0.91809183 0.9877871  1.0777503  0.9785553  0.78533185 0.90421134\n",
      "  1.1561818  1.0601766  0.875492   0.9416475 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [72/500], Cumulative Loss: 0.1140, LR: 1.000e-03\n",
      "Final parameters: [[0.94754255 1.6893753  0.7169217  1.0704921  0.57442856 0.59794974\n",
      "  0.9695856  0.54355395 0.6234575  1.4778752 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [73/500], Cumulative Loss: 0.1206, LR: 1.000e-03\n",
      "Final parameters: [[ 1.169219    3.984673   -0.30560368  1.319843   -0.9637313  -0.39783347\n",
      "   1.0109725  -0.4958747  -0.1103532   3.256801  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [74/500], Cumulative Loss: 0.2719, LR: 1.000e-03\n",
      "Final parameters: [[0.976903   2.134124   0.4591449  1.0486563  0.29522917 0.4313181\n",
      "  0.890353   0.23362914 0.46576193 1.6641233 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [75/500], Cumulative Loss: 0.2398, LR: 1.000e-03\n",
      "Final parameters: [[1.1085144  2.4812853  0.44911587 1.1619911  0.11585879 0.2586186\n",
      "  1.0488797  0.25364387 0.49463207 2.1751857 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [76/500], Cumulative Loss: 0.3518, LR: 1.000e-03\n",
      "Final parameters: [[1.0144365  1.5847709  0.6678985  0.9320881  0.34474164 0.5639668\n",
      "  1.0267204  0.626799   0.6434915  1.6697224 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [77/500], Cumulative Loss: 0.0686, LR: 1.000e-03\n",
      "Final parameters: [[ 1.241471    2.8324616   0.02105839  1.1766534  -0.11711439  0.18834089\n",
      "   0.96317124  0.01270124  0.36072156  2.4450755 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [78/500], Cumulative Loss: 0.1099, LR: 1.000e-03\n",
      "Final parameters: [[1.0047504 1.1413602 0.9503276 1.0393605 1.0222471 1.0119152 1.0922079\n",
      "  0.9108504 1.0466588 1.1002452]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [79/500], Cumulative Loss: 0.1357, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1373267   2.8609223   0.24271579  1.2251339  -0.03739187  0.2506796\n",
      "   1.0970414   0.07874221  0.4239702   2.5059652 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [80/500], Cumulative Loss: 0.4555, LR: 1.000e-03\n",
      "Final parameters: [[1.0222738  1.1236522  1.1963305  0.9722661  0.8794286  0.8687174\n",
      "  1.0595169  1.0270545  0.82627773 0.89926505]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [81/500], Cumulative Loss: 0.2749, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0972164   2.5958717   0.38682008  1.0995554  -0.1802864   0.07580961\n",
      "   0.97923684  0.12581879  0.30182198  2.2293315 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [82/500], Cumulative Loss: 0.4244, LR: 1.000e-03\n",
      "Final parameters: [[0.8810145  0.86539847 1.2328786  0.99830574 1.0702493  1.0376726\n",
      "  1.1200429  1.0044595  0.8643233  0.8714627 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [83/500], Cumulative Loss: 0.4485, LR: 1.000e-03\n",
      "Final parameters: [[ 0.8172652  -0.45317715  1.8542264   0.86913794  1.7717491   1.5278409\n",
      "   1.0716455   1.7637506   1.4083886  -0.05291884]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [84/500], Cumulative Loss: 0.2997, LR: 1.000e-03\n",
      "Final parameters: [[1.0865899  2.6860108  0.2651661  1.1725764  0.10864106 0.30936098\n",
      "  0.9751779  0.07267367 0.4432107  2.2627149 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [85/500], Cumulative Loss: 0.1407, LR: 1.000e-03\n",
      "Final parameters: [[0.88529116 2.1319525  0.34918535 0.97834843 0.00860246 0.2816013\n",
      "  0.95638186 0.27703393 0.36773014 1.9020262 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [86/500], Cumulative Loss: 0.3193, LR: 1.000e-03\n",
      "Final parameters: [[0.9200863  0.9785116  1.0597188  0.869539   0.81645906 0.77285516\n",
      "  1.0298707  0.9575622  0.8117558  1.0710461 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [87/500], Cumulative Loss: 0.2915, LR: 1.000e-03\n",
      "Final parameters: [[1.0033171  2.053783   0.6889414  1.13119    0.315965   0.50513583\n",
      "  1.0684032  0.49983975 0.49527484 1.6993526 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [88/500], Cumulative Loss: 0.5446, LR: 1.000e-03\n",
      "Final parameters: [[0.9622057  2.1308649  0.49251837 1.1136341  0.22849143 0.38326648\n",
      "  0.94573283 0.3258219  0.48380786 1.752235  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [89/500], Cumulative Loss: 0.0882, LR: 1.000e-03\n",
      "Final parameters: [[0.84759164 0.00224853 1.1940993  0.8433112  1.561146   1.319369\n",
      "  0.9532883  1.2481296  1.1606407  0.15431124]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [90/500], Cumulative Loss: 0.2560, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1196464   2.5292065   0.2524103   1.182655   -0.21755177  0.2418069\n",
      "   1.1965003   0.1365199   0.2841487   2.480458  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [91/500], Cumulative Loss: 0.1121, LR: 1.000e-03\n",
      "Final parameters: [[0.89431554 1.4766846  1.1394281  1.1660882  0.5850444  0.6226573\n",
      "  1.2021966  0.75733143 0.63598937 1.2773052 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [92/500], Cumulative Loss: 0.3991, LR: 1.000e-03\n",
      "Final parameters: [[1.0482067  0.94641674 0.9750707  0.8906546  0.9688878  0.9825492\n",
      "  0.9058784  0.9638114  1.0083336  0.92139816]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [93/500], Cumulative Loss: 0.2866, LR: 1.000e-03\n",
      "Final parameters: [[1.0957184  1.8768306  0.66497505 1.0684123  0.6651068  0.6545158\n",
      "  0.9532164  0.5701325  0.83664346 1.5797501 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [94/500], Cumulative Loss: 0.1925, LR: 1.000e-03\n",
      "Final parameters: [[ 1.066586    3.1485186   0.09410782  1.3228741  -0.10826217  0.10655241\n",
      "   1.0640936  -0.16949482  0.25815374  2.5888433 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [95/500], Cumulative Loss: 1.1462, LR: 1.000e-03\n",
      "Final parameters: [[0.8017195  0.6930363  1.2111399  0.8790195  0.8433423  0.81868315\n",
      "  1.0815523  1.1128991  0.8276459  0.92671126]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [96/500], Cumulative Loss: 0.3678, LR: 1.000e-03\n",
      "Final parameters: [[0.7156055  0.17819852 1.5069995  0.8693263  1.3529584  1.1726618\n",
      "  1.0414029  1.4193792  1.0365758  0.33634967]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [97/500], Cumulative Loss: 0.3519, LR: 1.000e-03\n",
      "Final parameters: [[1.0056995  1.9044924  0.4746492  1.0326     0.5484877  0.65419346\n",
      "  0.93911123 0.5850093  0.85186225 1.604446  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [98/500], Cumulative Loss: 0.3558, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0778685   3.0768642   0.0934405   1.2789253  -0.22524089  0.12528841\n",
      "   1.0736469  -0.17240813  0.3007743   2.6777432 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [99/500], Cumulative Loss: 0.3317, LR: 1.000e-03\n",
      "Final parameters: [[0.9307109  0.14286178 1.4517963  0.89432746 1.3606415  1.3194449\n",
      "  0.972038   1.3526465  1.131515   0.27834928]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [100/500], Cumulative Loss: 0.2178, LR: 1.000e-03\n",
      "Final parameters: [[1.1734825  1.9817425  0.44583735 1.0671208  0.41581446 0.5492041\n",
      "  0.843545   0.44032395 0.73960114 1.7226124 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [101/500], Cumulative Loss: 0.5369, LR: 1.000e-03\n",
      "Final parameters: [[1.090339   0.6164819  1.2977294  1.0296079  1.4096134  1.2217942\n",
      "  1.0138215  1.2286042  1.0945809  0.45221424]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [102/500], Cumulative Loss: 0.0465, LR: 1.000e-03\n",
      "Final parameters: [[0.92122614 0.8073529  1.2022353  1.0668417  1.2695475  1.1909945\n",
      "  1.0937107  1.2013767  1.1809378  0.8985294 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [103/500], Cumulative Loss: 0.1333, LR: 1.000e-03\n",
      "Final parameters: [[0.99329317 1.5775672  0.71993107 0.97843677 0.46612406 0.63802797\n",
      "  0.9973085  0.7231723  0.7678577  1.5708612 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [104/500], Cumulative Loss: 0.1592, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0502363   2.6086915   0.35166293  1.1292441  -0.1684812   0.08663628\n",
      "   1.0892338   0.240248    0.30776608  2.2554085 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [105/500], Cumulative Loss: 0.2550, LR: 1.000e-03\n",
      "Final parameters: [[0.9855988  1.427744   0.8664574  0.9908592  0.5620021  0.62753785\n",
      "  1.0092101  0.7569516  0.6363137  1.329711  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [106/500], Cumulative Loss: 0.4379, LR: 1.000e-03\n",
      "Final parameters: [[1.0091131  1.6078433  0.7055881  1.1190268  1.0498606  0.90544724\n",
      "  0.9212334  0.58808184 0.9399257  1.2256503 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [107/500], Cumulative Loss: 0.9578, LR: 1.000e-03\n",
      "Final parameters: [[1.1194115  1.4733884  0.7389575  1.0446173  0.88832736 0.9111382\n",
      "  1.0047747  0.82513434 1.0801468  1.3668716 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [108/500], Cumulative Loss: 0.0134, LR: 1.000e-03\n",
      "Final parameters: [[0.8914734  0.9189643  0.9634345  1.0801334  1.244717   1.1257898\n",
      "  0.95872396 1.0056596  1.1521467  0.99736863]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [109/500], Cumulative Loss: 0.8017, LR: 1.000e-03\n",
      "Final parameters: [[0.8540002  0.7281157  1.1653132  0.8837918  0.8957107  0.9334215\n",
      "  0.88819355 1.0902004  0.95235705 0.8986664 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [110/500], Cumulative Loss: 1.3340, LR: 1.000e-03\n",
      "Final parameters: [[1.2723761  2.5859892  0.1452806  1.0999359  0.22181538 0.49981532\n",
      "  0.89208394 0.25179738 0.74885786 2.204264  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [111/500], Cumulative Loss: 0.3654, LR: 1.000e-03\n",
      "Final parameters: [[1.0876274  0.87161994 0.6549653  0.98025024 1.2710823  1.209082\n",
      "  0.7199914  1.0256444  1.3369106  0.677481  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [112/500], Cumulative Loss: 0.5480, LR: 1.000e-03\n",
      "Final parameters: [[1.1996355  1.8467524  0.48672295 1.1226087  0.88216627 0.91004646\n",
      "  0.98535377 0.7287381  1.0547271  1.5175103 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [113/500], Cumulative Loss: 0.3218, LR: 1.000e-03\n",
      "Final parameters: [[ 1.089304   -0.3955825   1.3423061   0.7745288   1.9143624   1.7122333\n",
      "   0.62695944  1.7595441   1.6772735  -0.16076994]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [114/500], Cumulative Loss: 0.2106, LR: 1.000e-03\n",
      "Final parameters: [[1.2969012  1.8088394  0.4239042  1.0534717  0.67220724 0.83505285\n",
      "  0.7937814  0.5304389  1.0138057  1.6464972 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [115/500], Cumulative Loss: 0.5943, LR: 1.000e-03\n",
      "Final parameters: [[1.0020813  0.33869365 1.1766202  1.0721481  1.551398   1.4794457\n",
      "  0.95713544 1.2947624  1.4045739  0.67957467]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [116/500], Cumulative Loss: 0.9550, LR: 1.000e-03\n",
      "Final parameters: [[1.1404591  2.2375648  0.48109743 1.223353   0.55539834 0.69460624\n",
      "  1.0282975  0.47906333 0.81391364 1.6833038 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [117/500], Cumulative Loss: 0.4214, LR: 1.000e-03\n",
      "Final parameters: [[1.0844958  1.168407   0.97840834 1.1188639  1.2688785  1.2125193\n",
      "  1.1604269  1.0599364  1.1401185  1.0441158 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [118/500], Cumulative Loss: 0.7090, LR: 1.000e-03\n",
      "Final parameters: [[0.97932005 0.15435223 1.5129671  1.0196815  1.8504095  1.617319\n",
      "  0.9270823  1.613466   1.5222461  0.22078557]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [119/500], Cumulative Loss: 0.4290, LR: 1.000e-03\n",
      "Final parameters: [[1.1936975  2.2923594  0.6349921  1.150295   0.28579843 0.4383712\n",
      "  0.92660934 0.29151228 0.44901475 1.8253183 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [120/500], Cumulative Loss: 0.6958, LR: 1.000e-03\n",
      "Final parameters: [[1.2640952  1.0699849  0.4387322  0.88290143 1.3943503  1.3087773\n",
      "  0.40029818 0.9152664  1.3911624  0.6656591 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [121/500], Cumulative Loss: 0.4709, LR: 1.000e-03\n",
      "Final parameters: [[0.98112077 0.38134772 0.99410474 1.0176876  1.6364442  1.5903733\n",
      "  0.794118   1.2625732  1.5488442  0.46067134]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [122/500], Cumulative Loss: 0.1004, LR: 1.000e-03\n",
      "Final parameters: [[1.0885102  0.8945727  0.89233786 1.0769222  1.4690064  1.342535\n",
      "  0.81551135 0.9439009  1.2619032  0.7463946 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [123/500], Cumulative Loss: 0.3677, LR: 1.000e-03\n",
      "Final parameters: [[0.9983392  0.8896146  0.79740375 0.9754155  1.3627284  1.3113015\n",
      "  0.8002915  0.9280343  1.1736029  0.6959063 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [124/500], Cumulative Loss: 2.0110, LR: 1.000e-03\n",
      "Final parameters: [[1.1271981  0.717882   1.1724812  1.0483441  1.5271187  1.5141903\n",
      "  0.81427205 1.2514287  1.3781958  0.40234476]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [125/500], Cumulative Loss: 0.5446, LR: 1.000e-03\n",
      "Final parameters: [[1.1409161  1.9935749  0.40972444 1.1436633  0.6150327  0.7033666\n",
      "  0.97149587 0.5093627  0.8381907  1.9552945 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [126/500], Cumulative Loss: 0.1490, LR: 1.000e-03\n",
      "Final parameters: [[1.0862848  0.5886724  1.1461725  1.0088705  1.514728   1.3778312\n",
      "  0.82279676 1.2099249  1.3031758  0.41650432]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [127/500], Cumulative Loss: 1.1819, LR: 1.000e-03\n",
      "Final parameters: [[1.165916   1.0723124  0.9052136  0.9615766  0.99448323 1.0565903\n",
      "  0.75539625 0.97455955 1.086435   0.9856733 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [128/500], Cumulative Loss: 0.3338, LR: 1.000e-03\n",
      "Final parameters: [[1.342211   0.41504878 1.1015596  0.930868   1.9564003  1.8410225\n",
      "  0.6064972  1.490156   1.9207977  0.14385483]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [129/500], Cumulative Loss: 1.1960, LR: 1.000e-03\n",
      "Final parameters: [[1.0271587  0.34574303 1.0347041  0.95528907 1.8053979  1.4951345\n",
      "  0.8799732  1.2734059  1.5508754  0.3797085 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [130/500], Cumulative Loss: 0.4416, LR: 1.000e-03\n",
      "Final parameters: [[0.9714006  0.5626895  1.0264258  0.8675723  1.2211375  1.1163118\n",
      "  0.694048   1.0609609  1.1453745  0.60596555]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [131/500], Cumulative Loss: 0.3676, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1188319  -0.46311513  1.1841004   0.71799886  2.0499766   1.8498931\n",
      "   0.6396154   1.8051676   1.8895993  -0.17091672]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [132/500], Cumulative Loss: 0.2229, LR: 1.000e-03\n",
      "Final parameters: [[1.2191114  0.8458556  0.8265408  0.9774409  1.5516585  1.4386927\n",
      "  0.78779763 1.1228403  1.440366   0.47660267]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [133/500], Cumulative Loss: 0.4431, LR: 1.000e-03\n",
      "Final parameters: [[0.87908953 0.33337066 1.2788761  0.94588333 1.2318742  1.3009928\n",
      "  0.9645996  1.3713964  1.190371   0.40918118]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [134/500], Cumulative Loss: 0.2846, LR: 1.000e-03\n",
      "Final parameters: [[1.1593453  1.6911519  0.23178084 0.99115145 0.7154003  0.84337324\n",
      "  0.6436962  0.51820135 1.0098157  1.4488482 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [135/500], Cumulative Loss: 0.0686, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0848027   2.7821946  -0.18089443  1.1728926   0.21635437  0.479667\n",
      "   0.7744774  -0.16030245  0.6284199   2.4172142 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [136/500], Cumulative Loss: 0.5404, LR: 1.000e-03\n",
      "Final parameters: [[1.0591985  2.1553843  0.37461203 1.0242642  0.3585413  0.4300134\n",
      "  0.9521374  0.3932453  0.71774745 1.846621  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [137/500], Cumulative Loss: 0.0827, LR: 1.000e-03\n",
      "Final parameters: [[0.8461309  0.8101258  1.0952361  0.93772316 1.097004   1.0484664\n",
      "  0.9863787  1.1161873  1.1486391  0.99871516]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [138/500], Cumulative Loss: 0.2035, LR: 1.000e-03\n",
      "Final parameters: [[1.253875   2.5192366  0.31330714 1.2429878  0.3121139  0.55029225\n",
      "  0.94580257 0.27879208 0.6269227  2.093812  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [139/500], Cumulative Loss: 0.0862, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1058695   2.6576004  -0.01962508  1.1089082   0.14264837  0.4750634\n",
      "   0.9379095   0.16550645  0.6520517   2.3184648 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [140/500], Cumulative Loss: 0.3615, LR: 1.000e-03\n",
      "Final parameters: [[1.1331568  2.4367316  0.27337718 1.1651837  0.21591406 0.5133078\n",
      "  0.9754281  0.36256394 0.6692058  1.9380821 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [141/500], Cumulative Loss: 1.2730, LR: 1.000e-03\n",
      "Final parameters: [[1.175765   2.003749   0.3979707  1.1020739  0.6996124  0.7976854\n",
      "  0.79269284 0.4593139  0.8343196  1.6401739 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [142/500], Cumulative Loss: 0.1337, LR: 1.000e-03\n",
      "Final parameters: [[0.9971788  1.6999797  0.79853004 1.1375481  0.48689047 0.67964697\n",
      "  1.1832026  0.74883306 0.6429013  1.4239271 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [143/500], Cumulative Loss: 0.1795, LR: 1.000e-03\n",
      "Final parameters: [[1.1357613  1.5584848  0.28133228 0.94112504 0.7214342  0.8374813\n",
      "  0.6924512  0.58628786 1.0731719  1.3901916 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [144/500], Cumulative Loss: 0.1673, LR: 1.000e-03\n",
      "Final parameters: [[0.9209738 0.6771996 1.1714346 0.8979225 1.2107869 1.2264661 0.9629061\n",
      "  1.1820372 1.1194997 0.7222452]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [145/500], Cumulative Loss: 0.4249, LR: 1.000e-03\n",
      "Final parameters: [[1.1135633  1.4748248  0.9612891  1.1326334  0.6955679  0.86177194\n",
      "  1.030032   0.87063956 0.8804298  1.4812974 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [146/500], Cumulative Loss: 0.0864, LR: 1.000e-03\n",
      "Final parameters: [[0.9173839  0.10852162 1.6912032  1.0476255  1.7350751  1.4736394\n",
      "  0.98858404 1.5604358  1.3282921  0.09088321]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [147/500], Cumulative Loss: 0.8046, LR: 1.000e-03\n",
      "Final parameters: [[0.8650291  0.2640341  1.0534573  0.90069705 1.5439552  1.4441934\n",
      "  0.90430295 1.2942038  1.3166785  0.36854142]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [148/500], Cumulative Loss: 0.1986, LR: 1.000e-03\n",
      "Final parameters: [[0.9564688  1.0653496  1.3309988  1.0977422  0.91071904 0.95697594\n",
      "  1.2651203  1.0654864  0.9056075  1.2422853 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [149/500], Cumulative Loss: 0.5091, LR: 1.000e-03\n",
      "Final parameters: [[1.0124576  0.8331275  0.88979256 1.1308544  1.5259054  1.3569673\n",
      "  1.0756507  1.049726   1.2995098  0.85909307]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [150/500], Cumulative Loss: 0.0789, LR: 1.000e-03\n",
      "Final parameters: [[1.2089461  0.85276675 0.8393656  0.99805355 1.3810905  1.360668\n",
      "  0.8104019  1.0835534  1.3114086  0.688018  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [151/500], Cumulative Loss: 1.3268, LR: 1.000e-03\n",
      "Final parameters: [[1.0886698 0.8206256 1.0511265 0.9353893 1.3367254 1.195962  0.8610159\n",
      "  1.1069472 1.2150708 0.5201164]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [152/500], Cumulative Loss: 1.0600, LR: 1.000e-03\n",
      "Final parameters: [[1.3181212  2.8826146  0.15211654 1.1730993  0.07951088 0.40848973\n",
      "  0.7840276  0.10156055 0.52844477 2.3639827 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [153/500], Cumulative Loss: 0.1330, LR: 1.000e-03\n",
      "Final parameters: [[1.1254077  0.17879629 1.2316614  0.8206836  1.4456872  1.3941557\n",
      "  0.87587374 1.4780716  1.354652   0.3738813 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [154/500], Cumulative Loss: 0.2538, LR: 1.000e-03\n",
      "Final parameters: [[1.1198077  2.0454886  0.47797525 1.2649693  0.64112693 0.7431767\n",
      "  1.1700869  0.52827245 0.7887758  1.7756162 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [155/500], Cumulative Loss: 0.8768, LR: 1.000e-03\n",
      "Final parameters: [[1.195333   1.9347763  0.21237351 1.0710502  0.64908254 0.86661947\n",
      "  0.85287476 0.45086837 0.9897472  1.6176126 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [156/500], Cumulative Loss: 0.1315, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1267364   2.463473   -0.10144656  1.0035828   0.00663734  0.2918241\n",
      "   0.8954182   0.12466531  0.51255476  2.3431869 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [157/500], Cumulative Loss: 0.2442, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0844259   2.28318    -0.01182921  1.1723086   0.5510717   0.67904913\n",
      "   0.79234207  0.22106904  0.88039535  2.078632  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [158/500], Cumulative Loss: 0.2140, LR: 1.000e-03\n",
      "Final parameters: [[0.82879156 1.5597752  0.7891695  1.0549837  0.40658686 0.6226447\n",
      "  1.1904193  0.7404972  0.69722223 1.6696836 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [159/500], Cumulative Loss: 1.0960, LR: 1.000e-03\n",
      "Final parameters: [[1.088293   2.5118842  0.29087856 1.2075214  0.04769459 0.32365054\n",
      "  0.96192116 0.18671626 0.45712143 2.2777615 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [160/500], Cumulative Loss: 0.4426, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1740062   2.6341305   0.08766522  1.1727955  -0.04320795  0.35266376\n",
      "   0.96549946  0.08260649  0.50477165  2.365877  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [161/500], Cumulative Loss: 0.7165, LR: 1.000e-03\n",
      "Final parameters: [[0.97051156 1.9561764  0.4351776  1.1093156  0.41070774 0.6786083\n",
      "  0.9142389  0.5165658  0.80934864 1.8252578 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [162/500], Cumulative Loss: 0.2573, LR: 1.000e-03\n",
      "Final parameters: [[1.1630275  1.1641055  0.82106775 1.1668868  1.3147173  1.256546\n",
      "  1.0282913  0.9752573  1.1804444  0.99987864]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [163/500], Cumulative Loss: 0.0886, LR: 1.000e-03\n",
      "Final parameters: [[1.3550214  2.442853   0.30953938 1.1988044  0.34547108 0.51492226\n",
      "  0.972445   0.2343016  0.55250293 2.0197556 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [164/500], Cumulative Loss: 0.9933, LR: 1.000e-03\n",
      "Final parameters: [[1.0386463 1.3379488 0.7186737 1.1108639 1.0102928 1.0321141 0.9736686\n",
      "  0.8798753 1.0834851 1.180609 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [165/500], Cumulative Loss: 0.2098, LR: 1.000e-03\n",
      "Final parameters: [[0.9777409  0.7016273  0.91711456 0.9196963  1.0804366  1.0326486\n",
      "  0.8786706  1.1224438  1.0959439  0.6781837 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [166/500], Cumulative Loss: 1.6547, LR: 1.000e-03\n",
      "Final parameters: [[1.0747532  1.1912876  0.9813585  1.0672722  1.0947454  1.1321403\n",
      "  0.986194   1.0306172  1.0847417  0.83945334]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [167/500], Cumulative Loss: 1.0054, LR: 1.000e-03\n",
      "Final parameters: [[1.1782854  1.9460317  0.48229712 1.1266155  0.5194588  0.64811915\n",
      "  1.0611157  0.47675553 0.8211663  1.964688  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [168/500], Cumulative Loss: 0.2515, LR: 1.000e-03\n",
      "Final parameters: [[1.133665   1.9403687  0.14443853 0.97882783 0.48016244 0.57092696\n",
      "  0.7639266  0.351029   0.7357656  1.5635983 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [169/500], Cumulative Loss: 0.1878, LR: 1.000e-03\n",
      "Final parameters: [[1.021114   2.5292609  0.0906502  1.0118916  0.06962448 0.2959098\n",
      "  0.73396826 0.02732076 0.46862677 1.9674397 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [170/500], Cumulative Loss: 0.0474, LR: 1.000e-03\n",
      "Final parameters: [[0.9716819  2.3306844  0.47120085 1.1302618  0.15188116 0.55096585\n",
      "  1.0626026  0.47323328 0.67359    2.1780224 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [171/500], Cumulative Loss: 0.1946, LR: 1.000e-03\n",
      "Final parameters: [[1.0520446  2.162646   0.59921646 1.2037072  0.28342533 0.5575611\n",
      "  1.1947414  0.5203767  0.6890078  2.086436  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [172/500], Cumulative Loss: 0.1237, LR: 1.000e-03\n",
      "Final parameters: [[ 1.346374    2.926456   -0.06662118  1.3004965   0.5247995   0.5771286\n",
      "   0.84749883  0.03393959  0.80055577  2.118491  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [173/500], Cumulative Loss: 0.2238, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1307694   2.8893647  -0.29174566  1.1214459  -0.01463979  0.2882638\n",
      "   0.8370006  -0.0530372   0.4599704   2.3019483 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [174/500], Cumulative Loss: 0.5344, LR: 1.000e-03\n",
      "Final parameters: [[1.1428694  1.5130843  0.6955527  1.0217444  0.85864884 0.8495412\n",
      "  0.7228336  0.747421   0.9874005  1.030402  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [175/500], Cumulative Loss: 0.0434, LR: 1.000e-03\n",
      "Final parameters: [[1.0699053  1.1054229  0.9145884  0.89128906 0.7747557  0.8638625\n",
      "  0.9322792  0.8982867  0.8175396  0.97039014]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [176/500], Cumulative Loss: 1.0117, LR: 1.000e-03\n",
      "Final parameters: [[0.9730621  0.00972608 1.461285   0.9273422  1.839963   1.5602888\n",
      "  0.8618082  1.5396012  1.4110186  0.08390567]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [177/500], Cumulative Loss: 0.6660, LR: 1.000e-03\n",
      "Final parameters: [[0.8343231  0.43491858 1.0128834  0.837437   1.1696222  1.1292555\n",
      "  1.1000224  1.2812595  1.2271643  0.70453507]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [178/500], Cumulative Loss: 0.2242, LR: 1.000e-03\n",
      "Final parameters: [[1.1239785  1.5481911  0.67301357 1.1690453  0.8787649  1.0042169\n",
      "  0.960439   0.6970529  0.9579962  1.2626054 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [179/500], Cumulative Loss: 0.1455, LR: 1.000e-03\n",
      "Final parameters: [[1.0608158 1.0818889 1.2383449 1.1434298 1.1304711 1.0630354 1.0958929\n",
      "  1.0896659 1.0901428 1.0312619]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [180/500], Cumulative Loss: 0.0918, LR: 1.000e-03\n",
      "Final parameters: [[1.1297702 0.7051615 1.0799693 1.0365548 1.366756  1.3136809 0.9849791\n",
      "  1.2417091 1.2263021 0.5915098]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [181/500], Cumulative Loss: 0.2071, LR: 1.000e-03\n",
      "Final parameters: [[1.1480944  0.08146635 1.519398   0.98122257 1.6372056  1.4666996\n",
      "  0.8828741  1.5002753  1.327445   0.12655188]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [182/500], Cumulative Loss: 0.3875, LR: 1.000e-03\n",
      "Final parameters: [[1.1223342  1.2831287  0.93958455 1.1409397  1.1072252  1.1217757\n",
      "  0.88123304 0.9350946  1.0286617  1.0245584 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [183/500], Cumulative Loss: 0.6408, LR: 1.000e-03\n",
      "Final parameters: [[0.9153522  0.14315271 1.3864255  0.8281232  1.4446669  1.2461782\n",
      "  0.9261862  1.3473889  1.1925522  0.04430624]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [184/500], Cumulative Loss: 0.1440, LR: 1.000e-03\n",
      "Final parameters: [[0.9860267  0.9423118  0.8035499  0.9357366  0.84890634 0.922403\n",
      "  0.9965639  0.90918434 0.8989026  1.066337  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [185/500], Cumulative Loss: 0.3017, LR: 1.000e-03\n",
      "Final parameters: [[0.97402024 1.3084989  0.65520805 1.0319308  0.94481295 0.91832846\n",
      "  0.8798528  0.5961587  0.9192115  1.2601624 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [186/500], Cumulative Loss: 0.4381, LR: 1.000e-03\n",
      "Final parameters: [[0.9396565  0.9495779  0.7919812  0.8816686  1.0334258  0.9597942\n",
      "  0.830653   0.92093796 0.95135784 0.8641347 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [187/500], Cumulative Loss: 0.6202, LR: 1.000e-03\n",
      "Final parameters: [[1.043579  1.0298417 0.9996153 1.0117829 1.2569705 1.0840275 1.0457429\n",
      "  1.0828424 1.1268024 1.0619653]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [188/500], Cumulative Loss: 1.0436, LR: 1.000e-03\n",
      "Final parameters: [[0.8782683  1.3356329  0.7540661  1.0191954  0.76038367 0.80819994\n",
      "  0.9264549  0.7930429  0.8918747  1.2059722 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [189/500], Cumulative Loss: 0.2386, LR: 1.000e-03\n",
      "Final parameters: [[1.0799797  2.3781333  0.305229   1.2625443  0.13468027 0.38341004\n",
      "  1.0137818  0.20125204 0.4123754  2.029508  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [190/500], Cumulative Loss: 0.1802, LR: 1.000e-03\n",
      "Final parameters: [[0.9661721  2.1923795  0.19799632 1.0549226  0.3187311  0.5430635\n",
      "  0.98628527 0.33748108 0.71049833 1.9038051 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [191/500], Cumulative Loss: 0.6776, LR: 1.000e-03\n",
      "Final parameters: [[0.8701817  1.4834521  0.6884823  0.96596706 0.39607567 0.5391037\n",
      "  1.0733639  0.62910736 0.54094386 1.406618  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [192/500], Cumulative Loss: 0.4334, LR: 1.000e-03\n",
      "Final parameters: [[0.8230213  1.3231337  0.90716183 0.97986424 0.49798155 0.57536834\n",
      "  0.950256   0.7554877  0.5937674  1.2436861 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [193/500], Cumulative Loss: 0.2967, LR: 1.000e-03\n",
      "Final parameters: [[0.98303497 1.3110961  0.59805804 1.013757   1.1376129  1.0637146\n",
      "  0.83865    0.7853862  1.1362418  1.1073997 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [194/500], Cumulative Loss: 0.3200, LR: 1.000e-03\n",
      "Final parameters: [[1.0632342  1.6526864  0.6761937  0.9592289  0.5858609  0.6407791\n",
      "  0.8913673  0.57139605 0.80294    1.5125839 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [195/500], Cumulative Loss: 0.1433, LR: 1.000e-03\n",
      "Final parameters: [[0.8604585  1.3594745  0.68585277 0.91609323 0.5112929  0.6371671\n",
      "  0.937734   0.63328254 0.60543793 1.3841094 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [196/500], Cumulative Loss: 0.2824, LR: 1.000e-03\n",
      "Final parameters: [[0.89812654 1.4886132  0.7159631  0.9877871  0.6419068  0.67632\n",
      "  0.9991879  0.665193   0.70023894 1.352886  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [197/500], Cumulative Loss: 0.3173, LR: 1.000e-03\n",
      "Final parameters: [[0.9218064  0.8791216  0.98881155 0.88412    0.66927266 0.8149473\n",
      "  0.90931475 0.92585295 0.8011037  0.87781775]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [198/500], Cumulative Loss: 0.1794, LR: 1.000e-03\n",
      "Final parameters: [[0.916632   2.252653   0.80375487 1.2624243  0.0826315  0.32850385\n",
      "  1.2925053  0.3812391  0.2846293  1.8908958 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [199/500], Cumulative Loss: 0.3310, LR: 1.000e-03\n",
      "Final parameters: [[0.90078914 2.250164   0.24601421 1.0013719  0.01013857 0.21536282\n",
      "  0.81050336 0.11644745 0.3620969  1.7440963 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [200/500], Cumulative Loss: 1.6015, LR: 1.000e-03\n",
      "Final parameters: [[0.8842397  1.0248748  0.9786347  1.023696   1.1372178  0.93207836\n",
      "  0.8407638  0.7967813  0.92358786 0.7833052 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [201/500], Cumulative Loss: 0.2776, LR: 1.000e-03\n",
      "Final parameters: [[0.91184664 0.38010687 1.2510651  0.8749776  1.3329805  1.1829287\n",
      "  0.92416334 1.2790657  1.1251214  0.32803646]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [202/500], Cumulative Loss: 0.4278, LR: 1.000e-03\n",
      "Final parameters: [[0.9476446  1.3283609  0.9662741  1.0889074  0.8227087  0.8319526\n",
      "  1.06132    0.7965242  0.81982017 1.1772711 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [203/500], Cumulative Loss: 1.0704, LR: 1.000e-03\n",
      "Final parameters: [[0.8347645  0.6559195  1.2405025  0.94222546 1.0912639  0.9831338\n",
      "  0.9598199  1.1539488  1.0009592  0.5883091 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [204/500], Cumulative Loss: 0.1664, LR: 1.000e-03\n",
      "Final parameters: [[1.0155774  0.86968315 1.2068137  1.0447291  1.019188   1.0366199\n",
      "  1.0218291  1.0961467  0.9926998  0.76585877]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [205/500], Cumulative Loss: 0.3929, LR: 1.000e-03\n",
      "Final parameters: [[1.0799463  2.261628   0.72345823 1.1433847  0.16779086 0.37028015\n",
      "  1.1485083  0.4422727  0.5681527  2.1939516 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [206/500], Cumulative Loss: 1.4692, LR: 1.000e-03\n",
      "Final parameters: [[1.1099718  2.3116062  0.1971947  1.1633475  0.43642554 0.6482453\n",
      "  0.7710553  0.24035797 0.7434885  1.8219559 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [207/500], Cumulative Loss: 0.9611, LR: 1.000e-03\n",
      "Final parameters: [[ 0.9848032  -0.39034677  1.8349462   0.7723119   1.7120498   1.4584605\n",
      "   1.0292574   1.7339623   1.3342265  -0.11394166]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [208/500], Cumulative Loss: 0.8161, LR: 1.000e-03\n",
      "Final parameters: [[ 0.8384384  -0.10198119  1.7306476   0.9595032   1.7339274   1.5850986\n",
      "   1.1074435   1.6200277   1.3148991   0.0835029 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [209/500], Cumulative Loss: 0.7107, LR: 1.000e-03\n",
      "Final parameters: [[1.001051   0.9785133  0.971614   0.98161113 0.5657253  0.7406233\n",
      "  0.96026236 0.8412087  0.7029354  1.1863794 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [210/500], Cumulative Loss: 0.1012, LR: 1.000e-03\n",
      "Final parameters: [[ 1.301354    3.1464896  -0.26493534  1.286657    0.13704458  0.29752958\n",
      "   0.77444035 -0.19949088  0.5825837   2.456623  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [211/500], Cumulative Loss: 0.0815, LR: 1.000e-03\n",
      "Final parameters: [[ 0.8871522  -0.15309688  1.4938698   0.7314035   1.6371535   1.4150206\n",
      "   0.7942671   1.5741018   1.3783715  -0.13807154]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [212/500], Cumulative Loss: 0.1992, LR: 1.000e-03\n",
      "Final parameters: [[1.0818543  1.5259746  0.5544254  1.1276864  1.0108526  0.99906725\n",
      "  1.0000657  0.71851724 1.1142002  1.4049327 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [213/500], Cumulative Loss: 0.2434, LR: 1.000e-03\n",
      "Final parameters: [[1.0672188 0.9397065 0.9813133 1.0737627 1.195174  1.1809112 1.0202098\n",
      "  1.0336502 1.123888  0.7613552]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [214/500], Cumulative Loss: 0.1270, LR: 1.000e-03\n",
      "Final parameters: [[0.9607956  0.2098766  1.3958675  0.96007484 1.4762738  1.4104106\n",
      "  0.9658333  1.4454106  1.1992137  0.3365385 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [215/500], Cumulative Loss: 0.8707, LR: 1.000e-03\n",
      "Final parameters: [[1.2869436  2.605432   0.33618504 1.1766045  0.2673049  0.4875279\n",
      "  0.99117714 0.259916   0.61132    1.9869878 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [216/500], Cumulative Loss: 0.3261, LR: 1.000e-03\n",
      "Final parameters: [[1.1570351  1.811324   0.6119889  1.086394   0.59371334 0.69057477\n",
      "  0.9438596  0.69805574 0.82941514 1.5834    ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [217/500], Cumulative Loss: 0.2915, LR: 1.000e-03\n",
      "Final parameters: [[1.0854264  1.0139778  0.59799546 0.89477295 0.9319636  0.95584595\n",
      "  0.7910637  0.8734317  0.9798365  0.8815044 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [218/500], Cumulative Loss: 0.9785, LR: 1.000e-03\n",
      "Final parameters: [[ 0.9006146  -0.64027524  1.7094252   0.9888904   2.2603168   1.9301593\n",
      "   1.0341942   1.7245699   1.6194285  -0.55373514]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [219/500], Cumulative Loss: 0.2757, LR: 1.000e-03\n",
      "Final parameters: [[0.9057257  0.58153933 0.98538166 0.90863556 1.3062764  1.1973407\n",
      "  0.9510776  1.075105   1.1527001  0.55793834]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [220/500], Cumulative Loss: 0.0884, LR: 1.000e-03\n",
      "Final parameters: [[1.3043139  1.7081597  0.71226394 1.219202   0.9082614  0.9776284\n",
      "  1.014144   0.759139   1.0444052  1.5774273 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [221/500], Cumulative Loss: 0.4979, LR: 1.000e-03\n",
      "Final parameters: [[0.92263544 0.72148925 0.9807336  0.86340195 1.0453197  1.0971822\n",
      "  0.9778556  1.0040958  1.0622779  0.96554893]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [222/500], Cumulative Loss: 0.7420, LR: 1.000e-03\n",
      "Final parameters: [[0.94930005 1.2375175  0.89903975 1.0402172  0.83003986 0.9102461\n",
      "  1.0511638  0.9336127  1.0404207  1.2643479 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [223/500], Cumulative Loss: 0.7038, LR: 1.000e-03\n",
      "Final parameters: [[ 0.93262994  2.7885642  -0.02811362  1.222514   -0.18634373  0.17236562\n",
      "   1.0625046  -0.10306332  0.34033817  2.4825501 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [224/500], Cumulative Loss: 0.4118, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1028807   3.1022754  -0.22122276  1.172529    0.00693082  0.26860228\n",
      "   0.7200847  -0.40231472  0.34357738  2.380656  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [225/500], Cumulative Loss: 0.2665, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1221902   2.8709545  -0.32159072  1.0948534  -0.14681967  0.20813571\n",
      "   0.70243496 -0.16507229  0.38216895  2.4063478 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [226/500], Cumulative Loss: 0.2189, LR: 1.000e-03\n",
      "Final parameters: [[1.0535958  1.7293636  0.5871366  1.0645915  0.55078995 0.7023625\n",
      "  1.0319816  0.6285056  0.74061847 1.6194307 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [227/500], Cumulative Loss: 0.7981, LR: 1.000e-03\n",
      "Final parameters: [[ 1.2668457   3.3394978  -0.5374932   1.1444037  -0.25170368  0.06932862\n",
      "   0.80105007 -0.3084107   0.43883413  2.6996346 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [228/500], Cumulative Loss: 0.6279, LR: 1.000e-03\n",
      "Final parameters: [[0.98467135 1.238981   0.5854892  1.0181377  1.0620698  1.0521699\n",
      "  0.8477382  0.7923836  1.0776078  0.9772919 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [229/500], Cumulative Loss: 1.6160, LR: 1.000e-03\n",
      "Final parameters: [[1.1493232  1.1029053  1.1002316  1.0750926  1.0723083  1.0916647\n",
      "  1.0117209  1.0752232  1.1049374  0.91024446]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [230/500], Cumulative Loss: 0.0979, LR: 1.000e-03\n",
      "Final parameters: [[1.1653208  0.31779638 1.4319942  1.0856336  1.7891151  1.6318439\n",
      "  1.1557392  1.6450028  1.5508006  0.4471681 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [231/500], Cumulative Loss: 0.9511, LR: 1.000e-03\n",
      "Final parameters: [[0.9691188  0.29157406 1.3980252  0.8767987  1.35211    1.3831574\n",
      "  0.9336532  1.4070883  1.2650099  0.37821478]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [232/500], Cumulative Loss: 0.8657, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0737162  -0.13308859  1.5462674   0.9636651   1.893597    1.70594\n",
      "   0.9200572   1.6958253   1.6808523   0.00960864]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [233/500], Cumulative Loss: 0.3993, LR: 1.000e-03\n",
      "Final parameters: [[1.1257149  2.4652817  0.15068382 1.0234934  0.12684855 0.2980176\n",
      "  0.6671432  0.19301353 0.50162214 1.8713778 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [234/500], Cumulative Loss: 0.7626, LR: 1.000e-03\n",
      "Final parameters: [[ 1.3413126   3.208056   -0.12006287  1.3328464   0.15400612  0.31252933\n",
      "   0.7657919  -0.28522938  0.46179903  2.3826675 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [235/500], Cumulative Loss: 0.1366, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1853598   2.6077356   0.14634223  1.1263154  -0.01441826  0.36348534\n",
      "   0.94881666  0.19998616  0.52244663  2.2742405 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [236/500], Cumulative Loss: 0.2000, LR: 1.000e-03\n",
      "Final parameters: [[1.0229635  0.24127722 1.4858047  1.0411506  1.60354    1.4297173\n",
      "  1.1225374  1.4397198  1.2710074  0.27406085]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [237/500], Cumulative Loss: 0.7490, LR: 1.000e-03\n",
      "Final parameters: [[0.83573157 1.0065154  0.88523775 1.0311778  1.0490645  0.94321895\n",
      "  0.9739609  0.87061477 0.9955926  0.94117177]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [238/500], Cumulative Loss: 0.0848, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1850896   2.8565893  -0.03223894  1.2372953   0.2065976   0.4308532\n",
      "   0.87244153 -0.01963213  0.59667367  2.3013272 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [239/500], Cumulative Loss: 0.3875, LR: 1.000e-03\n",
      "Final parameters: [[1.0064554  1.6098571  0.7079879  1.0254159  0.635985   0.6407572\n",
      "  1.0752432  0.64781284 0.8190304  1.5738872 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [240/500], Cumulative Loss: 0.1118, LR: 1.000e-03\n",
      "Final parameters: [[1.0323117  2.5918357  0.13742328 1.0846505  0.08300672 0.30793315\n",
      "  0.86674404 0.0881868  0.5617016  2.2688005 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [241/500], Cumulative Loss: 1.2028, LR: 1.000e-03\n",
      "Final parameters: [[0.9702733  2.0592399  0.30410892 1.1736673  0.6631972  0.7307667\n",
      "  0.91006756 0.21157157 0.7287301  1.6505133 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [242/500], Cumulative Loss: 0.5169, LR: 1.000e-03\n",
      "Final parameters: [[ 0.9390571  -0.19152525  1.4958049   0.82827353  1.7638117   1.4921637\n",
      "   0.8806947   1.514921    1.4153005  -0.21632276]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [243/500], Cumulative Loss: 0.8728, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0625951e+00  2.1277256e+00 -2.0954013e-03  1.0946976e+00\n",
      "   6.2424219e-01  6.4508975e-01  8.4237862e-01  2.2734158e-01\n",
      "   8.4894139e-01  1.7708287e+00]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [244/500], Cumulative Loss: 0.1970, LR: 1.000e-03\n",
      "Final parameters: [[0.99854386 0.5207779  1.4137888  1.0274771  1.6202734  1.4600708\n",
      "  1.0193586  1.3604298  1.3420321  0.45879614]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [245/500], Cumulative Loss: 1.6272, LR: 1.000e-03\n",
      "Final parameters: [[1.1327231  0.8601235  1.3323808  0.92093456 1.2705973  1.1003146\n",
      "  0.88772106 1.2040306  1.092751   0.57570374]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [246/500], Cumulative Loss: 0.3542, LR: 1.000e-03\n",
      "Final parameters: [[ 0.89535594 -0.17311049  1.2794106   0.824729    1.6935072   1.4951746\n",
      "   0.8393694   1.4908084   1.3648374  -0.16009259]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [247/500], Cumulative Loss: 0.3653, LR: 1.000e-03\n",
      "Final parameters: [[0.9211854  1.2670456  0.60324436 1.0100737  0.95136416 0.95806956\n",
      "  0.9869066  0.780444   0.9580293  1.28437   ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [248/500], Cumulative Loss: 0.4505, LR: 1.000e-03\n",
      "Final parameters: [[1.0171093 1.0437303 1.1096714 1.0836143 1.2707039 1.1367056 1.0724062\n",
      "  1.0153476 1.1324348 1.0205201]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [249/500], Cumulative Loss: 1.7255, LR: 1.000e-03\n",
      "Final parameters: [[1.059381   1.694457   0.6951103  1.0701685  0.52132744 0.60636055\n",
      "  0.9327558  0.60702884 0.7969762  1.8480866 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [250/500], Cumulative Loss: 0.7468, LR: 1.000e-03\n",
      "Final parameters: [[1.1211551  0.35719985 1.4815111  0.9442314  1.6037235  1.374506\n",
      "  0.7782632  1.341645   1.2239697  0.303987  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [251/500], Cumulative Loss: 0.4344, LR: 1.000e-03\n",
      "Final parameters: [[1.2379766  2.4362373  0.3842672  1.155873   0.38526452 0.5643687\n",
      "  0.8086562  0.34716514 0.7074358  1.7750441 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [252/500], Cumulative Loss: 0.3012, LR: 1.000e-03\n",
      "Final parameters: [[ 1.120904    2.6132655  -0.03017266  1.0458734   0.01832365  0.28082368\n",
      "   0.8204712   0.00898579  0.46143687  2.250604  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [253/500], Cumulative Loss: 0.8913, LR: 1.000e-03\n",
      "Final parameters: [[1.091049   2.0116105  0.21976757 1.1654801  0.6566934  0.8087323\n",
      "  0.99509174 0.49826717 0.88835406 1.8634446 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [254/500], Cumulative Loss: 0.4279, LR: 1.000e-03\n",
      "Final parameters: [[ 1.3431115   3.0124097  -0.40717402  1.2813039   0.26975328  0.5017149\n",
      "   0.8994192   0.00335369  0.78684294  2.5308483 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [255/500], Cumulative Loss: 1.1774, LR: 1.000e-03\n",
      "Final parameters: [[0.83763474 0.6132186  0.8862419  0.9302195  1.2033461  1.0973592\n",
      "  0.9950095  1.1093094  1.0858094  0.70180637]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [256/500], Cumulative Loss: 1.4632, LR: 1.000e-03\n",
      "Final parameters: [[0.9624385 0.813339  0.8904641 0.9688745 1.2404798 1.1569889 0.989467\n",
      "  1.121713  1.2283558 0.885102 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [257/500], Cumulative Loss: 0.2888, LR: 1.000e-03\n",
      "Final parameters: [[0.94205654 1.5292786  0.59380275 0.99955475 0.40323272 0.54754746\n",
      "  0.9276154  0.651121   0.5841927  1.456045  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [258/500], Cumulative Loss: 0.1364, LR: 1.000e-03\n",
      "Final parameters: [[0.8772216  0.8366649  0.98771286 1.0367646  1.2958769  1.2855034\n",
      "  1.0359722  1.1809062  1.2982666  1.0047133 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [259/500], Cumulative Loss: 0.4378, LR: 1.000e-03\n",
      "Final parameters: [[1.1789429  1.8542478  0.20275153 1.0111794  0.8117515  0.87034726\n",
      "  0.6340825  0.47020516 1.097081   1.5961424 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [260/500], Cumulative Loss: 0.1966, LR: 1.000e-03\n",
      "Final parameters: [[0.9872744 0.5593176 0.8444919 0.8637172 1.4268917 1.3844949 0.7688159\n",
      "  1.215997  1.42722   0.6792805]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [261/500], Cumulative Loss: 1.2084, LR: 1.000e-03\n",
      "Final parameters: [[0.95939887 1.4655772  0.6852844  1.0184646  0.63434637 0.77631104\n",
      "  1.1219342  0.7754284  0.74058807 1.2728982 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [262/500], Cumulative Loss: 0.7242, LR: 1.000e-03\n",
      "Final parameters: [[0.94258153 0.03255085 1.5028678  0.77771807 1.5383021  1.440028\n",
      "  0.9354637  1.6433076  1.4495895  0.40270102]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [263/500], Cumulative Loss: 0.1658, LR: 1.000e-03\n",
      "Final parameters: [[ 0.9777597  -0.8671752   1.8915623   0.8758203   2.0920382   1.813844\n",
      "   0.98886865  1.9745177   1.615244   -0.40681404]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [264/500], Cumulative Loss: 0.2133, LR: 1.000e-03\n",
      "Final parameters: [[1.2748493  2.5870082  0.24169046 1.1453199  0.13174215 0.41436693\n",
      "  0.79942584 0.16372767 0.425249   2.1493008 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [265/500], Cumulative Loss: 1.1260, LR: 1.000e-03\n",
      "Final parameters: [[1.1787878  0.96977556 0.61036366 1.0054263  1.2611104  1.2546569\n",
      "  0.61277556 0.8461086  1.2301301  0.7932607 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [266/500], Cumulative Loss: 0.1335, LR: 1.000e-03\n",
      "Final parameters: [[1.044398   1.8570232  0.5713856  1.0714912  0.71823955 0.78035957\n",
      "  0.9001539  0.52613854 0.93757504 1.5843673 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [267/500], Cumulative Loss: 0.3172, LR: 1.000e-03\n",
      "Final parameters: [[0.95561683 0.899033   1.175016   1.1014441  0.7253017  0.88246405\n",
      "  1.3887789  1.0666026  0.7090658  1.3381466 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [268/500], Cumulative Loss: 0.3899, LR: 1.000e-03\n",
      "Final parameters: [[1.171631   0.2640385  0.8607199  0.7998859  1.5139849  1.3670582\n",
      "  0.6183362  1.1795597  1.4397738  0.41188323]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [269/500], Cumulative Loss: 0.9335, LR: 1.000e-03\n",
      "Final parameters: [[1.0527235  0.7351306  1.2135184  0.9481643  1.1371932  1.147347\n",
      "  1.0342997  1.2380301  1.1549238  0.82895666]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [270/500], Cumulative Loss: 0.6922, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0500779  -0.0696708   1.4821881   0.8872392   1.8437451   1.639392\n",
      "   0.98241276  1.819682    1.7078477   0.08650027]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [271/500], Cumulative Loss: 0.4131, LR: 1.000e-03\n",
      "Final parameters: [[1.1288354  1.4930127  0.89171034 1.0404756  0.76669455 0.84232116\n",
      "  0.71508497 0.7520107  0.7476521  0.8069143 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [272/500], Cumulative Loss: 0.1662, LR: 1.000e-03\n",
      "Final parameters: [[1.1922219  1.6810557  0.49660394 1.1215293  0.8682995  0.84332305\n",
      "  0.84277105 0.49271032 0.9614474  1.3818845 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [273/500], Cumulative Loss: 0.4052, LR: 1.000e-03\n",
      "Final parameters: [[0.8476929  2.037116   0.3624368  1.1330323  0.3241218  0.50464135\n",
      "  1.032979   0.39303252 0.67346734 1.9296509 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [274/500], Cumulative Loss: 1.0303, LR: 1.000e-03\n",
      "Final parameters: [[1.1434808  1.7641664  0.69188315 1.0213578  0.42590395 0.66979057\n",
      "  0.9171145  0.69027436 0.8419149  1.58891   ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [275/500], Cumulative Loss: 1.3558, LR: 1.000e-03\n",
      "Final parameters: [[1.1494074  1.7525485  0.62948495 1.0924498  0.65633804 0.69962114\n",
      "  0.8514436  0.5572254  0.85924107 1.5817826 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [276/500], Cumulative Loss: 0.1168, LR: 1.000e-03\n",
      "Final parameters: [[0.8393737  0.9490129  1.0524516  0.98957676 0.7857339  0.85942876\n",
      "  1.1502417  0.9599631  0.9315069  1.2464591 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [277/500], Cumulative Loss: 0.4450, LR: 1.000e-03\n",
      "Final parameters: [[0.74229074 1.0355089  1.1059102  0.9493331  0.74063826 0.68522835\n",
      "  1.0693305  0.8789191  0.6830307  0.9922277 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [278/500], Cumulative Loss: 0.5965, LR: 1.000e-03\n",
      "Final parameters: [[1.0804713  1.7991548  0.8221494  1.143991   0.44809395 0.56048393\n",
      "  1.1188111  0.6563673  0.70218945 1.8781631 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [279/500], Cumulative Loss: 0.2758, LR: 1.000e-03\n",
      "Final parameters: [[ 1.118413    3.3034425  -0.0923624   1.3263302  -0.231817    0.16330226\n",
      "   1.0630567  -0.3362832   0.34615844  2.680525  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [280/500], Cumulative Loss: 0.9250, LR: 1.000e-03\n",
      "Final parameters: [[0.72593737 0.3712372  1.0412099  0.9346293  1.412531   1.1769304\n",
      "  0.9538524  1.1721674  1.1361865  0.3212114 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [281/500], Cumulative Loss: 0.2378, LR: 1.000e-03\n",
      "Final parameters: [[1.0686994  1.7659707  0.89885443 1.1616571  0.7322931  0.7889475\n",
      "  1.1547767  0.74058294 0.8559145  1.6316949 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [282/500], Cumulative Loss: 0.3997, LR: 1.000e-03\n",
      "Final parameters: [[0.8925243  0.01524146 1.2746133  0.75408596 1.6111063  1.5026972\n",
      "  0.73843396 1.3189449  1.2970053  0.0962096 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [283/500], Cumulative Loss: 0.2302, LR: 1.000e-03\n",
      "Final parameters: [[0.96777713 0.5202181  0.9571321  0.81050575 1.1025758  0.9981928\n",
      "  0.82123387 1.138476   1.0641732  0.49714446]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [284/500], Cumulative Loss: 1.1936, LR: 1.000e-03\n",
      "Final parameters: [[1.2589157  2.1887407  0.2270931  1.0711789  0.7303681  0.7879986\n",
      "  0.7167343  0.40627643 0.8484102  1.7009258 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [285/500], Cumulative Loss: 0.3384, LR: 1.000e-03\n",
      "Final parameters: [[ 1.3413457   3.08562    -0.31062648  1.1836193   0.20557015  0.42419195\n",
      "   0.8056603  -0.01706564  0.74116683  2.2282145 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [286/500], Cumulative Loss: 1.4690, LR: 1.000e-03\n",
      "Final parameters: [[0.96190804 1.2010268  0.8187032  0.9795134  1.0717111  1.0537277\n",
      "  0.7413359  0.7730518  0.98869944 0.66875637]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [287/500], Cumulative Loss: 0.6574, LR: 1.000e-03\n",
      "Final parameters: [[1.0418442  0.5578613  1.2322117  0.8173796  1.2071333  1.2538941\n",
      "  0.95522404 1.318607   1.3323612  0.80660117]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [288/500], Cumulative Loss: 0.1211, LR: 1.000e-03\n",
      "Final parameters: [[ 9.3691993e-01 -1.9432604e-03  2.0705540e+00  1.0122483e+00\n",
      "   1.5283873e+00  1.4159107e+00  1.3318204e+00  1.7932439e+00\n",
      "   1.2544711e+00  4.3069878e-01]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [289/500], Cumulative Loss: 0.2321, LR: 1.000e-03\n",
      "Final parameters: [[ 0.88332635 -0.04657769  1.8306026   0.9782385   1.8140128   1.5125879\n",
      "   1.0975473   1.6696706   1.5033362  -0.13154966]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [290/500], Cumulative Loss: 0.0963, LR: 1.000e-03\n",
      "Final parameters: [[1.0051229  1.9690043  0.24189171 1.0171871  0.25078753 0.42604303\n",
      "  0.8446853  0.30943373 0.5076609  1.7819452 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [291/500], Cumulative Loss: 0.2183, LR: 1.000e-03\n",
      "Final parameters: [[ 1.4982471   3.5886252  -0.8591038   1.2450521  -0.16804911  0.04106738\n",
      "   0.71477103 -0.5094706   0.3953303   2.7728934 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [292/500], Cumulative Loss: 0.4569, LR: 1.000e-03\n",
      "Final parameters: [[ 1.3562579   3.6717927  -0.84461635  1.2334322  -0.15356052  0.29263762\n",
      "   0.7448262  -0.32323375  0.6404154   3.189931  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [293/500], Cumulative Loss: 1.9327, LR: 1.000e-03\n",
      "Final parameters: [[1.0790471  0.41656366 0.8790859  0.9076431  1.6246221  1.5882069\n",
      "  0.89443576 1.3363703  1.4805512  0.20076984]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [294/500], Cumulative Loss: 0.8420, LR: 1.000e-03\n",
      "Final parameters: [[1.0541764  1.3837135  0.7382018  0.9324347  0.8037741  0.99595\n",
      "  0.8131936  0.7778746  0.87089646 1.0805588 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [295/500], Cumulative Loss: 0.8302, LR: 1.000e-03\n",
      "Final parameters: [[0.9197625  0.7273689  1.1076562  1.0950627  1.2140646  1.2517788\n",
      "  1.1160628  1.1661924  1.1386129  0.95679164]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [296/500], Cumulative Loss: 0.3450, LR: 1.000e-03\n",
      "Final parameters: [[1.2397518  1.7436279  0.28742748 1.0537056  0.71239436 0.91357833\n",
      "  0.8411844  0.5052068  0.98116404 1.5221018 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [297/500], Cumulative Loss: 0.3538, LR: 1.000e-03\n",
      "Final parameters: [[0.96911526 0.58878285 0.8989617  0.8759685  1.3823284  1.3802953\n",
      "  0.6899764  1.2973727  1.4798418  0.5080559 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [298/500], Cumulative Loss: 0.2827, LR: 1.000e-03\n",
      "Final parameters: [[1.0574212  1.0846039  0.640088   0.91366917 1.2754437  1.2257313\n",
      "  0.7136438  0.93935347 1.3005798  0.64879966]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [299/500], Cumulative Loss: 0.5559, LR: 1.000e-03\n",
      "Final parameters: [[1.260924   1.8058863  0.50915575 0.9940885  0.48814338 0.73657703\n",
      "  0.97731847 0.6902343  0.85285    1.7484632 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [300/500], Cumulative Loss: 0.6420, LR: 1.000e-03\n",
      "Final parameters: [[1.2824101  2.2875972  0.30086878 1.2776786  0.785319   0.76649475\n",
      "  0.7548174  0.31695017 0.83328176 1.565042  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [301/500], Cumulative Loss: 0.9867, LR: 1.000e-03\n",
      "Final parameters: [[1.108788   1.895302   0.5579246  1.1264306  0.60067725 0.66523105\n",
      "  1.0053854  0.5247389  0.7825954  1.8520485 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [302/500], Cumulative Loss: 0.3468, LR: 1.000e-03\n",
      "Final parameters: [[1.212648   1.6450744  0.6299431  1.1804333  1.1477766  1.1119655\n",
      "  0.7853364  0.85418385 1.1838119  1.0968692 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [303/500], Cumulative Loss: 0.2175, LR: 1.000e-03\n",
      "Final parameters: [[1.0819571  1.0911183  1.0225323  0.98302937 1.0824405  1.1220064\n",
      "  0.9140727  0.94367236 1.005895   0.7476106 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [304/500], Cumulative Loss: 0.8784, LR: 1.000e-03\n",
      "Final parameters: [[0.9699668  0.88203824 0.73180926 0.94925416 1.2537081  1.1035848\n",
      "  0.7782229  0.7106625  1.0208368  0.56684774]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [305/500], Cumulative Loss: 0.2035, LR: 1.000e-03\n",
      "Final parameters: [[0.9618529  1.7709556  0.62998    1.0115352  0.5492023  0.54769295\n",
      "  1.0060328  0.5048565  0.75258493 1.5989757 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [306/500], Cumulative Loss: 0.4822, LR: 1.000e-03\n",
      "Final parameters: [[0.96353716 1.8917906  0.49984246 1.164513   0.6917777  0.6951314\n",
      "  1.0261769  0.5624374  0.82836735 1.4852443 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [307/500], Cumulative Loss: 0.9846, LR: 1.000e-03\n",
      "Final parameters: [[1.0286856  0.49157006 0.9611449  1.0247989  1.3870336  1.2622914\n",
      "  1.0098944  1.1656662  1.213283   0.78572243]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [308/500], Cumulative Loss: 0.1119, LR: 1.000e-03\n",
      "Final parameters: [[1.1032764  2.0755355  0.3364895  1.2614409  0.9189555  0.91824454\n",
      "  0.89209294 0.38548273 0.94202673 1.5572741 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [309/500], Cumulative Loss: 0.4062, LR: 1.000e-03\n",
      "Final parameters: [[1.2053084  1.5760669  0.594812   1.0272616  0.86904067 0.9228861\n",
      "  0.87624836 0.6587689  0.82100147 1.2088436 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [310/500], Cumulative Loss: 0.5707, LR: 1.000e-03\n",
      "Final parameters: [[1.0541203  1.6101525  0.48511064 0.9636022  0.54614675 0.6290826\n",
      "  0.9396359  0.56351316 0.75100976 1.3995993 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [311/500], Cumulative Loss: 0.2070, LR: 1.000e-03\n",
      "Final parameters: [[1.0633975 1.1737357 0.5973588 0.9183341 0.7971194 0.8790829 0.8170091\n",
      "  0.8589369 0.9708437 1.3812426]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [312/500], Cumulative Loss: 0.2417, LR: 1.000e-03\n",
      "Final parameters: [[0.9666895  2.0373125  0.43705165 1.1598057  0.48723426 0.7421154\n",
      "  1.1101315  0.37497276 0.74173707 1.8966274 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [313/500], Cumulative Loss: 0.7240, LR: 1.000e-03\n",
      "Final parameters: [[0.94125104 0.5690888  1.2154028  0.91407454 1.1691556  1.1736344\n",
      "  1.004568   1.1292233  1.1029719  0.81916654]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [314/500], Cumulative Loss: 0.4895, LR: 1.000e-03\n",
      "Final parameters: [[1.1277354  2.0793414  0.5755468  1.1596106  0.34570435 0.5818705\n",
      "  0.97728217 0.48387247 0.69420874 1.8370478 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [315/500], Cumulative Loss: 0.7662, LR: 1.000e-03\n",
      "Final parameters: [[0.966655   2.059756   0.63993335 1.1952487  0.27952415 0.4422586\n",
      "  1.0902982  0.46685928 0.50977635 1.923978  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [316/500], Cumulative Loss: 1.2662, LR: 1.000e-03\n",
      "Final parameters: [[1.100496   1.8597622  0.53284323 1.1088655  0.74718696 0.77032137\n",
      "  0.8958772  0.46332723 0.9028111  1.6997104 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [317/500], Cumulative Loss: 2.7418, LR: 1.000e-03\n",
      "Final parameters: [[0.95903903 1.895143   0.3743246  1.0342532  0.37331212 0.59424496\n",
      "  0.81011224 0.42213324 0.7712696  1.6562066 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [318/500], Cumulative Loss: 0.3163, LR: 1.000e-03\n",
      "Final parameters: [[1.0074649  1.4126738  1.0424026  1.2306409  0.86784565 0.889423\n",
      "  1.3618015  0.95741004 0.8690513  1.2692379 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [319/500], Cumulative Loss: 0.2769, LR: 1.000e-03\n",
      "Final parameters: [[1.2553167  1.7974182  0.92960554 1.158936   0.91090894 0.9508607\n",
      "  1.100041   0.86861664 0.95774776 1.3860662 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [320/500], Cumulative Loss: 0.8731, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1030194   2.048765   -0.07614321  1.0654292   0.5764518   0.7136761\n",
      "   0.6703325   0.19332029  0.8637186   1.6197202 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [321/500], Cumulative Loss: 0.3590, LR: 1.000e-03\n",
      "Final parameters: [[1.2429361  2.4198005  0.11807626 1.3157613  0.50843    0.68057215\n",
      "  0.7698     0.21008536 0.7901265  2.001707  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [322/500], Cumulative Loss: 0.5089, LR: 1.000e-03\n",
      "Final parameters: [[1.3681948  2.0074368  0.39240932 1.2375364  0.8777396  0.8887263\n",
      "  0.78590924 0.4317743  0.900474   1.4924576 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [323/500], Cumulative Loss: 0.5024, LR: 1.000e-03\n",
      "Final parameters: [[ 1.2307124   3.1180732  -0.32093892  1.1344126  -0.1545003   0.2553079\n",
      "   0.8514434  -0.18608528  0.37698296  2.857524  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [324/500], Cumulative Loss: 1.0580, LR: 1.000e-03\n",
      "Final parameters: [[1.3607621  1.4975404  0.2711253  1.0798881  1.0997851  1.1133335\n",
      "  0.6143589  0.71928155 1.2240912  1.0798373 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [325/500], Cumulative Loss: 1.0140, LR: 1.000e-03\n",
      "Final parameters: [[ 1.2300714   3.3644693  -0.6783118   1.2395482  -0.15309292  0.3915736\n",
      "   0.7251477  -0.38146013  0.4361548   2.567044  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [326/500], Cumulative Loss: 0.6613, LR: 1.000e-03\n",
      "Final parameters: [[0.97888345 1.2542732  0.8930881  1.173181   1.1752094  1.164174\n",
      "  0.95281076 0.9762223  1.113496   1.0624007 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [327/500], Cumulative Loss: 1.1536, LR: 1.000e-03\n",
      "Final parameters: [[0.9033923  2.0779445  0.85849226 1.2503763  0.3344488  0.47544903\n",
      "  1.242451   0.4924049  0.47802258 2.063527  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [328/500], Cumulative Loss: 0.6241, LR: 1.000e-03\n",
      "Final parameters: [[1.1738256  1.9943713  0.06807877 0.9930198  0.30301714 0.617113\n",
      "  0.6773853  0.2744925  0.8376367  1.9519248 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [329/500], Cumulative Loss: 0.2182, LR: 1.000e-03\n",
      "Final parameters: [[1.2431412  2.6017797  0.44741884 1.2468555  0.07388048 0.28790203\n",
      "  1.0275798  0.17410858 0.4678162  2.2624357 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [330/500], Cumulative Loss: 1.0808, LR: 1.000e-03\n",
      "Final parameters: [[1.3188177  1.1994696  0.7791774  1.0305427  1.3915586  1.2606971\n",
      "  0.7412398  0.88000727 1.2850131  0.6701741 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [331/500], Cumulative Loss: 0.3316, LR: 1.000e-03\n",
      "Final parameters: [[1.1772847  1.3856003  0.83005184 1.0017669  0.68377846 0.8380385\n",
      "  0.98333967 0.90701616 0.8638663  1.2603879 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [332/500], Cumulative Loss: 0.8519, LR: 1.000e-03\n",
      "Final parameters: [[0.9706101  1.0403925  0.6476351  0.9296693  1.1024232  1.0887164\n",
      "  0.92519265 1.0286834  1.2194021  1.0409737 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [333/500], Cumulative Loss: 0.3765, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1786743   3.143614   -0.24915147  1.1330016  -0.09664094  0.33357108\n",
      "   0.869341   -0.04007158  0.52735734  2.644332  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [334/500], Cumulative Loss: 0.5388, LR: 1.000e-03\n",
      "Final parameters: [[ 1.156047    3.08389    -0.08427885  1.216155   -0.27969545  0.06924184\n",
      "   0.97825795 -0.04897509  0.33332777  2.5747726 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [335/500], Cumulative Loss: 0.3700, LR: 1.000e-03\n",
      "Final parameters: [[1.3302919  1.3802975  0.50345457 1.0421771  1.1697237  1.2229019\n",
      "  0.72049373 0.8296374  1.3260204  1.0397885 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [336/500], Cumulative Loss: 1.6585, LR: 1.000e-03\n",
      "Final parameters: [[1.083886  0.6030563 1.2992914 1.0027249 1.322009  1.2724158 0.9418741\n",
      "  1.1359832 1.1683781 0.5814179]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [337/500], Cumulative Loss: 1.2281, LR: 1.000e-03\n",
      "Final parameters: [[1.191877   2.12599    0.3449682  1.1456559  0.54141533 0.66261137\n",
      "  0.8515785  0.33261034 0.73242855 1.5576975 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [338/500], Cumulative Loss: 0.7000, LR: 1.000e-03\n",
      "Final parameters: [[1.0012126  1.6491107  0.59570193 0.9561487  0.6650456  0.7188886\n",
      "  0.8664717  0.5054549  0.7807176  1.4389786 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [339/500], Cumulative Loss: 0.3882, LR: 1.000e-03\n",
      "Final parameters: [[ 0.99951756  0.02720864  1.5447522   0.9806755   1.8415835   1.5473733\n",
      "   1.0235462   1.5547063   1.4522812  -0.16822161]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [340/500], Cumulative Loss: 1.1306, LR: 1.000e-03\n",
      "Final parameters: [[ 1.2309984   3.1148381  -0.3193845   1.2350945  -0.12835371  0.25094548\n",
      "   0.9617257  -0.11842791  0.450628    2.8077836 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [341/500], Cumulative Loss: 0.7938, LR: 1.000e-03\n",
      "Final parameters: [[1.2068307  1.534575   0.4329601  0.8812829  0.7825872  0.87464416\n",
      "  0.744751   0.734822   1.0539244  1.2503332 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [342/500], Cumulative Loss: 0.3449, LR: 1.000e-03\n",
      "Final parameters: [[1.2451353  2.144267   0.45495355 1.0424298  0.23774847 0.51064473\n",
      "  1.0620819  0.51302004 0.76289916 1.8228246 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [343/500], Cumulative Loss: 0.4781, LR: 1.000e-03\n",
      "Final parameters: [[1.0416338  2.0079722  0.361507   1.0588413  0.1279629  0.46227095\n",
      "  0.889886   0.32318518 0.56841284 1.8924507 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [344/500], Cumulative Loss: 1.0087, LR: 1.000e-03\n",
      "Final parameters: [[1.1102786  1.4364737  0.7446771  1.0587913  0.8186317  0.9611997\n",
      "  0.89368653 0.6947816  0.933723   1.2726057 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [345/500], Cumulative Loss: 0.5374, LR: 1.000e-03\n",
      "Final parameters: [[0.9437415  0.7687816  1.1537676  0.85480297 0.7373861  0.8837888\n",
      "  1.0428958  1.0707648  0.8891418  0.98241407]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [346/500], Cumulative Loss: 0.9984, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0627462   2.7281687  -0.04800698  1.0630639  -0.02179748  0.2890122\n",
      "   0.86215943  0.06251679  0.45977375  2.074458  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [347/500], Cumulative Loss: 0.5649, LR: 1.000e-03\n",
      "Final parameters: [[1.014569   0.07889278 1.3618155  1.0317478  1.7235931  1.5976108\n",
      "  0.9860304  1.4057239  1.4169931  0.22937524]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [348/500], Cumulative Loss: 0.1485, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1745905   2.7993765   0.07961291  1.2127119  -0.18777248  0.21251701\n",
      "   0.9796049   0.08644013  0.36836395  2.4591024 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [349/500], Cumulative Loss: 0.1533, LR: 1.000e-03\n",
      "Final parameters: [[1.0717113  2.4521492  0.49484372 1.2255884  0.07195659 0.36149567\n",
      "  1.2727928  0.33461556 0.6076218  2.3157792 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [350/500], Cumulative Loss: 1.1691, LR: 1.000e-03\n",
      "Final parameters: [[0.7521446  1.5718101  0.79148304 1.0090406  0.25217786 0.39781857\n",
      "  1.1656374  0.55480784 0.45794132 1.4101881 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [351/500], Cumulative Loss: 0.2877, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0914797   3.5296435  -0.12201288  1.28924    -0.5968219  -0.22164026\n",
      "   1.0016743  -0.31911513  0.02268817  2.9927387 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [352/500], Cumulative Loss: 0.6466, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0739403   2.7849529   0.33749673  1.2462695  -0.17617527  0.04501641\n",
      "   1.0391757  -0.03130706  0.12112966  2.34159   ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [353/500], Cumulative Loss: 0.3477, LR: 1.000e-03\n",
      "Final parameters: [[0.83994585 1.567629   0.7559587  1.0537865  0.5772774  0.6590618\n",
      "  1.1307073  0.674108   0.72770333 1.2192646 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [354/500], Cumulative Loss: 0.4476, LR: 1.000e-03\n",
      "Final parameters: [[0.87515783 2.1095665  0.565925   1.1171563  0.14266738 0.2903642\n",
      "  1.1258178  0.40688658 0.5098324  1.9124227 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [355/500], Cumulative Loss: 0.3563, LR: 1.000e-03\n",
      "Final parameters: [[0.8841441  1.3632159  1.3220079  1.1412232  0.46683648 0.6374048\n",
      "  1.3516612  0.926782   0.65722173 1.5811346 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [356/500], Cumulative Loss: 0.5036, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0534322   2.8444095   0.4549908   1.2007556  -0.41497084 -0.07490639\n",
      "   1.0990849  -0.07445927  0.03811475  2.412262  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [357/500], Cumulative Loss: 0.9047, LR: 1.000e-03\n",
      "Final parameters: [[0.9522476  1.2953808  0.69315904 1.0685323  0.99809575 0.83070385\n",
      "  0.9384318  0.6795102  0.9760945  1.1030163 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [358/500], Cumulative Loss: 0.6672, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0234435   2.6115344   0.40574095  1.2001896  -0.04806277  0.1305756\n",
      "   1.0915859   0.20363754  0.3198865   2.058552  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [359/500], Cumulative Loss: 1.1741, LR: 1.000e-03\n",
      "Final parameters: [[0.57326865 0.57074106 1.6980734  0.9713284  0.73351973 0.7019985\n",
      "  1.3405575  1.2444996  0.7389388  0.75150764]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [360/500], Cumulative Loss: 2.1186, LR: 1.000e-03\n",
      "Final parameters: [[ 0.8141892   2.160839    0.55363387  1.0221592  -0.1460493   0.03169554\n",
      "   1.1336681   0.30016583  0.28115094  2.1955078 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [361/500], Cumulative Loss: 0.8360, LR: 1.000e-03\n",
      "Final parameters: [[0.9657669  2.0768087  0.5123239  1.0178822  0.24723591 0.4006052\n",
      "  1.0542631  0.42863643 0.52329576 1.8748091 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [362/500], Cumulative Loss: 0.4157, LR: 1.000e-03\n",
      "Final parameters: [[0.9831547  1.5364594  0.78293097 0.9927169  0.55956656 0.64566624\n",
      "  0.8794296  0.6168857  0.64645684 1.2037294 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [363/500], Cumulative Loss: 0.3595, LR: 1.000e-03\n",
      "Final parameters: [[0.7130787  0.6070417  1.2355381  0.9360289  0.9303663  0.8350017\n",
      "  1.1719785  1.1879892  0.9025418  0.87472653]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [364/500], Cumulative Loss: 0.2935, LR: 1.000e-03\n",
      "Final parameters: [[0.8896735  2.4208882  0.34933686 1.153654   0.26630336 0.3211842\n",
      "  0.935513   0.18648103 0.45968634 1.8888505 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [365/500], Cumulative Loss: 0.6924, LR: 1.000e-03\n",
      "Final parameters: [[ 9.46877539e-01  2.91715908e+00 -8.77708197e-04  1.12098992e+00\n",
      "  -4.61790919e-01 -1.68596208e-02  9.70446765e-01 -8.24917778e-02\n",
      "   1.17560595e-01  2.44122076e+00]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [366/500], Cumulative Loss: 0.8580, LR: 1.000e-03\n",
      "Final parameters: [[0.97713673 1.8680973  0.37751824 1.1544192  0.63333356 0.715383\n",
      "  1.0574973  0.34886053 0.80030096 1.8186541 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [367/500], Cumulative Loss: 0.2207, LR: 1.000e-03\n",
      "Final parameters: [[ 1.140448    2.9895465  -0.06657121  1.055961   -0.28230673  0.00680651\n",
      "   0.77722096 -0.18814114  0.17173634  2.290561  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [368/500], Cumulative Loss: 0.2627, LR: 1.000e-03\n",
      "Final parameters: [[0.9847147  1.985658   0.41749558 1.0362419  0.5502125  0.59922785\n",
      "  0.8947115  0.41784897 0.71757126 1.6697627 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [369/500], Cumulative Loss: 0.3573, LR: 1.000e-03\n",
      "Final parameters: [[1.0405966  1.2548778  1.0673465  1.0754428  0.8070309  0.9096961\n",
      "  1.2835069  0.93488324 0.92797554 1.435179  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [370/500], Cumulative Loss: 0.7501, LR: 1.000e-03\n",
      "Final parameters: [[ 9.9562925e-01  2.4835937e+00  6.0268599e-01  1.0330551e+00\n",
      "  -3.2319790e-01  1.7961860e-03  1.0656723e+00  2.3485024e-01\n",
      "   4.8457608e-02  2.1554980e+00]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [371/500], Cumulative Loss: 0.9065, LR: 1.000e-03\n",
      "Final parameters: [[ 9.4868344e-01  2.7428062e+00 -3.0153245e-02  1.1153483e+00\n",
      "  -3.3832219e-01  1.3220124e-01  1.0105231e+00  1.4804453e-03\n",
      "   2.2691423e-01  2.3414366e+00]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [372/500], Cumulative Loss: 0.3768, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0062335e+00  3.0142229e+00 -9.3891144e-02  1.1410676e+00\n",
      "  -2.7341840e-01  1.9003749e-03  8.6894405e-01 -3.0211663e-01\n",
      "   2.3634443e-01  2.6140101e+00]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [373/500], Cumulative Loss: 1.7747, LR: 1.000e-03\n",
      "Final parameters: [[0.91095686 1.157736   1.1932205  0.9372751  0.6582048  0.6263789\n",
      "  1.0854176  0.89572    0.7247099  1.3951585 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [374/500], Cumulative Loss: 0.1135, LR: 1.000e-03\n",
      "Final parameters: [[1.1871139  2.132915   0.5393323  1.2520441  0.6485022  0.70217633\n",
      "  1.0147314  0.4451449  0.78246415 1.7471775 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [375/500], Cumulative Loss: 0.6140, LR: 1.000e-03\n",
      "Final parameters: [[0.98893744 0.5414251  1.5240171  1.0207391  1.1837357  1.0924047\n",
      "  0.9456719  1.1592757  0.9559959  0.6571255 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [376/500], Cumulative Loss: 0.1783, LR: 1.000e-03\n",
      "Final parameters: [[1.1120666  2.1380744  0.6041841  1.2004551  0.41691378 0.6702869\n",
      "  1.2001997  0.42847866 0.71384734 2.0109346 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [377/500], Cumulative Loss: 0.2116, LR: 1.000e-03\n",
      "Final parameters: [[1.1404469  2.8444195  0.29052263 1.2574286  0.11962664 0.3096045\n",
      "  1.0765879  0.14635438 0.61453146 2.412165  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [378/500], Cumulative Loss: 0.4692, LR: 1.000e-03\n",
      "Final parameters: [[ 1.2270085e+00  2.9602225e+00 -4.7080383e-02  1.1932362e+00\n",
      "   9.5424965e-02  3.0046549e-01  8.9546436e-01 -4.6283752e-04\n",
      "   5.8124405e-01  2.4229264e+00]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [379/500], Cumulative Loss: 1.4350, LR: 1.000e-03\n",
      "Final parameters: [[1.1395042  2.1616228  0.4860923  1.1506745  0.51299    0.53598\n",
      "  0.9172116  0.36359465 0.83830774 1.8363848 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [380/500], Cumulative Loss: 1.1447, LR: 1.000e-03\n",
      "Final parameters: [[1.0616038  2.3088088  0.54509926 1.1836278  0.26495504 0.42953992\n",
      "  1.0588037  0.46818176 0.49972773 2.0960479 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [381/500], Cumulative Loss: 0.5720, LR: 1.000e-03\n",
      "Final parameters: [[ 1.3684529   3.7235894  -0.8421811   1.1376941  -0.5497503   0.02637534\n",
      "   0.6078758  -0.47970134  0.4480047   2.9894917 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [382/500], Cumulative Loss: 0.9133, LR: 1.000e-03\n",
      "Final parameters: [[0.7520423  0.14333746 1.2768791  0.84667486 1.4989959  1.3914291\n",
      "  0.90695095 1.3753486  1.2710619  0.18110538]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [383/500], Cumulative Loss: 0.4772, LR: 1.000e-03\n",
      "Final parameters: [[1.1685336  1.4894058  0.91617626 1.0503968  0.68578607 0.8133916\n",
      "  1.0490363  0.83464164 0.8409405  1.328172  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [384/500], Cumulative Loss: 0.4726, LR: 1.000e-03\n",
      "Final parameters: [[0.90495425 0.01409943 1.4622949  0.73601794 1.229733   1.1499366\n",
      "  0.85785574 1.5744088  1.0988078  0.29720324]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [385/500], Cumulative Loss: 0.3149, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0647414   2.5584252  -0.02605303  0.96620095 -0.09584964  0.20214914\n",
      "   0.83749115  0.13302022  0.43348724  2.3831532 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [386/500], Cumulative Loss: 0.5477, LR: 1.000e-03\n",
      "Final parameters: [[ 1.2068114   2.52963    -0.06240433  1.1064981   0.3718682   0.61436474\n",
      "   0.77562195  0.08318716  0.72964096  2.004254  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [387/500], Cumulative Loss: 0.6331, LR: 1.000e-03\n",
      "Final parameters: [[1.0380607  0.7174641  0.72097456 0.87683034 1.127494   1.1426429\n",
      "  0.85364217 0.8815393  1.1012869  0.7480642 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [388/500], Cumulative Loss: 1.0712, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1427144   2.263222   -0.10252897  1.0520428   0.6331017   0.7090901\n",
      "   0.75488114  0.34881306  0.98921525  1.8016382 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [389/500], Cumulative Loss: 0.4260, LR: 1.000e-03\n",
      "Final parameters: [[1.3071066  0.33178318 0.91415143 0.94155264 2.028829   1.8368027\n",
      "  0.9389814  1.499442   1.7783624  0.30859423]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [390/500], Cumulative Loss: 0.2256, LR: 1.000e-03\n",
      "Final parameters: [[1.2064388  0.9132384  0.8756997  0.88931274 0.97733426 1.0468521\n",
      "  0.8207964  1.0760968  1.0845616  0.992799  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [391/500], Cumulative Loss: 0.3283, LR: 1.000e-03\n",
      "Final parameters: [[1.1448216  0.3097484  1.5465958  1.0777383  1.8603672  1.6755\n",
      "  1.0121936  1.5928988  1.6830757  0.47781858]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [392/500], Cumulative Loss: 0.5875, LR: 1.000e-03\n",
      "Final parameters: [[1.2352054  2.186423   0.1579821  1.1558211  0.460305   0.6093495\n",
      "  1.0075686  0.49080473 0.9218547  1.9734397 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [393/500], Cumulative Loss: 2.5801, LR: 1.000e-03\n",
      "Final parameters: [[1.1761725  2.2185051  0.66763914 1.1529677  0.2833433  0.6083925\n",
      "  1.0414399  0.6136498  0.73622984 1.7544721 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [394/500], Cumulative Loss: 0.4555, LR: 1.000e-03\n",
      "Final parameters: [[1.0084414  2.2608733  0.34015104 1.1546861  0.4644576  0.47561392\n",
      "  0.93218076 0.2116446  0.7020401  1.8104985 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [395/500], Cumulative Loss: 0.8769, LR: 1.000e-03\n",
      "Final parameters: [[ 1.2435687   2.5428724  -0.15869063  1.0725541   0.29333985  0.4511951\n",
      "   0.61847705  0.04226746  0.71835315  2.0239806 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [396/500], Cumulative Loss: 0.6803, LR: 1.000e-03\n",
      "Final parameters: [[1.0685734  1.7141788  0.4504612  1.0127267  0.50624526 0.6507844\n",
      "  0.73173463 0.44038716 0.6254425  1.3279353 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [397/500], Cumulative Loss: 0.5852, LR: 1.000e-03\n",
      "Final parameters: [[ 1.4458551   3.3266494  -0.51212126  1.310524    0.11447468  0.37258482\n",
      "   0.87396145 -0.09579957  0.81666064  2.6809397 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [398/500], Cumulative Loss: 0.4202, LR: 1.000e-03\n",
      "Final parameters: [[1.0493357  2.5296137  0.11252927 1.0887383  0.29730186 0.42421365\n",
      "  0.8146031  0.13308941 0.5818637  2.1594646 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [399/500], Cumulative Loss: 0.8160, LR: 1.000e-03\n",
      "Final parameters: [[1.0917733  1.8339162  0.28673986 0.9893611  0.7563654  0.7543076\n",
      "  0.6125394  0.47272348 0.8823991  1.1691093 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [400/500], Cumulative Loss: 0.5315, LR: 1.000e-03\n",
      "Final parameters: [[1.0740318  2.2368562  0.30161512 1.1370466  0.1556052  0.40580136\n",
      "  0.89234287 0.1841821  0.4712504  1.7656081 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [401/500], Cumulative Loss: 1.4407, LR: 1.000e-03\n",
      "Final parameters: [[1.0714266  1.623084   0.27791378 0.97836727 0.6819218  0.74924076\n",
      "  0.9518287  0.45634833 0.733459   1.425233  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [402/500], Cumulative Loss: 0.1333, LR: 1.000e-03\n",
      "Final parameters: [[ 1.2228943   2.960567   -0.04883756  1.3102282   0.16325366  0.34410942\n",
      "   0.9501355  -0.1838741   0.43302602  2.5283482 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [403/500], Cumulative Loss: 1.4207, LR: 1.000e-03\n",
      "Final parameters: [[ 1.1757028   2.8525925   0.05400896  1.1978261   0.0208675   0.29111895\n",
      "   0.8687017  -0.0503103   0.42301893  2.3332675 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [404/500], Cumulative Loss: 0.2470, LR: 1.000e-03\n",
      "Final parameters: [[1.0745343  1.5738615  0.8783449  1.1961681  0.86153805 0.9796553\n",
      "  1.0977154  0.8489727  0.9283891  1.4618477 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [405/500], Cumulative Loss: 0.0967, LR: 1.000e-03\n",
      "Final parameters: [[0.85353285 0.89621294 0.8282986  0.95541173 0.8529002  0.9763192\n",
      "  0.8849745  0.766273   0.87000805 1.1480496 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [406/500], Cumulative Loss: 0.3556, LR: 1.000e-03\n",
      "Final parameters: [[1.0333985 1.9860686 0.8526995 1.2866144 0.6589879 0.6656395 1.1200889\n",
      "  0.5156754 0.5126389 1.528077 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [407/500], Cumulative Loss: 1.9502, LR: 1.000e-03\n",
      "Final parameters: [[0.9288499  2.0234494  0.2044873  1.1183413  0.3931595  0.62314695\n",
      "  0.9735342  0.25883436 0.6054126  1.8349065 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [408/500], Cumulative Loss: 1.5209, LR: 1.000e-03\n",
      "Final parameters: [[0.90125906 0.08634107 1.2744713  0.89463264 1.7951534  1.4195071\n",
      "  0.9811437  1.4251807  1.3252578  0.22165956]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [409/500], Cumulative Loss: 0.5317, LR: 1.000e-03\n",
      "Final parameters: [[0.9920902 0.7398434 1.4855855 1.1567228 1.1075519 1.1969626 1.3902314\n",
      "  1.431373  1.0228899 1.068301 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [410/500], Cumulative Loss: 1.2209, LR: 1.000e-03\n",
      "Final parameters: [[1.0319924  2.125787   0.4667666  1.1496289  0.05096667 0.35298356\n",
      "  1.1793268  0.40408343 0.58891696 2.239095  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [411/500], Cumulative Loss: 0.9404, LR: 1.000e-03\n",
      "Final parameters: [[1.215463   1.2159834  1.0587277  1.0558743  0.92111665 0.9847042\n",
      "  1.0767974  1.0717818  0.9994997  1.1952342 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [412/500], Cumulative Loss: 1.9957, LR: 1.000e-03\n",
      "Final parameters: [[1.0231249  0.7365743  0.84382725 0.95241404 1.3437699  1.2543972\n",
      "  0.835147   1.1517168  1.3201956  0.8052786 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [413/500], Cumulative Loss: 2.4359, LR: 1.000e-03\n",
      "Final parameters: [[0.7832109 0.4121494 1.1500117 1.0118532 1.237598  1.2413266 1.0516204\n",
      "  1.1877174 1.1285148 0.7139989]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [414/500], Cumulative Loss: 0.4738, LR: 1.000e-03\n",
      "Final parameters: [[1.0928861  1.2510654  0.7607101  0.9805411  1.0007486  0.88413376\n",
      "  0.802343   0.73373824 0.84202206 0.73765755]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [415/500], Cumulative Loss: 0.4826, LR: 1.000e-03\n",
      "Final parameters: [[1.2882179  2.34374    0.3267859  1.161111   0.37461454 0.6067772\n",
      "  0.9179578  0.3759863  0.69004506 1.9159341 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [416/500], Cumulative Loss: 1.6676, LR: 1.000e-03\n",
      "Final parameters: [[0.81433845 0.8372726  0.73881626 0.97336745 0.9735836  0.97561705\n",
      "  0.96996325 0.96959007 1.0616809  0.97783506]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [417/500], Cumulative Loss: 0.4103, LR: 1.000e-03\n",
      "Final parameters: [[0.99968874 0.97580385 0.71069807 0.86797965 0.76871383 0.988986\n",
      "  0.85411906 0.89339304 0.9996405  1.007101  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [418/500], Cumulative Loss: 0.6424, LR: 1.000e-03\n",
      "Final parameters: [[1.0093639  1.742845   0.8179263  1.0090475  0.04354379 0.29347464\n",
      "  1.0326761  0.6860645  0.4413208  1.6477811 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [419/500], Cumulative Loss: 1.2627, LR: 1.000e-03\n",
      "Final parameters: [[1.1218656  0.18207312 1.036189   0.86137843 1.8418826  1.5997806\n",
      "  0.69558644 1.2836406  1.3872561  0.01903763]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [420/500], Cumulative Loss: 1.1996, LR: 1.000e-03\n",
      "Final parameters: [[0.7861104  1.3944783  0.65645814 0.87569207 0.45711166 0.6167179\n",
      "  1.0866133  0.75051314 0.7443377  1.5178772 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [421/500], Cumulative Loss: 1.0853, LR: 1.000e-03\n",
      "Final parameters: [[1.1659828  2.0210762  0.09030685 1.0934538  0.8232452  0.86738497\n",
      "  0.816008   0.45860642 1.0503774  1.6939254 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [422/500], Cumulative Loss: 2.0299, LR: 1.000e-03\n",
      "Final parameters: [[1.1058608 0.9643805 0.6600418 0.9998125 1.3700686 1.3355322 0.8238817\n",
      "  1.0739413 1.3592807 1.0118599]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [423/500], Cumulative Loss: 1.7522, LR: 1.000e-03\n",
      "Final parameters: [[1.2447805  2.354728   0.136729   1.2036408  0.6824384  0.8607315\n",
      "  0.6673685  0.41921437 0.8691497  1.8685403 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [424/500], Cumulative Loss: 0.4318, LR: 1.000e-03\n",
      "Final parameters: [[1.2718899  2.67486    0.14210172 1.1939889  0.16802907 0.5082137\n",
      "  0.9157116  0.23523942 0.70173687 2.252725  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [425/500], Cumulative Loss: 0.6539, LR: 1.000e-03\n",
      "Final parameters: [[1.1168545  2.41329    0.14954053 1.1896496  0.47907817 0.61890864\n",
      "  0.75342244 0.21977334 0.7928575  2.0417552 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [426/500], Cumulative Loss: 1.3931, LR: 1.000e-03\n",
      "Final parameters: [[0.9084684  1.2175875  0.73250544 1.0154557  1.0041201  0.9438966\n",
      "  0.88932693 0.76700276 1.0320634  0.93005687]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [427/500], Cumulative Loss: 0.5330, LR: 1.000e-03\n",
      "Final parameters: [[1.1667457  0.7208113  1.2080975  0.924126   1.1897651  1.0887903\n",
      "  0.7851354  1.2339549  0.98928535 0.52708614]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [428/500], Cumulative Loss: 0.2339, LR: 1.000e-03\n",
      "Final parameters: [[0.9877596  1.6959504  0.921964   1.1486609  0.40548602 0.6413712\n",
      "  0.89372134 0.5422689  0.5868726  1.5454429 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [429/500], Cumulative Loss: 0.3791, LR: 1.000e-03\n",
      "Final parameters: [[1.155765   1.4039726  0.94148856 1.1952468  0.8536127  0.8842679\n",
      "  0.9872327  0.7485557  0.74571866 1.1995409 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [430/500], Cumulative Loss: 0.3068, LR: 1.000e-03\n",
      "Final parameters: [[1.063563   0.57927376 0.5473902  0.7683822  1.4226717  1.2594365\n",
      "  0.6504116  0.9493177  1.2264653  0.37757117]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [431/500], Cumulative Loss: 1.0380, LR: 1.000e-03\n",
      "Final parameters: [[1.2259796  0.4766289  0.8118104  0.95260245 1.3148111  1.4356314\n",
      "  0.8176434  1.2556539  1.3916739  0.71344805]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [432/500], Cumulative Loss: 0.3879, LR: 1.000e-03\n",
      "Final parameters: [[ 1.2764907   2.523379   -0.3356266   1.0351921   0.41786587  0.53985274\n",
      "   0.7111625   0.12428455  0.7702737   2.153625  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [433/500], Cumulative Loss: 0.9811, LR: 1.000e-03\n",
      "Final parameters: [[1.2124935  2.1442425  0.4972208  1.2559351  0.50254965 0.6941947\n",
      "  1.0077724  0.47395867 0.68256843 1.7450942 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [434/500], Cumulative Loss: 1.3060, LR: 1.000e-03\n",
      "Final parameters: [[1.0053571  0.9139188  0.9837482  0.8919246  0.732918   0.9704275\n",
      "  1.0013922  1.1299303  0.96732247 0.9011335 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [435/500], Cumulative Loss: 0.7350, LR: 1.000e-03\n",
      "Final parameters: [[0.90696836 0.9871099  1.2297697  1.1772984  1.4812949  1.2368042\n",
      "  0.9478681  1.0424154  1.2218202  0.6274281 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [436/500], Cumulative Loss: 0.0713, LR: 1.000e-03\n",
      "Final parameters: [[0.9456934  0.8898927  0.8891446  1.0490278  1.4065415  1.1944255\n",
      "  0.96111816 0.9865294  1.2403953  0.98464906]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [437/500], Cumulative Loss: 0.2042, LR: 1.000e-03\n",
      "Final parameters: [[1.2573855  0.87112397 0.545445   0.98522806 1.4182484  1.2693186\n",
      "  0.8170479  0.9643586  1.2935387  0.7426877 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [438/500], Cumulative Loss: 0.2618, LR: 1.000e-03\n",
      "Final parameters: [[0.8624569 1.7429703 0.77923   0.9887146 0.2028654 0.5711751 1.2413282\n",
      "  0.9163102 0.795809  2.0020907]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [439/500], Cumulative Loss: 0.7381, LR: 1.000e-03\n",
      "Final parameters: [[1.1106056  0.96580476 1.1940832  1.1322395  1.2272071  1.191076\n",
      "  1.0505534  1.095032   1.0357035  0.69625235]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [440/500], Cumulative Loss: 1.9381, LR: 1.000e-03\n",
      "Final parameters: [[1.0879302  1.7478482  0.8058785  1.0179956  0.5709629  0.7948302\n",
      "  0.91959465 0.6841587  0.77543867 1.25398   ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [441/500], Cumulative Loss: 0.4436, LR: 1.000e-03\n",
      "Final parameters: [[1.0549183  0.5063945  1.1947563  0.9829788  1.73488    1.536082\n",
      "  0.9733013  1.2519181  1.5386307  0.40484768]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [442/500], Cumulative Loss: 1.3432, LR: 1.000e-03\n",
      "Final parameters: [[1.163614   1.7632343  0.6511209  1.0772673  0.7275504  0.8742076\n",
      "  0.8806988  0.5811019  0.84044945 1.4246179 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [443/500], Cumulative Loss: 0.2438, LR: 1.000e-03\n",
      "Final parameters: [[0.95968634 1.2871302  0.91105384 0.98892933 0.9343643  0.85979414\n",
      "  0.97963756 0.8153759  0.90431815 1.2070943 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [444/500], Cumulative Loss: 0.3421, LR: 1.000e-03\n",
      "Final parameters: [[0.88922197 0.4728122  0.6642077  0.82444805 1.2891362  1.1978363\n",
      "  0.6958986  1.1006178  1.2204382  0.62819886]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [445/500], Cumulative Loss: 1.2875, LR: 1.000e-03\n",
      "Final parameters: [[ 0.8253052  -0.10770848  1.3107488   0.6804539   1.593213    1.430031\n",
      "   0.9477877   1.5613959   1.4785942   0.08256231]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [446/500], Cumulative Loss: 1.1776, LR: 1.000e-03\n",
      "Final parameters: [[1.0136815  0.00529985 1.024807   0.94831395 2.1122267  1.7435195\n",
      "  0.74291575 1.4278772  1.679755   0.12232062]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [447/500], Cumulative Loss: 1.0185, LR: 1.000e-03\n",
      "Final parameters: [[1.2028025  1.0611705  1.0281391  1.0354496  0.92184824 0.9201935\n",
      "  1.0824875  0.90185285 0.8693665  1.0892823 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [448/500], Cumulative Loss: 0.3566, LR: 1.000e-03\n",
      "Final parameters: [[0.904925   1.8075365  0.69134724 0.92897195 0.13892114 0.32253885\n",
      "  1.006169   0.64982677 0.59438246 1.8027776 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [449/500], Cumulative Loss: 0.4295, LR: 1.000e-03\n",
      "Final parameters: [[0.7275745  0.08113363 1.1211734  0.85640824 1.1692569  1.1692758\n",
      "  0.92823565 1.2550871  1.1485023  0.508989  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [450/500], Cumulative Loss: 0.2833, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0059257   2.2191765   0.42120793  0.9931245  -0.12170279  0.24923292\n",
      "   1.0230258   0.46868616  0.30867192  2.0531461 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [451/500], Cumulative Loss: 0.6285, LR: 1.000e-03\n",
      "Final parameters: [[1.038124   1.1155262  1.4322712  1.0180509  0.95301485 0.861674\n",
      "  1.1535616  1.1249421  0.9148871  1.1289154 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [452/500], Cumulative Loss: 0.6450, LR: 1.000e-03\n",
      "Final parameters: [[0.9600253  0.72156787 0.9610069  0.8354147  0.9489552  0.9870431\n",
      "  0.8149435  1.090041   1.0398262  0.80550754]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [453/500], Cumulative Loss: 0.0695, LR: 1.000e-03\n",
      "Final parameters: [[1.1675931  1.7217064  0.7666444  0.9632771  0.24147636 0.4037497\n",
      "  0.91736996 0.6079719  0.51344913 1.6059669 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [454/500], Cumulative Loss: 1.2832, LR: 1.000e-03\n",
      "Final parameters: [[1.0835502  0.32185453 1.4297185  0.9542477  1.6511078  1.3203855\n",
      "  0.9127415  1.4264979  1.3078951  0.14109169]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [455/500], Cumulative Loss: 1.0081, LR: 1.000e-03\n",
      "Final parameters: [[1.0894228  1.269129   1.2019658  0.8961237  0.37871164 0.60411495\n",
      "  1.0523274  1.010345   0.7144312  1.5038539 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [456/500], Cumulative Loss: 0.1103, LR: 1.000e-03\n",
      "Final parameters: [[ 0.89751786 -0.55570126  2.0019286   0.7831179   1.8762444   1.6769369\n",
      "   1.1608037   1.9615377   1.4614409  -0.13693397]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [457/500], Cumulative Loss: 0.4380, LR: 1.000e-03\n",
      "Final parameters: [[ 0.87503535 -0.8353794   2.2407403   0.96770906  2.0685372   1.7176641\n",
      "   1.1102479   2.1775818   1.7085514  -0.5710856 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [458/500], Cumulative Loss: 0.7470, LR: 1.000e-03\n",
      "Final parameters: [[0.90085316 0.08672483 1.675249   0.7120831  1.3096458  1.0461199\n",
      "  1.004527   1.4663365  0.940787   0.02428403]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [459/500], Cumulative Loss: 0.5497, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0985103   2.3991592   0.15471207  1.2006865  -0.0822126   0.35177234\n",
      "   1.16017     0.17958882  0.39760143  2.2728639 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [460/500], Cumulative Loss: 0.3072, LR: 1.000e-03\n",
      "Final parameters: [[0.9573168  1.0652312  0.9895227  0.9529611  0.9206874  0.90989316\n",
      "  1.0754309  0.9968112  0.91260374 1.0549535 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [461/500], Cumulative Loss: 1.1535, LR: 1.000e-03\n",
      "Final parameters: [[0.8370977  1.2089542  0.9161381  0.9650613  0.5947653  0.56194884\n",
      "  1.1346282  0.81327015 0.6722497  1.3371751 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [462/500], Cumulative Loss: 0.2817, LR: 1.000e-03\n",
      "Final parameters: [[1.0995886  1.1070055  0.98182464 0.88975215 0.69354415 0.6948713\n",
      "  1.0069184  0.840076   0.78904825 1.0684869 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [463/500], Cumulative Loss: 0.1396, LR: 1.000e-03\n",
      "Final parameters: [[0.905323   1.8547636  0.5779757  1.1692393  0.5192057  0.5735126\n",
      "  1.2059443  0.56372744 0.766381   1.8855906 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [464/500], Cumulative Loss: 0.0962, LR: 1.000e-03\n",
      "Final parameters: [[1.0512145  2.7292283  0.42432445 1.3368063  0.08144376 0.3123059\n",
      "  1.0300285  0.17348626 0.53013206 2.4373927 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [465/500], Cumulative Loss: 0.6410, LR: 1.000e-03\n",
      "Final parameters: [[1.0038017  1.4622893  0.74493337 0.9475389  0.6664403  0.7128299\n",
      "  0.8424979  0.6847312  0.73053163 1.1813397 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [466/500], Cumulative Loss: 0.6745, LR: 1.000e-03\n",
      "Final parameters: [[0.9559733  0.6315222  1.097971   0.8574616  0.98155105 0.9699792\n",
      "  1.0953403  1.1280941  0.8674904  0.8160988 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [467/500], Cumulative Loss: 0.4552, LR: 1.000e-03\n",
      "Final parameters: [[1.1143388  1.9652002  0.5508821  1.06803    0.16955452 0.40194184\n",
      "  1.0175271  0.42316416 0.5302804  1.8591189 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [468/500], Cumulative Loss: 0.4724, LR: 1.000e-03\n",
      "Final parameters: [[0.97899365 1.4980474  0.9028436  1.0550646  0.5138491  0.52609867\n",
      "  1.3070251  0.73209584 0.54779935 1.5282005 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [469/500], Cumulative Loss: 0.4196, LR: 1.000e-03\n",
      "Final parameters: [[0.9732523  1.5971905  0.9232723  1.1154985  0.774131   0.5780238\n",
      "  1.1871072  0.74942046 0.76873946 1.310396  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [470/500], Cumulative Loss: 0.1475, LR: 1.000e-03\n",
      "Final parameters: [[ 0.73996586  1.7556354   0.5931096   0.8836091  -0.03399913  0.16849597\n",
      "   0.9847204   0.43418682  0.32673144  1.6032951 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [471/500], Cumulative Loss: 0.9657, LR: 1.000e-03\n",
      "Final parameters: [[0.818945   1.0904988  0.9926846  1.0394261  0.9127074  0.8316707\n",
      "  1.1629128  0.94381255 0.87186736 1.0983734 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [472/500], Cumulative Loss: 0.5340, LR: 1.000e-03\n",
      "Final parameters: [[0.8628987  1.0668138  1.1505724  1.0248747  0.88221955 0.7344496\n",
      "  1.252571   0.95457214 0.68371904 1.1157554 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [473/500], Cumulative Loss: 0.3349, LR: 1.000e-03\n",
      "Final parameters: [[ 0.82876885  1.7865629   1.1290073   1.1373097  -0.04952399  0.09796762\n",
      "   1.3374225   0.7277957   0.28412437  1.5757467 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [474/500], Cumulative Loss: 0.3748, LR: 1.000e-03\n",
      "Final parameters: [[ 0.83415574 -0.50270426  2.2576034   0.9074513   1.3296711   1.2221229\n",
      "   1.3654819   1.8878082   0.92255986  0.10044858]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [475/500], Cumulative Loss: 0.4394, LR: 1.000e-03\n",
      "Final parameters: [[0.7624304  1.1176581  0.9086149  1.0065153  0.8318571  0.8016822\n",
      "  1.0249922  0.8066416  0.80117106 1.188569  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [476/500], Cumulative Loss: 1.8229, LR: 1.000e-03\n",
      "Final parameters: [[1.0768585  1.9862567  0.84095305 1.0321491  0.09713382 0.2926086\n",
      "  1.233462   0.63423157 0.38616002 1.7928902 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [477/500], Cumulative Loss: 0.7704, LR: 1.000e-03\n",
      "Final parameters: [[ 0.799864    3.7298381  -0.0637482   1.2227087  -1.22429    -0.5986877\n",
      "   1.2842133  -0.48059356 -0.32157338  3.567473  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [478/500], Cumulative Loss: 0.4073, LR: 1.000e-03\n",
      "Final parameters: [[0.9786863  1.4801829  0.95015854 1.0910363  0.7981119  0.81689423\n",
      "  1.1509405  0.8202066  0.88939416 1.4446021 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [479/500], Cumulative Loss: 0.4399, LR: 1.000e-03\n",
      "Final parameters: [[ 0.9547616   3.4841821   0.22842477  1.2619678  -0.8138941  -0.33754283\n",
      "   1.196178   -0.31552613 -0.15183382  3.0002773 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [480/500], Cumulative Loss: 0.3397, LR: 1.000e-03\n",
      "Final parameters: [[1.091671   1.2125915  1.0229537  1.0757127  0.9974053  0.9065236\n",
      "  1.1622561  1.0495683  0.99678993 1.2468288 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [481/500], Cumulative Loss: 0.6653, LR: 1.000e-03\n",
      "Final parameters: [[0.88624567 1.2575604  1.3078026  1.1327477  0.53003776 0.5904844\n",
      "  1.3599055  0.9834203  0.68354034 1.5913479 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [482/500], Cumulative Loss: 0.3325, LR: 1.000e-03\n",
      "Final parameters: [[ 1.0201930e+00  2.6537070e+00  1.1430000e-01  9.8589611e-01\n",
      "  -4.6660292e-01  1.3238192e-03  8.0066299e-01  3.8633458e-02\n",
      "   2.5322396e-01  2.3366237e+00]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [483/500], Cumulative Loss: 0.3458, LR: 1.000e-03\n",
      "Final parameters: [[0.8417701 0.8521917 0.9187718 1.0582883 1.1585199 1.0967836 1.1527387\n",
      "  1.0316018 1.1143742 1.0247078]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [484/500], Cumulative Loss: 0.6654, LR: 1.000e-03\n",
      "Final parameters: [[0.97866344 2.1294844  0.8017968  1.1705351  0.16110468 0.30353767\n",
      "  1.3076996  0.41328076 0.42200905 2.2351038 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [485/500], Cumulative Loss: 0.5518, LR: 1.000e-03\n",
      "Final parameters: [[1.0960402  1.3427061  0.8715377  1.1417676  0.8190142  0.78840274\n",
      "  1.1474689  0.82578814 0.9745784  1.5137675 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [486/500], Cumulative Loss: 0.2568, LR: 1.000e-03\n",
      "Final parameters: [[1.0037841  1.9518101  0.2625419  0.9256445  0.09904486 0.41095978\n",
      "  0.7138969  0.40576944 0.5997882  1.8116317 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [487/500], Cumulative Loss: 0.9300, LR: 1.000e-03\n",
      "Final parameters: [[0.9253367  1.0371324  1.2105058  1.0388608  0.75135905 0.8262931\n",
      "  1.290177   1.0518105  0.8060175  1.2429687 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [488/500], Cumulative Loss: 0.4463, LR: 1.000e-03\n",
      "Final parameters: [[0.86471283 0.9887572  1.1612542  0.93202853 0.93437856 0.98249924\n",
      "  0.99468    1.0614122  1.0536058  0.873043  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [489/500], Cumulative Loss: 1.7916, LR: 1.000e-03\n",
      "Final parameters: [[1.0928922 1.4510641 0.8978543 1.0099003 0.7322892 0.6489545 1.0145878\n",
      "  0.8317404 0.9279179 1.710772 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [490/500], Cumulative Loss: 0.8340, LR: 1.000e-03\n",
      "Final parameters: [[0.92879087 1.55608    0.7255997  1.0301257  0.68341243 0.61451507\n",
      "  1.0620103  0.76034087 0.7784461  1.3879905 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [491/500], Cumulative Loss: 0.2101, LR: 1.000e-03\n",
      "Final parameters: [[1.1108137  2.011209   0.14281817 1.0349596  0.26072535 0.48618\n",
      "  0.77898467 0.3783688  0.6870739  1.7203661 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [492/500], Cumulative Loss: 0.4421, LR: 1.000e-03\n",
      "Final parameters: [[1.0055355  1.4224007  0.55550504 0.94407904 0.59327495 0.7711413\n",
      "  0.84687567 0.6258891  0.729632   1.2895768 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [493/500], Cumulative Loss: 0.6338, LR: 1.000e-03\n",
      "Final parameters: [[0.80082995 0.70768344 1.1369913  0.9066244  1.1492618  1.0235623\n",
      "  0.98868334 0.9875204  0.980675   0.7146156 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [494/500], Cumulative Loss: 0.7533, LR: 1.000e-03\n",
      "Final parameters: [[1.2006761  1.6695155  0.24037331 0.9406185  0.33801576 0.54977083\n",
      "  0.86667204 0.47320253 0.71181893 1.5052088 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [495/500], Cumulative Loss: 1.8708, LR: 1.000e-03\n",
      "Final parameters: [[0.80789816 0.25690004 1.3641194  0.9149462  1.3501651  1.2246567\n",
      "  0.9584255  1.2972271  1.1773648  0.4596102 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [496/500], Cumulative Loss: 0.8260, LR: 1.000e-03\n",
      "Final parameters: [[0.9826684  1.5499694  0.52365386 1.0539905  0.9545817  0.9727906\n",
      "  0.8634844  0.5456395  0.9017376  1.1618791 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [497/500], Cumulative Loss: 0.8914, LR: 1.000e-03\n",
      "Final parameters: [[0.9646432  0.00238036 1.8815064  1.0477681  1.508371   1.3686011\n",
      "  1.2007127  1.7085284  1.2122644  0.22649114]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [498/500], Cumulative Loss: 2.1010, LR: 1.000e-03\n",
      "Final parameters: [[1.1378706  0.78853834 1.4455991  0.9293646  1.3089125  1.1664416\n",
      "  0.8770762  1.4081713  1.1760831  0.59049815]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [499/500], Cumulative Loss: 1.4475, LR: 1.000e-03\n",
      "Final parameters: [[1.1886725  1.4532318  0.9716538  1.162776   0.98043245 0.8803995\n",
      "  1.0477062  0.91282415 0.9185037  1.3855206 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [500/500], Cumulative Loss: 0.6814, LR: 1.000e-03\n",
      "Final parameters: [[ 0.87943935 -0.45526436  1.6440914   0.8036576   1.9462886   1.6122671\n",
      "   0.9111839   1.595201    1.5413071  -0.09139171]]\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "n = 10\n",
    "W = np.random.randn(n, n)\n",
    "theta0 = np.ones((n, 1))\n",
    "lstm_optimizer = LSTMConcurrent(num_optims=1)\n",
    "writer = SummaryWriter(\"train/LSTMC_gamma_0_e3\") \n",
    "meta_optimizer = optim.Adam(lstm_optimizer.parameters(), lr=0.001)\n",
    "lstm_optimizer = train_LSTM(lstm_optimizer, meta_optimizer, QuadraticOptimizee, {\"W\": W, \"theta0\": theta0}, num_epochs=500, time_horizon=500, discount=None, writer=writer)\n",
    "writer = SummaryWriter(\"runs/LSTMC_gamma_0_e3\")\n",
    "params = test_LSTM(lstm_optimizer, QuadraticOptimizee, {\"W\": W, \"theta0\": theta0}, time_horizon=1000, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87ddb3d0988402cb9f5e9f8c99cfe95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Shape torch.Size([10, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_22104\\3647760373.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(preprocessed).to(gradients.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Cumulative Loss: 232685.3281, LR: 1.000e-04\n",
      "Final parameters: [[-56.50897  -53.47805  -52.255253 -51.560833 -51.361187 -45.479355\n",
      "  -51.359352 -51.721733 -57.24269  -58.77405 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [2/500], Cumulative Loss: 233961.1406, LR: 1.000e-04\n",
      "Final parameters: [[-57.65584  -52.655945 -53.384445 -51.997425 -48.91757  -45.666992\n",
      "  -52.54768  -49.802753 -57.337666 -58.01194 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [3/500], Cumulative Loss: 220886.4531, LR: 1.000e-04\n",
      "Final parameters: [[-55.829365 -52.958355 -51.44749  -50.05098  -47.349697 -45.452236\n",
      "  -50.483547 -48.312386 -56.304104 -57.05438 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [4/500], Cumulative Loss: 211067.3594, LR: 1.000e-04\n",
      "Final parameters: [[-54.646168 -51.203163 -50.09778  -47.298798 -46.586906 -43.33314\n",
      "  -51.113052 -46.601032 -54.7307   -55.285213]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [5/500], Cumulative Loss: 203845.0781, LR: 1.000e-04\n",
      "Final parameters: [[-54.228737 -50.82611  -47.81899  -47.47801  -45.387726 -41.176105\n",
      "  -49.377293 -45.430637 -54.079063 -55.66159 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [6/500], Cumulative Loss: 200588.3594, LR: 1.000e-04\n",
      "Final parameters: [[-53.824856 -48.667747 -49.310646 -46.038696 -44.574223 -41.02467\n",
      "  -49.82002  -46.229553 -54.699356 -53.63795 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [7/500], Cumulative Loss: 156967.2969, LR: 1.000e-04\n",
      "Final parameters: [[-42.192234 -44.011665 -43.55798  -42.87856  -43.221275 -41.63399\n",
      "  -45.515675 -47.009212 -43.865463 -44.707115]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [8/500], Cumulative Loss: 174012.0469, LR: 1.000e-04\n",
      "Final parameters: [[-48.989952 -46.680035 -44.505608 -42.518433 -44.10172  -38.59044\n",
      "  -45.415543 -43.958412 -50.78736  -50.83031 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [9/500], Cumulative Loss: 168211.8594, LR: 1.000e-04\n",
      "Final parameters: [[-50.54274  -45.95334  -43.289337 -44.33793  -40.4187   -37.41309\n",
      "  -42.619396 -43.465668 -50.490894 -49.866856]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [10/500], Cumulative Loss: 134035.8750, LR: 1.000e-04\n",
      "Final parameters: [[-40.965706 -40.13353  -37.87709  -39.61427  -38.851974 -36.810883\n",
      "  -41.726524 -45.24736  -42.606987 -44.011898]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [11/500], Cumulative Loss: 138905.1562, LR: 1.000e-04\n",
      "Final parameters: [[-42.511276 -42.21214  -38.932392 -37.343422 -38.238827 -36.667274\n",
      "  -41.513268 -39.52553  -48.749382 -46.18144 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [12/500], Cumulative Loss: 142669.1094, LR: 1.000e-04\n",
      "Final parameters: [[-44.54113  -41.014572 -41.09161  -39.63391  -37.395973 -34.321053\n",
      "  -40.121696 -40.84786  -48.732796 -47.65086 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [13/500], Cumulative Loss: 104743.6562, LR: 1.000e-04\n",
      "Final parameters: [[-37.102867 -35.607483 -32.490025 -33.594433 -32.058533 -31.23712\n",
      "  -38.831657 -41.342297 -39.014603 -39.959442]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [14/500], Cumulative Loss: 129128.8359, LR: 1.000e-04\n",
      "Final parameters: [[-43.56097  -41.57664  -36.769413 -36.31644  -34.130215 -32.20028\n",
      "  -39.171368 -38.089325 -46.568855 -46.617188]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [15/500], Cumulative Loss: 96298.6719, LR: 1.000e-04\n",
      "Final parameters: [[-34.01989  -32.10178  -34.29507  -33.27114  -30.298567 -29.881351\n",
      "  -36.896957 -40.613655 -37.365402 -35.997246]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [16/500], Cumulative Loss: 114002.4375, LR: 1.000e-04\n",
      "Final parameters: [[-42.3865   -37.38071  -34.556892 -33.727177 -31.846352 -30.414244\n",
      "  -36.585537 -37.256844 -44.94616  -43.151615]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [17/500], Cumulative Loss: 115328.7891, LR: 1.000e-04\n",
      "Final parameters: [[-42.20238  -37.617413 -37.417007 -33.698788 -32.16982  -30.150646\n",
      "  -37.057266 -37.217224 -41.027508 -42.05649 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [18/500], Cumulative Loss: 100998.1172, LR: 1.000e-04\n",
      "Final parameters: [[-38.10898  -34.296818 -33.98997  -32.19099  -29.252022 -26.203625\n",
      "  -35.297737 -35.104725 -41.68018  -40.734787]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [19/500], Cumulative Loss: 66759.1875, LR: 1.000e-04\n",
      "Final parameters: [[-28.233078 -28.459108 -26.796463 -25.681171 -26.336416 -25.552504\n",
      "  -30.83089  -33.32442  -31.608156 -30.237926]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [20/500], Cumulative Loss: 65390.8086, LR: 1.000e-04\n",
      "Final parameters: [[-27.72829  -27.539797 -25.523346 -26.955381 -24.775702 -23.528412\n",
      "  -31.83158  -33.278378 -30.828875 -29.601076]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [21/500], Cumulative Loss: 83874.2188, LR: 1.000e-04\n",
      "Final parameters: [[-36.41789  -32.55679  -29.570585 -27.855642 -25.871426 -23.867628\n",
      "  -31.74603  -32.427025 -38.74901  -38.818863]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [22/500], Cumulative Loss: 75965.2344, LR: 1.000e-04\n",
      "Final parameters: [[-33.4967   -30.91957  -29.616592 -25.4164   -25.08235  -24.089346\n",
      "  -30.34387  -30.308624 -36.8834   -36.30955 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [23/500], Cumulative Loss: 63962.9414, LR: 1.000e-04\n",
      "Final parameters: [[-30.275955 -29.177135 -26.15778  -23.092434 -23.467329 -23.422232\n",
      "  -27.74627  -27.335941 -33.155655 -35.77562 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [24/500], Cumulative Loss: 66559.2500, LR: 1.000e-04\n",
      "Final parameters: [[-32.224777 -26.899176 -26.202604 -24.049904 -21.974546 -22.084835\n",
      "  -30.606092 -29.73845  -35.784306 -34.47449 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [25/500], Cumulative Loss: 61105.6875, LR: 1.000e-04\n",
      "Final parameters: [[-31.509422 -27.047112 -23.994421 -22.077053 -21.886156 -19.830978\n",
      "  -28.180681 -28.030455 -35.016224 -33.08186 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [26/500], Cumulative Loss: 22923.6289, LR: 1.000e-04\n",
      "Final parameters: [[-16.149715  -17.883644  -14.739769  -15.2120495 -14.313002  -17.111015\n",
      "  -17.479355  -17.160263  -16.781305  -17.670792 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [27/500], Cumulative Loss: 33033.2930, LR: 1.000e-04\n",
      "Final parameters: [[-20.722256 -20.032438 -17.032158 -17.614292 -16.461853 -16.266748\n",
      "  -22.909525 -26.014973 -22.216248 -21.422232]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [28/500], Cumulative Loss: 29282.2617, LR: 1.000e-04\n",
      "Final parameters: [[-19.590137  -16.303413  -17.097008  -15.4979515 -16.562057  -17.077038\n",
      "  -21.545849  -25.291044  -22.77261   -19.814808 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [29/500], Cumulative Loss: 25164.2773, LR: 1.000e-04\n",
      "Final parameters: [[-17.43818  -15.200351 -15.859236 -15.634609 -14.071601 -15.300219\n",
      "  -20.619137 -22.920227 -19.350397 -19.088543]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [30/500], Cumulative Loss: 15977.2656, LR: 1.000e-04\n",
      "Final parameters: [[-14.167202  -12.386565  -12.714916  -13.440448  -11.143919  -15.6764145\n",
      "  -15.014947  -14.476528  -12.881016  -15.0597105]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [31/500], Cumulative Loss: 36078.1055, LR: 1.000e-04\n",
      "Final parameters: [[-23.293913 -21.226955 -17.11995  -16.228096 -14.992078 -15.424226\n",
      "  -20.919018 -21.625414 -30.731852 -29.78817 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [32/500], Cumulative Loss: 25170.1172, LR: 1.000e-04\n",
      "Final parameters: [[-20.632412 -16.608688 -15.281336 -13.492327 -10.876769 -13.335574\n",
      "  -17.578663 -19.048763 -25.246536 -23.069973]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [33/500], Cumulative Loss: 11918.1074, LR: 1.000e-04\n",
      "Final parameters: [[-11.657584 -11.968898 -11.076998 -11.243674 -10.940709 -13.077254\n",
      "  -10.543127 -12.231417 -13.029559 -10.464711]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [34/500], Cumulative Loss: 22657.5840, LR: 1.000e-04\n",
      "Final parameters: [[-21.059725 -17.346973 -12.700705 -10.894441 -10.176132 -11.382112\n",
      "  -16.667185 -18.990992 -23.840115 -23.679932]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [35/500], Cumulative Loss: 20465.7461, LR: 1.000e-04\n",
      "Final parameters: [[-18.466467 -15.56761  -12.969521 -10.559508 -10.239201 -11.179628\n",
      "  -16.043068 -15.968144 -22.6946   -21.854317]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [36/500], Cumulative Loss: 17959.3242, LR: 1.000e-04\n",
      "Final parameters: [[-19.101181  -12.865521  -10.216216   -9.625509   -7.4501467  -8.567338\n",
      "  -16.154348  -18.304062  -24.52245   -22.098204 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [37/500], Cumulative Loss: 1060.5953, LR: 1.000e-04\n",
      "Final parameters: [[-2.3128414 -2.368418  -2.3632312 -2.3858325 -1.8439204 -1.5913142\n",
      "  -4.202665  -4.4114213 -3.4827545 -1.8773392]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [38/500], Cumulative Loss: 1275.3649, LR: 1.000e-04\n",
      "Final parameters: [[-1.2657465 -4.260396  -1.7468742 -3.1839628 -3.677814  -4.916438\n",
      "  -3.488842  -3.521343  -2.8563194 -2.6729965]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [39/500], Cumulative Loss: 11368.3174, LR: 1.000e-04\n",
      "Final parameters: [[-16.052193  -10.147913  -10.377614   -6.71926    -4.8033104  -5.886077\n",
      "   -8.897309  -13.59777   -20.765377  -17.803114 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [40/500], Cumulative Loss: 4775.4365, LR: 1.000e-04\n",
      "Final parameters: [[ -8.9751005  -7.3528214  -6.0063252  -3.471373   -2.8110886  -3.2413514\n",
      "   -4.7168283  -6.951614  -13.446709  -13.691054 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [41/500], Cumulative Loss: 3548.1328, LR: 1.000e-04\n",
      "Final parameters: [[ -9.702227   -6.1552367  -3.9641843  -2.2378821  -1.5591998  -0.5205746\n",
      "   -3.6867225  -6.904504  -12.739161   -9.885458 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [42/500], Cumulative Loss: 5583.6602, LR: 1.000e-04\n",
      "Final parameters: [[ -6.893366   -6.228223   -4.161979   -2.9110727 -10.880128  -10.514212\n",
      "   -7.0444345  -6.7712336 -13.484777   -9.844913 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [43/500], Cumulative Loss: 1556.3402, LR: 1.000e-04\n",
      "Final parameters: [[-4.297768   -5.035252   -0.61491555 -2.6954935  -4.3016424  -6.279956\n",
      "  -4.2024083  -3.693032   -2.3041062  -2.845875  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [44/500], Cumulative Loss: 2175.6392, LR: 1.000e-04\n",
      "Final parameters: [[ -6.6571712  -3.0425632  -2.0344088  -1.0684534  -2.9949467  -3.011936\n",
      "   -3.099322   -4.205226  -10.132865   -9.32457  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [45/500], Cumulative Loss: 2820.6826, LR: 1.000e-04\n",
      "Final parameters: [[ -7.007355    -5.3631916    0.12329657  -0.77823514  -2.8576865\n",
      "   -1.4429307   -5.872068    -7.2329774  -11.838286   -12.703129  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [46/500], Cumulative Loss: 657.3380, LR: 1.000e-04\n",
      "Final parameters: [[-6.942771   -3.621059   -0.42532316  0.90882105  4.0220003   2.8934832\n",
      "  -1.756775   -4.9522843  -3.5199418  -5.1680193 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [47/500], Cumulative Loss: 760.5848, LR: 1.000e-04\n",
      "Final parameters: [[-4.356408    2.5423543   1.7413621   2.118279   -5.588739   -4.110547\n",
      "  -0.21954083 -1.8791212  -8.41353    -4.8866277 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [48/500], Cumulative Loss: 445.4529, LR: 1.000e-04\n",
      "Final parameters: [[-2.5213094  -3.9793034   0.11622315 -0.3990864   0.6430476  -4.634161\n",
      "  -1.5911345  -0.07522765  1.7254     -0.04746387]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [49/500], Cumulative Loss: 415.9104, LR: 1.000e-04\n",
      "Final parameters: [[-2.6323483   2.0858254   3.8708868   1.9024457  -3.9711294  -3.3709393\n",
      "  -0.48209965 -2.1509495  -7.8027334  -4.3307323 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [50/500], Cumulative Loss: 74.8691, LR: 1.000e-04\n",
      "Final parameters: [[-1.7263662  -0.6725377   1.9662572   1.7632159   1.1151518   2.1304648\n",
      "  -0.41581082 -0.654923   -0.46655485  0.42357042]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [51/500], Cumulative Loss: 104.3069, LR: 1.000e-04\n",
      "Final parameters: [[-1.7355878  -0.01854429  6.218413    3.3250644   0.22742347 -1.5325751\n",
      "   1.6404467   1.3053153  -3.9378836  -2.3890722 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [52/500], Cumulative Loss: 444.5966, LR: 1.000e-04\n",
      "Final parameters: [[-4.680396   -1.2678115   0.6045221   2.327408    3.821318    3.2879515\n",
      "  -0.42851084 -4.286844   -5.839228   -3.8876104 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [53/500], Cumulative Loss: 155.0401, LR: 1.000e-04\n",
      "Final parameters: [[-2.1071372  -3.4542441   0.04090793  0.5867184   1.6953912  -0.9889373\n",
      "   1.1116129   0.15021668  1.3066921   0.77386093]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [54/500], Cumulative Loss: 657.7585, LR: 1.000e-04\n",
      "Final parameters: [[-2.4897108 -1.0437136  3.2144513  2.0352817 -2.9725528 -1.7921405\n",
      "  -0.7135975 -3.6557052 -8.534753  -3.9428918]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [55/500], Cumulative Loss: 70.2790, LR: 1.000e-04\n",
      "Final parameters: [[ 3.5830164   1.2365286   1.1176343  -1.1360123   1.082398    1.2434369\n",
      "   0.04183584 -0.5986808  -0.33466834  1.9849553 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [56/500], Cumulative Loss: 158.9834, LR: 1.000e-04\n",
      "Final parameters: [[-0.1329849  -1.3693767   1.282531    1.573077   -2.4303858  -0.35618097\n",
      "   1.3716259   0.98572147 -1.6453735   0.99590707]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [57/500], Cumulative Loss: 254.6306, LR: 1.000e-04\n",
      "Final parameters: [[-8.306997   -1.1729953   3.8179069   2.5560148  -0.39018178 -0.93032575\n",
      "   5.2369614   2.3274949  -0.602083   -5.543095  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [58/500], Cumulative Loss: 60.4030, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0115415  -2.7305937   1.7910888   0.8522869   0.6448566   2.1516113\n",
      "  -0.33981013  1.280628    0.99528766  0.56226134]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [59/500], Cumulative Loss: 96.3779, LR: 1.000e-04\n",
      "Final parameters: [[-0.6869537  -1.6810746   4.420868    3.7868009  -0.999481    0.53539246\n",
      "   3.7695596   1.6437033  -2.0261445   0.8165951 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [60/500], Cumulative Loss: 17.3064, LR: 1.000e-04\n",
      "Final parameters: [[ 0.78737366 -0.12024015  2.9140172   1.3609141  -2.645924   -0.0893217\n",
      "   2.1019325   1.2456592  -0.13454452  3.9190123 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [61/500], Cumulative Loss: 17.8652, LR: 1.000e-04\n",
      "Final parameters: [[-0.72682256 -0.81849766  3.1330943   2.0030835  -0.66195303 -0.3568552\n",
      "   2.8661213   1.3659246  -0.0133774   1.8056152 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [62/500], Cumulative Loss: 6.2853, LR: 1.000e-04\n",
      "Final parameters: [[ 0.9164957   0.577965    1.3370426   1.428361    0.12773007 -0.18384475\n",
      "   1.8884541   1.4519757   0.23727793  2.0757565 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [63/500], Cumulative Loss: 67.3125, LR: 1.000e-04\n",
      "Final parameters: [[-0.7340343   0.59980524  4.903772    2.9409869  -2.6841471  -2.8581245\n",
      "   4.306252   -0.53918916 -4.3230724   1.1357452 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [64/500], Cumulative Loss: 3.9113, LR: 1.000e-04\n",
      "Final parameters: [[0.14728072 0.8612958  1.5852654  1.3156682  0.20773068 0.46900344\n",
      "  1.6235119  0.5653627  0.46985853 0.0066581 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [65/500], Cumulative Loss: 310.2887, LR: 1.000e-04\n",
      "Final parameters: [[-9.456658   -2.7550657   8.113132    5.680098   -0.972097    0.41246933\n",
      "   2.956537    2.8231046   2.0205948  -8.394907  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [66/500], Cumulative Loss: 0.2966, LR: 1.000e-04\n",
      "Final parameters: [[1.0640341  0.9132967  0.614674   1.0464574  1.6423928  1.374935\n",
      "  0.71544135 0.8814759  1.3604728  0.449638  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [67/500], Cumulative Loss: 34.4090, LR: 1.000e-04\n",
      "Final parameters: [[-1.1022494   1.286147    2.503797    1.1851563  -0.8933649  -0.92890257\n",
      "   2.9012978  -0.59707505 -1.458714   -2.0697837 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [68/500], Cumulative Loss: 165.4868, LR: 1.000e-04\n",
      "Final parameters: [[-5.549619   -1.5682616   5.098213    4.355172    0.75671744 -0.46226057\n",
      "   2.6952293   2.0118668   2.3089192  -6.0016956 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [69/500], Cumulative Loss: 71.7582, LR: 1.000e-04\n",
      "Final parameters: [[-2.5200002   0.35502285  2.0488458   3.2238033   0.36502546  0.8278035\n",
      "   1.1766828   1.7757134   3.229153   -1.8147815 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [70/500], Cumulative Loss: 0.1746, LR: 1.000e-04\n",
      "Final parameters: [[0.87010694 0.908032   1.3945297  0.9006601  0.5885337  0.67850995\n",
      "  1.2006534  0.99334794 0.5399778  1.1049944 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [71/500], Cumulative Loss: 1.0828, LR: 1.000e-04\n",
      "Final parameters: [[ 0.8073497   0.5282102   1.0330772   1.0562032   1.7604318   1.5598725\n",
      "   0.70398283  1.0183628   1.4995269  -0.55558956]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [72/500], Cumulative Loss: 0.0374, LR: 1.000e-04\n",
      "Final parameters: [[0.9597197  0.63162386 1.0148504  0.9334846  1.3705537  1.2323667\n",
      "  0.89452153 1.150766   1.2537854  0.586216  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [73/500], Cumulative Loss: 0.0374, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1257368   2.8889003   0.20533141  1.1767807  -0.24322788  0.06237126\n",
      "   1.0145208   0.02108675  0.28456783  2.476296  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [74/500], Cumulative Loss: 0.2738, LR: 1.000e-04\n",
      "Final parameters: [[1.0737348  1.7772082  0.4538088  1.0847633  0.7407346  0.7921463\n",
      "  0.89984524 0.5470337  0.87496656 1.4970084 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [75/500], Cumulative Loss: 0.0553, LR: 1.000e-04\n",
      "Final parameters: [[1.0114225  2.0562685  0.5265881  1.0786394  0.18550542 0.40201816\n",
      "  1.0491608  0.42049778 0.53513736 1.9900036 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [76/500], Cumulative Loss: 0.3903, LR: 1.000e-04\n",
      "Final parameters: [[0.6509815  0.63786244 1.9456927  0.96743184 0.22720808 0.49004582\n",
      "  1.5658942  1.2783402  0.38503695 1.4249527 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [77/500], Cumulative Loss: 0.1547, LR: 1.000e-04\n",
      "Final parameters: [[ 0.90797114  2.6553757   0.45079136  1.1227677  -0.52016777 -0.11205164\n",
      "   1.2423573   0.16489449  0.10892094  2.700062  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [78/500], Cumulative Loss: 0.1558, LR: 1.000e-04\n",
      "Final parameters: [[1.0125083  0.44697356 1.1473606  0.93545926 1.4818197  1.3368318\n",
      "  0.9765707  1.2653395  1.2753341  0.5374029 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [79/500], Cumulative Loss: 0.0740, LR: 1.000e-04\n",
      "Final parameters: [[0.9217251  2.082896   0.6216769  1.1154659  0.03787199 0.31378627\n",
      "  1.2324945  0.43429437 0.4375715  2.152188  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [80/500], Cumulative Loss: 0.2446, LR: 1.000e-04\n",
      "Final parameters: [[1.1277354  0.38564473 0.7536889  0.90135026 1.9624076  1.619162\n",
      "  0.6470154  1.2122883  1.7247429  0.07750314]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [81/500], Cumulative Loss: 0.4612, LR: 1.000e-04\n",
      "Final parameters: [[ 1.406261    2.6965265  -0.23970935  1.1471803   0.6046057   0.6461166\n",
      "   0.643991    0.05838631  0.8585031   1.7827561 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [82/500], Cumulative Loss: 0.0067, LR: 1.000e-04\n",
      "Final parameters: [[1.0361161  0.5688196  1.13593    0.9077482  1.2987725  1.1677327\n",
      "  0.89398724 1.1608192  1.0936497  0.51209366]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [83/500], Cumulative Loss: 0.1139, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0151502  -0.8168585   1.337613    0.7696384   2.5815885   2.0994582\n",
      "   0.74648386  1.8419113   1.9775858  -0.812826  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [84/500], Cumulative Loss: 0.4885, LR: 1.000e-04\n",
      "Final parameters: [[0.79679537 1.3211815  1.1137381  1.0700252  0.42168432 0.5847873\n",
      "  1.2688546  0.8819     0.59837997 1.5411578 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [85/500], Cumulative Loss: 0.0515, LR: 1.000e-04\n",
      "Final parameters: [[1.0934838  2.233922   0.31162697 1.1565428  0.41378266 0.58380944\n",
      "  0.9612898  0.30862534 0.6361053  1.788479  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [86/500], Cumulative Loss: 0.1821, LR: 1.000e-04\n",
      "Final parameters: [[0.8492722  0.9042869  1.3867981  1.0379783  0.7308207  0.79687667\n",
      "  1.2362751  1.1534634  0.79842156 1.2125951 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [87/500], Cumulative Loss: 0.0705, LR: 1.000e-04\n",
      "Final parameters: [[1.1908327  2.1340992  0.24409576 1.087059   0.5734474  0.66602135\n",
      "  0.8587715  0.33858532 0.75869304 1.6462343 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [88/500], Cumulative Loss: 0.0214, LR: 1.000e-04\n",
      "Final parameters: [[1.1096737  1.4874617  0.7627369  1.0618973  0.7801316  0.81799406\n",
      "  0.9158684  0.7044674  0.8768001  1.3183017 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [89/500], Cumulative Loss: 0.1487, LR: 1.000e-04\n",
      "Final parameters: [[1.2292864  0.63752085 0.7813548  0.9641958  1.8189113  1.5185729\n",
      "  0.6653264  1.062702   1.548974   0.21610525]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [90/500], Cumulative Loss: 0.1481, LR: 1.000e-04\n",
      "Final parameters: [[1.1844711  2.3431253  0.060007   1.122166   0.4469318  0.613403\n",
      "  0.77648365 0.20094833 0.79819787 1.9272571 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [91/500], Cumulative Loss: 0.0893, LR: 1.000e-04\n",
      "Final parameters: [[1.1046124  1.1952043  0.73131263 0.96592605 1.1273783  1.0708778\n",
      "  0.8039387  0.8560278  1.0987713  0.8467899 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [92/500], Cumulative Loss: 0.0249, LR: 1.000e-04\n",
      "Final parameters: [[0.9878286  0.3335689  1.3370005  0.9895174  1.5321912  1.391532\n",
      "  1.0566097  1.3861753  1.3108019  0.46261472]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [93/500], Cumulative Loss: 0.0925, LR: 1.000e-04\n",
      "Final parameters: [[0.8727233  1.1128987  1.0575348  0.93525743 0.6411458  0.72204554\n",
      "  1.1347759  1.0064905  0.7670914  1.2391655 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [94/500], Cumulative Loss: 0.2093, LR: 1.000e-04\n",
      "Final parameters: [[ 1.3226571   2.4601135  -0.16516812  1.236959    0.87478423  0.88924927\n",
      "   0.70516634  0.10524958  0.9726913   1.6875226 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [95/500], Cumulative Loss: 0.0623, LR: 1.000e-04\n",
      "Final parameters: [[0.8060107  0.14813268 1.5824811  0.8474946  1.064501   1.0887011\n",
      "  1.1841795  1.4105673  0.9848708  0.6670525 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [96/500], Cumulative Loss: 0.2088, LR: 1.000e-04\n",
      "Final parameters: [[ 0.7770151  -0.27287707  1.9909818   0.92275196  1.3213658   1.2561418\n",
      "   1.3862184   1.7985611   1.1262691   0.47746897]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [97/500], Cumulative Loss: 0.1163, LR: 1.000e-04\n",
      "Final parameters: [[1.0626622  1.6776177  0.44299638 1.0252147  0.7631193  0.77882147\n",
      "  0.8487187  0.52457565 0.84473956 1.3680844 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [98/500], Cumulative Loss: 0.0958, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0649331   2.7174933   0.14092174  1.1848987  -0.12366495  0.21532008\n",
      "   0.9753093  -0.00514938  0.30871245  2.4204834 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [99/500], Cumulative Loss: 0.3693, LR: 1.000e-04\n",
      "Final parameters: [[1.0272481  0.6949002  0.7660647  1.0640309  1.734739   1.4168804\n",
      "  0.7937569  0.9930259  1.4803767  0.14221764]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [100/500], Cumulative Loss: 0.1211, LR: 1.000e-04\n",
      "Final parameters: [[1.1616403  1.4888366  0.56727415 1.0794253  0.99200964 1.020896\n",
      "  0.8662162  0.6646147  1.0165707  1.2757294 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [101/500], Cumulative Loss: 0.3281, LR: 1.000e-04\n",
      "Final parameters: [[1.0559375 0.4887168 1.4599354 0.9122619 1.1613342 1.10714   1.0597893\n",
      "  1.3613582 1.0701661 0.7393786]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [102/500], Cumulative Loss: 0.2083, LR: 1.000e-04\n",
      "Final parameters: [[1.097957   1.4667464  0.7545222  1.0461836  1.0141495  0.9851245\n",
      "  0.89222836 0.82575375 1.0697092  1.1501117 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [103/500], Cumulative Loss: 0.2486, LR: 1.000e-04\n",
      "Final parameters: [[0.83096635 0.36663157 1.4292957  0.9238474  1.1542109  1.1056299\n",
      "  1.096024   1.3163455  1.0008897  0.541201  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [104/500], Cumulative Loss: 0.0925, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0108925   2.1891277   0.46242678  1.0438519  -0.00641868  0.28011224\n",
      "   1.0178632   0.3482538   0.4887237   2.0409167 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [105/500], Cumulative Loss: 0.1510, LR: 1.000e-04\n",
      "Final parameters: [[0.91654813 0.8511446  1.2790577  1.056132   1.0093514  0.9993892\n",
      "  1.1647729  1.177244   0.95933604 0.9877654 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [106/500], Cumulative Loss: 0.0568, LR: 1.000e-04\n",
      "Final parameters: [[0.8692304  0.23396102 1.4099501  0.92272747 1.4270614  1.3175714\n",
      "  0.9988255  1.4355977  1.288075   0.3519749 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [107/500], Cumulative Loss: 0.1246, LR: 1.000e-04\n",
      "Final parameters: [[0.8433701  1.1841838  1.420819   1.1032279  0.46911728 0.64195037\n",
      "  1.3018085  0.9931744  0.589332   1.5149385 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [108/500], Cumulative Loss: 0.2007, LR: 1.000e-04\n",
      "Final parameters: [[1.094261   0.6088527  0.94034517 1.0108024  1.7530444  1.5270381\n",
      "  0.8361805  1.1544842  1.4571058  0.40734416]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [109/500], Cumulative Loss: 0.1453, LR: 1.000e-04\n",
      "Final parameters: [[0.9593816 0.5092914 1.4594288 0.9712515 1.1495827 1.0922568 1.1435581\n",
      "  1.3457825 1.0470521 0.738564 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [110/500], Cumulative Loss: 0.0487, LR: 1.000e-04\n",
      "Final parameters: [[1.105064   2.3848457  0.35110736 1.2140242  0.23501469 0.45308208\n",
      "  1.053477   0.27663165 0.58251244 2.146609  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [111/500], Cumulative Loss: 0.4257, LR: 1.000e-04\n",
      "Final parameters: [[1.025223   1.1044459  0.7665778  0.9997965  1.0679128  1.0741973\n",
      "  0.8947841  0.89450836 1.1105852  1.013955  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [112/500], Cumulative Loss: 0.3082, LR: 1.000e-04\n",
      "Final parameters: [[1.1564933  0.91182595 0.7391641  0.98814493 1.4782933  1.3375322\n",
      "  0.7511054  0.9792597  1.3287691  0.61383617]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [113/500], Cumulative Loss: 0.2523, LR: 1.000e-04\n",
      "Final parameters: [[1.2765912  0.36614946 0.7393289  0.9776722  2.160629   1.8429327\n",
      "  0.72591835 1.3187608  1.8028877  0.17554387]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [114/500], Cumulative Loss: 0.2572, LR: 1.000e-04\n",
      "Final parameters: [[1.0934277  1.494708   0.55072373 1.0162015  0.8719619  0.87582284\n",
      "  0.8691058  0.6349496  0.9133995  1.2491429 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [115/500], Cumulative Loss: 0.3439, LR: 1.000e-04\n",
      "Final parameters: [[1.1036867  0.7605144  0.83641946 0.97233665 1.6324368  1.453146\n",
      "  0.79919004 1.1699495  1.5105975  0.39511752]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [116/500], Cumulative Loss: 0.5383, LR: 1.000e-04\n",
      "Final parameters: [[0.778582   1.2409511  1.4822737  1.0687585  0.31800866 0.64118457\n",
      "  1.2346634  1.0418609  0.5121491  1.5767791 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [117/500], Cumulative Loss: 0.1227, LR: 1.000e-04\n",
      "Final parameters: [[1.0385714  1.0212834  1.125612   0.93651605 0.7503818  0.8127579\n",
      "  1.0280237  1.0350178  0.87565106 1.1253419 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [118/500], Cumulative Loss: 0.1165, LR: 1.000e-04\n",
      "Final parameters: [[0.9986562 0.9575635 1.0471799 1.0300192 1.1158161 1.0995549 1.0461377\n",
      "  1.0850297 1.0978543 1.0222728]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [119/500], Cumulative Loss: 0.6136, LR: 1.000e-04\n",
      "Final parameters: [[0.67574924 0.89867866 1.6707782  0.9683887  0.21116263 0.5077235\n",
      "  1.3593055  1.1490079  0.52878636 1.5046968 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [120/500], Cumulative Loss: 0.8345, LR: 1.000e-04\n",
      "Final parameters: [[ 1.5465398   0.7569436   0.00556532  1.030169    2.7770646   2.1959314\n",
      "   0.16677505  1.0114636   2.2769399  -0.3942225 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [121/500], Cumulative Loss: 0.1619, LR: 1.000e-04\n",
      "Final parameters: [[ 0.9339962  -0.1615503   1.513791    0.9424208   1.9539288   1.6940722\n",
      "   0.94821984  1.6263456   1.5547585  -0.16564386]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [122/500], Cumulative Loss: 0.2531, LR: 1.000e-04\n",
      "Final parameters: [[0.96979856 0.4054615  1.047339   0.9871198  1.624152   1.4515723\n",
      "  0.8948182  1.2996486  1.4378874  0.36610872]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [123/500], Cumulative Loss: 0.1138, LR: 1.000e-04\n",
      "Final parameters: [[1.1845893  0.64914614 0.8518793  1.0284431  1.8413734  1.577027\n",
      "  0.77519697 1.2091726  1.5267935  0.3947707 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [124/500], Cumulative Loss: 0.3305, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1245252   0.09711379  0.9803477   0.8540814   2.017677    1.706362\n",
      "   0.67150414  1.3830799   1.7168553  -0.06443624]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [125/500], Cumulative Loss: 0.1230, LR: 1.000e-04\n",
      "Final parameters: [[1.0860921  1.7534304  0.68231833 1.1191521  0.5594897  0.70739996\n",
      "  1.0729806  0.62092686 0.7608404  1.7180477 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [126/500], Cumulative Loss: 0.2276, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1396347   0.20197883  1.1564595   0.8791921   2.0030696   1.704115\n",
      "   0.67368567  1.525226    1.7339323  -0.13554712]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [127/500], Cumulative Loss: 0.0521, LR: 1.000e-04\n",
      "Final parameters: [[0.98229194 1.7053175  0.47496906 1.102523   0.7903241  0.8336724\n",
      "  0.89645445 0.5821537  0.9015316  1.380348  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [128/500], Cumulative Loss: 0.3026, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0553823  -0.03376728  1.1849482   0.8540385   1.9673246   1.7078104\n",
      "   0.7158399   1.4912778   1.6268041  -0.195499  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [129/500], Cumulative Loss: 0.0436, LR: 1.000e-04\n",
      "Final parameters: [[0.8635564  0.4889555  1.2464237  0.93499976 1.3223472  1.2344528\n",
      "  0.9489574  1.2004952  1.0972538  0.46437958]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [130/500], Cumulative Loss: 0.0702, LR: 1.000e-04\n",
      "Final parameters: [[1.0095782  0.28170943 1.1672975  0.9066615  1.7529173  1.5490978\n",
      "  0.8358461  1.4308957  1.4880273  0.21433927]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [131/500], Cumulative Loss: 0.1288, LR: 1.000e-04\n",
      "Final parameters: [[ 0.8800988  -1.1283023   2.1008813   0.7789837   2.4570744   2.032476\n",
      "   0.90637434  2.221115    1.8157239  -0.9724538 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [132/500], Cumulative Loss: 1.7975, LR: 1.000e-04\n",
      "Final parameters: [[ 1.8036878   1.9675359  -0.8717727   1.1050445   2.5793211   2.0611346\n",
      "  -0.24577516  0.44104648  2.2359056  -0.02273807]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [133/500], Cumulative Loss: 0.0212, LR: 1.000e-04\n",
      "Final parameters: [[ 0.9234666  -0.09010964  1.7098534   0.9087878   1.6281219   1.4367689\n",
      "   0.979606    1.6242108   1.3292944   0.03085382]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [134/500], Cumulative Loss: 0.4535, LR: 1.000e-04\n",
      "Final parameters: [[1.1393772  1.8945179  0.6801237  1.0865867  0.46576852 0.6244689\n",
      "  1.0413074  0.6199668  0.70643353 1.7164122 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [135/500], Cumulative Loss: 0.0955, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0875142   2.6645498   0.1871129   1.2484864  -0.157078    0.25577274\n",
      "   1.1209562   0.12075291  0.4858464   2.6278563 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [136/500], Cumulative Loss: 0.4530, LR: 1.000e-04\n",
      "Final parameters: [[1.0870813  0.5982156  1.1539836  0.939369   1.4265192  1.289957\n",
      "  0.93341565 1.2542435  1.2255597  0.5363602 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [137/500], Cumulative Loss: 0.0882, LR: 1.000e-04\n",
      "Final parameters: [[1.0848612  0.7080818  1.0081997  0.91646487 1.416875   1.3436034\n",
      "  0.8739499  1.2838238  1.3857502  0.5536084 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [138/500], Cumulative Loss: 0.5886, LR: 1.000e-04\n",
      "Final parameters: [[1.1807904  1.8782907  0.6038411  1.1061344  0.5247289  0.6954743\n",
      "  0.9681835  0.60952646 0.8155675  1.7001305 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [139/500], Cumulative Loss: 0.3656, LR: 1.000e-04\n",
      "Final parameters: [[1.2078878  2.689965   0.05006542 1.1779966  0.2851535  0.49570838\n",
      "  0.78666395 0.10687627 0.67038286 2.0867815 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [140/500], Cumulative Loss: 0.6662, LR: 1.000e-04\n",
      "Final parameters: [[ 1.6195977   1.4934683  -0.40106818  0.9726076   2.0220783   1.6391206\n",
      "   0.24991381  0.6821238   1.8502278   0.5083188 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [141/500], Cumulative Loss: 0.5662, LR: 1.000e-04\n",
      "Final parameters: [[0.8234149 1.2254549 0.9588558 1.0511328 0.5592826 0.7076029 1.1121237\n",
      "  0.8478374 0.7312307 1.4396642]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [142/500], Cumulative Loss: 0.4526, LR: 1.000e-04\n",
      "Final parameters: [[1.0763264  1.7824738  0.6134077  1.0435513  0.45117405 0.6263992\n",
      "  1.0611811  0.6564338  0.7176273  1.699691  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [143/500], Cumulative Loss: 0.0805, LR: 1.000e-04\n",
      "Final parameters: [[1.1214503  0.7649902  0.9842504  0.94809914 1.4674083  1.3421953\n",
      "  0.85513824 1.2351764  1.4278091  0.57651067]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [144/500], Cumulative Loss: 0.5287, LR: 1.000e-04\n",
      "Final parameters: [[0.8210815  0.5577985  1.6842889  0.9379493  0.5106343  0.70338756\n",
      "  1.2969553  1.2657455  0.604897   1.3274307 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [145/500], Cumulative Loss: 0.1269, LR: 1.000e-04\n",
      "Final parameters: [[0.9220979  1.5772132  1.2307788  1.0317743  0.02411738 0.33859396\n",
      "  1.1863832  0.82650954 0.39835906 1.8419963 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [146/500], Cumulative Loss: 0.2050, LR: 1.000e-04\n",
      "Final parameters: [[0.910539   0.45566756 1.118707   1.0364615  1.6196204  1.4982651\n",
      "  0.86319053 1.2365786  1.3522676  0.31083933]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [147/500], Cumulative Loss: 0.5228, LR: 1.000e-04\n",
      "Final parameters: [[ 0.9993598  -0.69764364  1.2441028   0.9285014   2.8812158   2.2701256\n",
      "   0.58994293  1.98367     2.2912648  -1.07709   ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [148/500], Cumulative Loss: 0.1520, LR: 1.000e-04\n",
      "Final parameters: [[0.85408884 0.9542891  1.4881448  1.0510845  0.5707722  0.7427867\n",
      "  1.312225   1.1998277  0.6989008  1.369065  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [149/500], Cumulative Loss: 0.0971, LR: 1.000e-04\n",
      "Final parameters: [[1.1668996  1.5376066  0.71193045 1.0381278  0.8545914  0.8603506\n",
      "  0.8854021  0.7394218  0.8807243  1.2890377 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [150/500], Cumulative Loss: 0.0700, LR: 1.000e-04\n",
      "Final parameters: [[0.9369854  0.6783125  1.155056   0.8682941  1.0113562  1.0282432\n",
      "  0.99051976 1.1940027  1.0276105  0.86207867]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [151/500], Cumulative Loss: 0.0457, LR: 1.000e-04\n",
      "Final parameters: [[1.1572679  1.4553697  0.7617351  1.0398103  0.84555286 0.90328485\n",
      "  0.9401845  0.82058805 0.9727878  1.3452059 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [152/500], Cumulative Loss: 0.5507, LR: 1.000e-04\n",
      "Final parameters: [[ 1.4812165   2.5146527  -0.62932944  1.141707    1.1527433   1.0415113\n",
      "   0.37065113  0.00784633  1.2099357   1.34907   ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [153/500], Cumulative Loss: 0.1404, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1108321   0.00535094  1.0953915   0.92210186  2.1613483   1.8024136\n",
      "   0.6840234   1.4221313   1.7181797  -0.22005823]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [154/500], Cumulative Loss: 0.4221, LR: 1.000e-04\n",
      "Final parameters: [[1.4688253  1.4723153  0.01286671 1.1096582  1.7335694  1.4947612\n",
      "  0.5609651  0.66628695 1.5642     0.9389432 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [155/500], Cumulative Loss: 0.0469, LR: 1.000e-04\n",
      "Final parameters: [[1.1391007  2.1433318  0.49847412 1.1789232  0.5040983  0.6470713\n",
      "  0.9745108  0.46592438 0.75372565 1.8781047 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [156/500], Cumulative Loss: 0.0533, LR: 1.000e-04\n",
      "Final parameters: [[0.9555967  1.7218977  1.0642315  1.1505959  0.34875953 0.5387248\n",
      "  1.2367116  0.7692282  0.5826626  1.7450054 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [157/500], Cumulative Loss: 0.5499, LR: 1.000e-04\n",
      "Final parameters: [[1.1641803  1.4369792  0.43726847 0.98898494 1.1943531  1.1029067\n",
      "  0.633635   0.7778175  1.2176249  0.96155113]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [158/500], Cumulative Loss: 0.1967, LR: 1.000e-04\n",
      "Final parameters: [[0.96417457 1.3928622  1.1398104  1.0210518  0.38187802 0.5620422\n",
      "  1.163767   0.83196986 0.55185485 1.6338211 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [159/500], Cumulative Loss: 20.3018, LR: 1.000e-04\n",
      "Final parameters: [[-0.62171465  0.2521364   3.3665574   2.4737675  -0.6167209   0.2877419\n",
      "   2.3921773   1.5809101  -0.43253988  2.0765233 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [160/500], Cumulative Loss: 0.1964, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0770599   3.0952861   0.1414172   1.1609368  -0.7779774  -0.24083279\n",
      "   1.1705036  -0.09163368 -0.08125113  3.1276321 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [161/500], Cumulative Loss: 0.0822, LR: 1.000e-04\n",
      "Final parameters: [[1.1520103  1.8242733  0.47275847 1.0769508  0.758633   0.7926535\n",
      "  0.7695319  0.46915796 0.83317626 1.3460535 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [162/500], Cumulative Loss: 0.2334, LR: 1.000e-04\n",
      "Final parameters: [[1.3053277  1.3578689  0.28234273 1.06972    1.4877008  1.3226159\n",
      "  0.64978623 0.737709   1.4213258  0.89441305]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [163/500], Cumulative Loss: 0.0528, LR: 1.000e-04\n",
      "Final parameters: [[1.2734061  2.326355   0.15026274 1.0953288  0.44064346 0.5958508\n",
      "  0.8281995  0.28230986 0.6986499  1.8826025 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [164/500], Cumulative Loss: 0.1158, LR: 1.000e-04\n",
      "Final parameters: [[0.87958497 1.7470065  0.79170084 1.1737422  0.44555998 0.6718851\n",
      "  1.052776   0.6174867  0.6697285  1.7202847 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [165/500], Cumulative Loss: 0.4314, LR: 1.000e-04\n",
      "Final parameters: [[1.350947   1.3800638  0.02894931 1.026514   1.8280644  1.5545549\n",
      "  0.45245898 0.7762175  1.677086   0.52484643]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [166/500], Cumulative Loss: 0.2792, LR: 1.000e-04\n",
      "Final parameters: [[1.1085837 1.0335802 0.7698759 1.0247618 1.404645  1.2922558 0.7944492\n",
      "  1.0240588 1.299081  0.7187098]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [167/500], Cumulative Loss: 0.1705, LR: 1.000e-04\n",
      "Final parameters: [[ 1.303385    2.8467994  -0.05415185  1.1946399   0.26443672  0.49254274\n",
      "   0.8385346   0.14793685  0.7373886   2.265626  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [168/500], Cumulative Loss: 0.1526, LR: 1.000e-04\n",
      "Final parameters: [[1.019051   1.0812949  0.69981086 0.98642504 1.161826   1.1144872\n",
      "  0.8681166  0.88357633 1.0605038  0.89788425]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [169/500], Cumulative Loss: 0.2106, LR: 1.000e-04\n",
      "Final parameters: [[1.2304554  2.067148   0.02598758 1.0394926  0.86365235 0.8846897\n",
      "  0.6196093  0.37908453 1.095864   1.4139341 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [170/500], Cumulative Loss: 0.8488, LR: 1.000e-04\n",
      "Final parameters: [[1.4557334  1.6406257  0.16841367 1.0871698  1.5464468  1.3458343\n",
      "  0.5260998  0.6767835  1.4971198  0.804007  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [171/500], Cumulative Loss: 0.2615, LR: 1.000e-04\n",
      "Final parameters: [[1.2584118 1.4875289 0.2868651 1.0113885 1.2524323 1.1515231 0.6009036\n",
      "  0.6967883 1.2945815 0.9062371]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [172/500], Cumulative Loss: 0.6349, LR: 1.000e-04\n",
      "Final parameters: [[ 1.5651319   2.0057626  -0.39041004  1.0832212   1.535984    1.3559152\n",
      "   0.42732766  0.49101606  1.5726751   1.1206963 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [173/500], Cumulative Loss: 0.2524, LR: 1.000e-04\n",
      "Final parameters: [[1.2911705  1.922237   0.04179745 1.1137652  0.9842411  0.97189647\n",
      "  0.79828227 0.48026484 1.0501045  1.5686287 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [174/500], Cumulative Loss: 0.3874, LR: 1.000e-04\n",
      "Final parameters: [[1.2124991  1.6103113  0.82041067 1.0527252  0.77206266 0.80990744\n",
      "  0.9445413  0.75726223 0.8041154  1.344205  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [175/500], Cumulative Loss: 0.5839, LR: 1.000e-04\n",
      "Final parameters: [[1.2930068  0.66517115 0.79819757 0.93804216 1.7898933  1.5542264\n",
      "  0.67072487 1.246081   1.6026194  0.26544952]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [176/500], Cumulative Loss: 0.2510, LR: 1.000e-04\n",
      "Final parameters: [[ 0.9153234  -0.5281208   1.7695462   0.83721244  2.027608    1.7251114\n",
      "   0.9504059   1.8488553   1.5785456  -0.29194587]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [177/500], Cumulative Loss: 0.0811, LR: 1.000e-04\n",
      "Final parameters: [[1.1780809  0.773981   0.9637964  0.960987   1.4158894  1.2666348\n",
      "  0.89817065 1.1700373  1.2688874  0.77173245]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [178/500], Cumulative Loss: 0.1156, LR: 1.000e-04\n",
      "Final parameters: [[1.0730927  0.81583583 1.0050348  0.9375617  1.1049186  1.0973221\n",
      "  0.94007987 1.1035678  1.1297785  0.8736729 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [179/500], Cumulative Loss: 0.0070, LR: 1.000e-04\n",
      "Final parameters: [[0.8883883 0.5680272 1.1827081 0.895673  1.1141949 1.1173317 1.0440655\n",
      "  1.2235211 1.0936157 0.7553788]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [180/500], Cumulative Loss: 0.8336, LR: 1.000e-04\n",
      "Final parameters: [[ 1.4964451   0.46156174  0.0768688   0.9605521   2.910417    2.2708645\n",
      "   0.2083693   1.2282513   2.364228   -0.6284902 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [181/500], Cumulative Loss: 0.6227, LR: 1.000e-04\n",
      "Final parameters: [[ 1.031057   -0.34952825  1.2682983   0.85565424  2.3587112   1.926982\n",
      "   0.6761136   1.6467427   1.859252   -0.56536824]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [182/500], Cumulative Loss: 0.1311, LR: 1.000e-04\n",
      "Final parameters: [[1.0290642  0.91463476 1.1099494  0.9415581  0.9514615  0.9460674\n",
      "  0.9685111  1.0244613  0.8850599  0.9474133 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [183/500], Cumulative Loss: 0.2426, LR: 1.000e-04\n",
      "Final parameters: [[ 0.60985786 -0.93979317  2.4142623   0.79455096  1.3915781   1.3532062\n",
      "   1.4817089   2.1195166   1.0878462   0.16656101]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [184/500], Cumulative Loss: 0.1933, LR: 1.000e-04\n",
      "Final parameters: [[1.1078919  1.2644646  0.57679576 1.1125554  1.3215885  1.2514879\n",
      "  0.88289213 0.8498536  1.2536025  1.0253832 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [185/500], Cumulative Loss: 23.7799, LR: 1.000e-04\n",
      "Final parameters: [[0.3834989 0.8111067 0.9957499 2.685702  0.8478072 1.2998977 1.2344894\n",
      "  1.0648617 1.3078508 1.9303348]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [186/500], Cumulative Loss: 0.1206, LR: 1.000e-04\n",
      "Final parameters: [[1.1196004 0.817703  1.0320926 1.0007463 1.4660468 1.3534604 0.8749359\n",
      "  1.1714095 1.3569511 0.5811552]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [187/500], Cumulative Loss: 0.1468, LR: 1.000e-04\n",
      "Final parameters: [[1.2866887  2.4502878  0.01165076 1.1311754  0.6420745  0.75015825\n",
      "  0.6241633  0.21750253 0.8709943  1.607718  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [188/500], Cumulative Loss: 17.8042, LR: 1.000e-04\n",
      "Final parameters: [[ 2.3888366   2.0807426  -0.19926637 -0.2521692  -0.30377758 -0.03436075\n",
      "   1.1926628   0.21380727  0.36320296  4.79499   ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [189/500], Cumulative Loss: 0.0767, LR: 1.000e-04\n",
      "Final parameters: [[1.1380292  2.2264366  0.14809662 1.0977652  0.42378637 0.578492\n",
      "  0.83243513 0.26431265 0.7791514  1.9547862 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [190/500], Cumulative Loss: 0.0645, LR: 1.000e-04\n",
      "Final parameters: [[1.1577436  2.2110116  0.27949488 1.2018983  0.63634187 0.7807966\n",
      "  0.89027643 0.43285573 0.8717313  1.7406619 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [191/500], Cumulative Loss: 11.6542, LR: 1.000e-04\n",
      "Final parameters: [[ 0.89363325  2.090334   -0.1122298   2.2288847   0.21834257  0.7625187\n",
      "   1.368081    0.15914845  0.54920554  3.7604399 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [192/500], Cumulative Loss: 9.4471, LR: 1.000e-04\n",
      "Final parameters: [[ 1.3851068   0.48048466 -0.5711192   1.755858    4.1884184   3.2297833\n",
      "  -0.45127088  1.2147679   3.143873   -2.4439156 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [193/500], Cumulative Loss: 0.1911, LR: 1.000e-04\n",
      "Final parameters: [[0.9488318  0.95501536 1.1241902  0.99329317 0.85688597 0.92469406\n",
      "  1.0706334  1.0387276  0.91582    1.1625818 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [194/500], Cumulative Loss: 0.0696, LR: 1.000e-04\n",
      "Final parameters: [[1.019594   0.88001823 1.0642457  1.0580091  1.2262778  1.1745827\n",
      "  1.0107381  1.078889   1.1292365  0.8156902 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [195/500], Cumulative Loss: 0.2100, LR: 1.000e-04\n",
      "Final parameters: [[1.2498614  1.7138883  0.30222815 1.040489   0.90615726 0.9385104\n",
      "  0.7834071  0.5808112  1.0469556  1.4100839 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [196/500], Cumulative Loss: 0.0748, LR: 1.000e-04\n",
      "Final parameters: [[1.0604122  1.5138459  1.0239129  1.1200433  0.5553727  0.71988606\n",
      "  1.1986165  0.8806777  0.72353995 1.6095654 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [197/500], Cumulative Loss: 0.2358, LR: 1.000e-04\n",
      "Final parameters: [[0.62250984 0.66407335 1.84536    1.0265877  0.37178946 0.6450654\n",
      "  1.4736241  1.3478814  0.52141434 1.3886139 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [198/500], Cumulative Loss: 0.1238, LR: 1.000e-04\n",
      "Final parameters: [[1.2164247  2.3514109  0.2837432  1.0761219  0.2801711  0.4570788\n",
      "  0.850205   0.29575613 0.6469796  1.9415656 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [199/500], Cumulative Loss: 21.3386, LR: 1.000e-04\n",
      "Final parameters: [[ 2.9850562  1.7706246 -2.1533656  1.4376494  2.999729   2.7764766\n",
      "  -0.8206528  1.3146203  3.3764887  3.4139903]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [200/500], Cumulative Loss: 0.2735, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1741484   0.3987238   0.8456919   1.019081    2.1270003   1.7382299\n",
      "   0.6270901   1.2112869   1.7012981  -0.02067477]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [201/500], Cumulative Loss: 19.7324, LR: 1.000e-04\n",
      "Final parameters: [[ 3.3302398   0.07182508 -3.1014416   0.41533673  4.3889313   2.9325664\n",
      "   0.46253693  0.60182434  3.6832807   2.8975396 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [202/500], Cumulative Loss: 0.1887, LR: 1.000e-04\n",
      "Final parameters: [[0.8273587  0.12472457 1.9119964  0.94481933 1.2470002  1.195673\n",
      "  1.2890619  1.6857928  1.0889298  0.48791215]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [203/500], Cumulative Loss: 0.1486, LR: 1.000e-04\n",
      "Final parameters: [[1.1442854  0.64194787 0.9318671  0.9931418  1.7179592  1.495488\n",
      "  0.7267986  1.1060418  1.3871783  0.21078578]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [204/500], Cumulative Loss: 0.0881, LR: 1.000e-04\n",
      "Final parameters: [[ 0.81762743 -0.42405203  1.4745477   0.8209766   1.9335527   1.6311276\n",
      "   0.8691758   1.6452521   1.488215   -0.32298416]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [205/500], Cumulative Loss: 0.1092, LR: 1.000e-04\n",
      "Final parameters: [[1.1157295  2.0777514  0.34414554 1.0738103  0.48523545 0.6185847\n",
      "  0.8379422  0.35520887 0.72987115 1.7538091 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [206/500], Cumulative Loss: 0.2908, LR: 1.000e-04\n",
      "Final parameters: [[ 1.397996    1.7170396  -0.09158111  0.99639416  1.2597026   1.1435895\n",
      "   0.48663014  0.4333722   1.2633111   1.1742171 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [207/500], Cumulative Loss: 8.4766, LR: 1.000e-04\n",
      "Final parameters: [[ 2.1895397  -0.8732972  -2.2085435   0.96930385  5.978909    3.8331137\n",
      "  -0.37594703  0.38673523  4.005911   -1.6748208 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [208/500], Cumulative Loss: 5.3967, LR: 1.000e-04\n",
      "Final parameters: [[-0.2128359  -0.04528861  2.01563     1.4305642   1.0123154   1.546582\n",
      "   1.1207073   1.6491197   2.010413   -0.3083233 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [209/500], Cumulative Loss: 1.4976, LR: 1.000e-04\n",
      "Final parameters: [[0.61298513 2.0022597  0.6192125  1.4856985  0.16328166 0.56225\n",
      "  1.0932608  0.40892082 0.94979924 1.7120025 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [210/500], Cumulative Loss: 0.2547, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1769938   2.3031147  -0.04092509  1.131373    0.55176014  0.70687795\n",
      "   0.8378987   0.25259677  0.892956    1.8410668 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [211/500], Cumulative Loss: 0.6931, LR: 1.000e-04\n",
      "Final parameters: [[ 1.2285132   0.0942565   0.6702916   0.90035063  2.5870113   2.1005483\n",
      "   0.46633223  1.447455    2.1109333  -0.5217959 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [212/500], Cumulative Loss: 0.2186, LR: 1.000e-04\n",
      "Final parameters: [[1.2832088  1.8089707  0.05428591 0.9947593  0.8855066  0.86075836\n",
      "  0.6256415  0.4258644  1.0361731  1.4056019 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [213/500], Cumulative Loss: 0.1303, LR: 1.000e-04\n",
      "Final parameters: [[1.0352889  1.1225537  0.97840625 1.0665835  1.0491358  1.0237603\n",
      "  0.9439515  0.89889175 0.981967   0.962839  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [214/500], Cumulative Loss: 0.7222, LR: 1.000e-04\n",
      "Final parameters: [[0.9042114  0.547689   1.0099815  0.8979433  1.3990787  1.2825722\n",
      "  0.75287586 1.1475279  1.1397885  0.4808775 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [215/500], Cumulative Loss: 256.5456, LR: 1.000e-04\n",
      "Final parameters: [[ 9.47814     4.5847096  -3.8134165  -3.222454   -1.6294857   0.19478154\n",
      "  -1.6195219   1.6591802   1.8664474  10.577192  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [216/500], Cumulative Loss: 0.3045, LR: 1.000e-04\n",
      "Final parameters: [[1.457691   1.1925281  0.17012984 1.0280869  1.8524628  1.5924256\n",
      "  0.5444742  0.80077064 1.6089833  0.5326883 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [217/500], Cumulative Loss: 0.1485, LR: 1.000e-04\n",
      "Final parameters: [[1.0859861  1.3523273  0.3993144  0.9864884  1.082304   1.0410141\n",
      "  0.71958566 0.66896963 1.1345234  0.95706403]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [218/500], Cumulative Loss: 6.1184, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1728883   0.56284416  0.15800065  1.60585     2.8125892   2.0801024\n",
      "   0.44912452  1.1640488   2.910765   -0.5110821 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [219/500], Cumulative Loss: 16.1730, LR: 1.000e-04\n",
      "Final parameters: [[-1.000633    0.45395815  3.848436    2.2834454  -0.4299038   0.4174407\n",
      "   1.6583308   2.0204384   0.44252872  0.20160021]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [220/500], Cumulative Loss: 0.0332, LR: 1.000e-04\n",
      "Final parameters: [[1.1295731 1.9381186 0.6708262 1.1383581 0.5160177 0.6512635 1.077514\n",
      "  0.6296828 0.7639776 1.7772357]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [221/500], Cumulative Loss: 0.0916, LR: 1.000e-04\n",
      "Final parameters: [[1.0748565  0.10389733 1.2082788  0.831051   1.7839667  1.543927\n",
      "  0.7716219  1.4001266  1.5142452  0.06656632]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [222/500], Cumulative Loss: 0.3779, LR: 1.000e-04\n",
      "Final parameters: [[1.2046745  1.2060058  0.3446727  1.0605552  1.7282565  1.4396148\n",
      "  0.5802237  0.85668665 1.6719123  0.43661144]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [223/500], Cumulative Loss: 0.5207, LR: 1.000e-04\n",
      "Final parameters: [[ 1.5898534   3.1460183  -0.9321422   1.3217567   0.94676477  0.8799304\n",
      "   0.41463304 -0.24807996  1.1259971   1.9303991 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [224/500], Cumulative Loss: 0.1204, LR: 1.000e-04\n",
      "Final parameters: [[ 1.2028998   2.8117585  -0.0724187   1.2517663   0.21434197  0.41529727\n",
      "   0.9635922   0.0278084   0.59351796  2.4130356 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [225/500], Cumulative Loss: 1.5313, LR: 1.000e-04\n",
      "Final parameters: [[ 1.8165305   2.0762367  -0.76289797  1.0269      1.5746846   1.2529019\n",
      "   0.27091473  0.77520174  1.6885768   1.1766213 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [226/500], Cumulative Loss: 0.4897, LR: 1.000e-04\n",
      "Final parameters: [[ 0.668862    1.4711637   1.3599638   1.0494801  -0.06291021  0.25824195\n",
      "   1.3394309   0.860229    0.3142324   1.8208127 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [227/500], Cumulative Loss: 0.2275, LR: 1.000e-04\n",
      "Final parameters: [[ 1.419648    3.1223142  -0.596956    1.2980313   0.5218479   0.63788813\n",
      "   0.6155226  -0.26907927  0.79773533  2.1720629 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [228/500], Cumulative Loss: 1.1564, LR: 1.000e-04\n",
      "Final parameters: [[1.0635890e+00 1.8104177e+00 4.6797097e-04 1.2867019e+00 1.4168842e+00\n",
      "  1.3603876e+00 4.6847183e-01 4.7186562e-01 1.4278846e+00 3.7844351e-01]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [229/500], Cumulative Loss: 0.0831, LR: 1.000e-04\n",
      "Final parameters: [[0.99746364 0.86576045 1.1242867  0.9479417  0.8873441  0.89692086\n",
      "  1.0759254  1.0585428  0.92123276 1.068265  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [230/500], Cumulative Loss: 0.0467, LR: 1.000e-04\n",
      "Final parameters: [[ 0.9516734  -0.05314006  1.6405356   0.88449204  1.5398356   1.3735322\n",
      "   1.0790448   1.6125467   1.2469008   0.1588857 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [231/500], Cumulative Loss: 0.0686, LR: 1.000e-04\n",
      "Final parameters: [[ 0.7939262  -0.81171757  1.7606763   0.77787733  2.0221007   1.7054422\n",
      "   0.95250964  1.8344506   1.5815413  -0.5474134 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [232/500], Cumulative Loss: 0.4764, LR: 1.000e-04\n",
      "Final parameters: [[ 0.9478989  -0.0139408   1.4204409   0.8438217   1.7094333   1.4811993\n",
      "   0.91666853  1.4963287   1.37026     0.09233841]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [233/500], Cumulative Loss: 8.7999, LR: 1.000e-04\n",
      "Final parameters: [[ 1.9524806   2.2878466  -0.27633712  0.90675443  1.5117003   1.584996\n",
      "  -0.2314392  -0.12695143  0.15339106  2.0586762 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [234/500], Cumulative Loss: 0.4197, LR: 1.000e-04\n",
      "Final parameters: [[1.1364667  2.0771375  0.44419414 1.1160157  0.85668135 0.9491073\n",
      "  0.59116334 0.47120854 1.0283624  1.0919081 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [235/500], Cumulative Loss: 27.8395, LR: 1.000e-04\n",
      "Final parameters: [[ 2.3665085   3.420042   -1.5275108  -0.6394524   1.2261072   0.8181394\n",
      "   0.16392766 -0.63963795  0.8733713   1.4090478 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [236/500], Cumulative Loss: 1.3751, LR: 1.000e-04\n",
      "Final parameters: [[ 0.35203135  0.8094956   2.4788888   0.9589838  -0.6310894  -0.08052316\n",
      "   1.9786913   1.3351747  -0.13126728  2.134846  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [237/500], Cumulative Loss: 5.6769, LR: 1.000e-04\n",
      "Final parameters: [[ 1.875211    1.6540285  -0.39525062  0.70130265  0.53313863  0.41444552\n",
      "   1.4827627   0.38127947  0.88182193  3.862044  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [238/500], Cumulative Loss: 0.3920, LR: 1.000e-04\n",
      "Final parameters: [[ 1.4477472   1.6568335  -0.10209655  1.0581858   1.7417616   1.449044\n",
      "   0.40888453  0.58760524  1.6633998   0.62660366]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [239/500], Cumulative Loss: 0.0401, LR: 1.000e-04\n",
      "Final parameters: [[0.98503816 2.3770316  0.3144636  1.0949644  0.02465184 0.2495707\n",
      "  0.9933612  0.22968091 0.43445474 2.1329525 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [240/500], Cumulative Loss: 31.9524, LR: 1.000e-04\n",
      "Final parameters: [[ 2.8427665   3.5266793   0.34067148 -0.50379086 -2.702441   -0.8627091\n",
      "   1.2857356  -0.06895325 -1.0488825   6.3988686 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [241/500], Cumulative Loss: 15.6604, LR: 1.000e-04\n",
      "Final parameters: [[ 2.3064673   3.3623672  -1.5176182   0.18817788  2.8127618   1.888259\n",
      "  -0.38970166 -0.11277116  1.3044946  -0.5908205 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [242/500], Cumulative Loss: 13.0545, LR: 1.000e-04\n",
      "Final parameters: [[-0.9405407   0.41740406  3.4355266   2.0586553   0.09741648  0.87687826\n",
      "   1.4473034   1.7852801   0.4485793  -1.1213272 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [243/500], Cumulative Loss: 0.4715, LR: 1.000e-04\n",
      "Final parameters: [[1.2190907  1.8519229  0.03472675 1.0474913  0.9984707  0.94600433\n",
      "  0.73467994 0.4341125  1.1041961  1.397636  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [244/500], Cumulative Loss: 0.5071, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1290625  -0.15288657  0.91754025  1.0237348   2.6833901   2.0661392\n",
      "   0.54760945  1.3889753   1.9710282  -0.7569881 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [245/500], Cumulative Loss: 0.9404, LR: 1.000e-04\n",
      "Final parameters: [[1.2927977  0.362316   0.59715545 0.8371567  1.6703191  1.2132982\n",
      "  1.11607    1.1633736  1.3822333  1.0770619 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [246/500], Cumulative Loss: 0.2425, LR: 1.000e-04\n",
      "Final parameters: [[ 1.2499195 -0.5009451  1.1178857  0.8098143  2.6028366  2.0736697\n",
      "   0.6504139  1.6902862  1.9648105 -0.7051002]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [247/500], Cumulative Loss: 0.2073, LR: 1.000e-04\n",
      "Final parameters: [[0.91762173 0.66175437 1.42869    1.0006042  0.9325049  0.9514102\n",
      "  1.1623453  1.1973878  0.88515943 0.9361375 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [248/500], Cumulative Loss: 0.1092, LR: 1.000e-04\n",
      "Final parameters: [[1.006169   1.4656336  0.95844156 0.97012407 0.34949446 0.52051204\n",
      "  1.1079102  0.76621413 0.6278759  1.6075665 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [249/500], Cumulative Loss: 5.0032, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0993389   0.98212504  1.6914891   0.30694145  0.06510051  0.32778227\n",
      "   1.4131594   0.9286525  -0.17033866  1.7770271 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [250/500], Cumulative Loss: 7.9210, LR: 1.000e-04\n",
      "Final parameters: [[ 0.396059    0.08828791  3.310255    0.2608357  -1.4893497  -0.5965791\n",
      "   2.5665743   1.5579402  -0.7671949   3.3899877 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [251/500], Cumulative Loss: 0.2912, LR: 1.000e-04\n",
      "Final parameters: [[1.0670117  2.244375   0.24460945 1.1794293  0.45587456 0.58643967\n",
      "  0.9508855  0.2657925  0.6812483  1.8722489 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [252/500], Cumulative Loss: 0.2684, LR: 1.000e-04\n",
      "Final parameters: [[1.0857378  1.666482   0.5028566  1.0869101  0.8398262  0.8768517\n",
      "  0.8772793  0.58087873 0.94802755 1.4434606 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [253/500], Cumulative Loss: 0.5007, LR: 1.000e-04\n",
      "Final parameters: [[ 1.6087891   2.3594565  -0.6594434   1.0709275   1.2331982   1.052624\n",
      "   0.422838    0.07230032  1.2601228   1.4275317 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [254/500], Cumulative Loss: 0.3409, LR: 1.000e-04\n",
      "Final parameters: [[ 1.3997887   2.6503863  -0.716032    1.1103239   0.9500175   0.8167769\n",
      "   0.41880232 -0.08268794  1.2209164   1.565011  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [255/500], Cumulative Loss: 0.0848, LR: 1.000e-04\n",
      "Final parameters: [[1.1305969  1.0737461  0.7238562  0.9889478  1.2511253  1.1407504\n",
      "  0.84439075 0.87894714 1.1031357  0.82358074]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [256/500], Cumulative Loss: 0.1822, LR: 1.000e-04\n",
      "Final parameters: [[1.0975436  0.72343963 0.8928627  0.92610985 1.562869   1.3823508\n",
      "  0.77592665 1.1010436  1.3724649  0.22187471]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [257/500], Cumulative Loss: 0.2261, LR: 1.000e-04\n",
      "Final parameters: [[1.1317374  1.458499   0.7692236  1.0097556  0.8192552  0.84970725\n",
      "  0.9526495  0.7836486  0.9326731  1.2660228 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [258/500], Cumulative Loss: 0.2014, LR: 1.000e-04\n",
      "Final parameters: [[1.1007628  1.4875218  0.45300582 1.0159332  0.95858145 0.9692386\n",
      "  0.8405488  0.6636326  1.0384562  1.2082632 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [259/500], Cumulative Loss: 0.1767, LR: 1.000e-04\n",
      "Final parameters: [[0.8890999  1.6241246  0.73607355 1.0945234  0.4149423  0.5607207\n",
      "  1.1163633  0.6154448  0.7292093  1.6078392 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [260/500], Cumulative Loss: 6.4633, LR: 1.000e-04\n",
      "Final parameters: [[ 0.70399487  0.70069164  0.65616363  1.7649748   2.3805587   1.7379712\n",
      "   0.63202757  1.2391224   2.2180164  -0.8316284 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [261/500], Cumulative Loss: 0.5379, LR: 1.000e-04\n",
      "Final parameters: [[1.3215121  1.0679085  0.10580923 1.0659488  2.0813875  1.6318727\n",
      "  0.52614367 0.7093674  1.6265934  0.2886473 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [262/500], Cumulative Loss: 29.2852, LR: 1.000e-04\n",
      "Final parameters: [[-0.8790096   0.8371314   2.2280278   1.1727266   1.170768    0.46192798\n",
      "   0.98510695 -0.29207128 -0.0508652  -4.057076  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [263/500], Cumulative Loss: 0.5170, LR: 1.000e-04\n",
      "Final parameters: [[ 0.4530958  -0.91808337  2.9849792   0.8580854   0.9596491   1.079633\n",
      "   1.7329769   2.2648811   0.7619877   0.44808048]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [264/500], Cumulative Loss: 0.0892, LR: 1.000e-04\n",
      "Final parameters: [[0.9399864  1.6417964  0.7255058  1.0738294  0.4799749  0.63304406\n",
      "  1.0882871  0.6492852  0.7252252  1.6524415 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [265/500], Cumulative Loss: 1.6698, LR: 1.000e-04\n",
      "Final parameters: [[0.9120047  1.5671796  0.21606246 1.3586185  0.9771104  0.80377203\n",
      "  0.98876387 0.6076707  1.3778503  1.200985  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [266/500], Cumulative Loss: 0.2378, LR: 1.000e-04\n",
      "Final parameters: [[1.0134387  2.0593421  0.53512    1.0939152  0.23193975 0.43479759\n",
      "  1.0676326  0.43592346 0.5328571  1.9716682 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [267/500], Cumulative Loss: 0.3410, LR: 1.000e-04\n",
      "Final parameters: [[ 0.82178885  1.608988    1.4319583   1.0483174  -0.01473785  0.29174548\n",
      "   1.3776941   0.9366233   0.3856102   1.7828339 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [268/500], Cumulative Loss: 0.0847, LR: 1.000e-04\n",
      "Final parameters: [[0.93205196 0.16832027 1.7018967  0.9321569  1.264394   1.153013\n",
      "  1.0870625  1.4080238  1.0116441  0.49703145]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [269/500], Cumulative Loss: 0.2919, LR: 1.000e-04\n",
      "Final parameters: [[1.0975047  0.73550135 0.8515487  0.9324121  1.4782304  1.321178\n",
      "  0.8582041  1.0943928  1.3158394  0.60957205]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [270/500], Cumulative Loss: 0.1474, LR: 1.000e-04\n",
      "Final parameters: [[0.9912882  0.4942356  1.3051293  0.8940965  1.2353079  1.1361395\n",
      "  0.96306384 1.3028616  1.1538163  0.53412676]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [271/500], Cumulative Loss: 0.2054, LR: 1.000e-04\n",
      "Final parameters: [[1.055975   0.82830685 0.9740254  0.95644456 1.2253717  1.1874372\n",
      "  0.93989277 1.0857949  1.2000592  0.85612595]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [272/500], Cumulative Loss: 0.1003, LR: 1.000e-04\n",
      "Final parameters: [[1.0768578  0.97181803 0.9421769  1.0163792  1.370827   1.2856374\n",
      "  0.8715444  1.124585   1.3098179  0.61614513]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [273/500], Cumulative Loss: 0.3669, LR: 1.000e-04\n",
      "Final parameters: [[1.366068   0.70819324 0.3672443  1.0428514  2.1112337  1.7225866\n",
      "  0.600148   0.8649559  1.5958201  0.31673533]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [274/500], Cumulative Loss: 0.0673, LR: 1.000e-04\n",
      "Final parameters: [[1.0876963  1.1823455  0.81768817 1.0621519  1.1878147  1.1458603\n",
      "  0.92562705 0.92904663 1.1996571  0.95036227]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [275/500], Cumulative Loss: 0.1508, LR: 1.000e-04\n",
      "Final parameters: [[1.1550974  1.0795128  0.5761736  0.94186777 1.2419378  1.1191676\n",
      "  0.7451067  0.86905915 1.2234346  0.78088987]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [276/500], Cumulative Loss: 0.5497, LR: 1.000e-04\n",
      "Final parameters: [[ 1.089188   -0.24569955  0.81650007  0.98686683  2.4637542   1.9077898\n",
      "   0.6551311   1.3508025   2.0150158  -0.28648555]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [277/500], Cumulative Loss: 0.1699, LR: 1.000e-04\n",
      "Final parameters: [[0.69609445 0.3374029  1.7098882  0.8561337  0.732271   0.8153732\n",
      "  1.2750803  1.4191848  0.8157851  0.77729523]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [278/500], Cumulative Loss: 62.7504, LR: 1.000e-04\n",
      "Final parameters: [[-2.420554    2.0529456   5.6532216   1.9641085  -2.4807305  -0.61981505\n",
      "   1.0954573   0.8552736  -1.2824398  -4.0470243 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [279/500], Cumulative Loss: 0.1320, LR: 1.000e-04\n",
      "Final parameters: [[1.1520139  2.461863   0.06522518 1.2378057  0.4908824  0.6126754\n",
      "  0.88475275 0.17481403 0.7462824  1.9598937 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [280/500], Cumulative Loss: 1.4082, LR: 1.000e-04\n",
      "Final parameters: [[0.7978197  0.29854393 2.2952929  0.65253484 0.66824    0.9258482\n",
      "  1.3173118  1.7539364  0.63251054 0.45131674]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [281/500], Cumulative Loss: 0.7511, LR: 1.000e-04\n",
      "Final parameters: [[ 0.28804785  0.80704653  2.43824     0.99231595 -0.231724    0.29471236\n",
      "   1.4073808   1.3213398  -0.0038105   1.2984474 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [282/500], Cumulative Loss: 5.7375, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1606525  -0.8764173   0.13633972  1.40792     3.8137581   2.6894066\n",
      "   0.4077102   1.2689418   2.8904235  -1.1582359 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [283/500], Cumulative Loss: 0.0520, LR: 1.000e-04\n",
      "Final parameters: [[0.98658305 1.4922292  0.5711657  0.99117255 0.60376835 0.7251545\n",
      "  0.9215308  0.6075802  0.80904675 1.432972  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [284/500], Cumulative Loss: 0.2352, LR: 1.000e-04\n",
      "Final parameters: [[1.1287042  1.1315186  0.6058763  1.0010579  1.2674421  1.1779038\n",
      "  0.77596676 0.8244255  1.2122483  0.89336205]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [285/500], Cumulative Loss: 1.1617, LR: 1.000e-04\n",
      "Final parameters: [[ 1.7850864   2.3285923  -0.8390766   1.1209358   1.8724258   1.5226578\n",
      "   0.17245613  0.21580546  1.6645839   0.8655731 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [286/500], Cumulative Loss: 5.4301, LR: 1.000e-04\n",
      "Final parameters: [[ 1.7830172  -0.03694337 -0.9731645   1.0075837   2.8238287   2.1072881\n",
      "   0.86049974  0.39862016  2.3742733   1.5216177 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [287/500], Cumulative Loss: 0.1311, LR: 1.000e-04\n",
      "Final parameters: [[0.8131985  0.65141743 1.3153875  0.92723125 0.78887427 0.82624435\n",
      "  1.1075618  1.1494534  0.8257317  0.8985585 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [288/500], Cumulative Loss: 3.0724, LR: 1.000e-04\n",
      "Final parameters: [[ 1.4547968   1.4322312  -0.09552273  0.5810806   1.8530545   1.5114427\n",
      "   0.3307761   0.40760761  1.6170478   0.60524726]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [289/500], Cumulative Loss: 0.7653, LR: 1.000e-04\n",
      "Final parameters: [[0.4535286  0.16012031 2.2939239  0.8954964  0.26224047 0.543763\n",
      "  1.6045469  1.5736573  0.46797547 1.1942868 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [290/500], Cumulative Loss: 0.7026, LR: 1.000e-04\n",
      "Final parameters: [[ 1.567513    2.2756643  -0.6290961   1.1449981   1.5905774   1.2981346\n",
      "   0.25722814  0.10307894  1.6110096   0.97399914]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [291/500], Cumulative Loss: 0.2865, LR: 1.000e-04\n",
      "Final parameters: [[ 1.369343    2.8107636  -0.2316064   1.1871618   0.44308865  0.5904913\n",
      "   0.7099906  -0.00743646  0.8283503   2.0508263 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [292/500], Cumulative Loss: 0.1637, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0886122   2.6643865   0.25945023  1.1432594  -0.1489985   0.05134588\n",
      "   1.0318807   0.08178316  0.1296069   2.5125484 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [293/500], Cumulative Loss: 0.2212, LR: 1.000e-04\n",
      "Final parameters: [[1.1406673  0.63546664 0.7367942  0.97072613 1.9360442  1.6229007\n",
      "  0.6662184  1.2054499  1.6527872  0.00722502]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [294/500], Cumulative Loss: 0.1944, LR: 1.000e-04\n",
      "Final parameters: [[1.2025931  0.79473346 0.660083   0.9897611  1.6493806  1.4603062\n",
      "  0.81478494 1.0889591  1.5643355  0.60496217]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [295/500], Cumulative Loss: 0.2059, LR: 1.000e-04\n",
      "Final parameters: [[1.1085228  1.0727327  0.68502253 1.0081289  1.3388613  1.2317672\n",
      "  0.8245287  0.9125191  1.2781882  0.8380111 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [296/500], Cumulative Loss: 0.1028, LR: 1.000e-04\n",
      "Final parameters: [[1.1033827  0.8565479  0.87359136 1.0312026  1.6086     1.4387301\n",
      "  0.8168373  1.1325061  1.4121884  0.4818094 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [297/500], Cumulative Loss: 0.5327, LR: 1.000e-04\n",
      "Final parameters: [[ 0.48861736 -1.0833094   2.857902    0.8386925   1.3003441   1.3034987\n",
      "   1.5574113   2.2435083   1.1093683   0.10316073]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [298/500], Cumulative Loss: 0.0761, LR: 1.000e-04\n",
      "Final parameters: [[0.99612063 0.56030446 1.2783508  0.97778195 1.3892934  1.2791303\n",
      "  1.0178531  1.3319988  1.2302698  0.5968878 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [299/500], Cumulative Loss: 0.2143, LR: 1.000e-04\n",
      "Final parameters: [[0.83698076 1.5147434  1.0499903  1.078575   0.17813233 0.44807905\n",
      "  1.2729309  0.7288219  0.49041435 1.927914  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [300/500], Cumulative Loss: 0.2365, LR: 1.000e-04\n",
      "Final parameters: [[1.1713204  1.8219532  0.27675772 1.0766178  0.95752865 0.9481582\n",
      "  0.80271053 0.58991826 1.1311598  1.3166263 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [301/500], Cumulative Loss: 0.2210, LR: 1.000e-04\n",
      "Final parameters: [[1.132571   0.896791   1.0398774  0.9775747  1.2003349  1.1342673\n",
      "  0.9408768  1.1225231  1.1813719  0.76912504]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [302/500], Cumulative Loss: 0.1197, LR: 1.000e-04\n",
      "Final parameters: [[1.0954186  1.276231   0.7040337  1.0023435  0.9752072  0.9996579\n",
      "  0.9438352  0.85191125 1.0645524  1.217159  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [303/500], Cumulative Loss: 0.3517, LR: 1.000e-04\n",
      "Final parameters: [[1.3555884  0.7961581  0.5569167  0.953287   1.9553747  1.6151421\n",
      "  0.57529    1.0997033  1.629471   0.23140246]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [304/500], Cumulative Loss: 0.2597, LR: 1.000e-04\n",
      "Final parameters: [[0.8014415  0.7676373  1.6591524  1.0142312  0.49563336 0.7176375\n",
      "  1.4650496  1.2003772  0.555799   1.4208058 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [305/500], Cumulative Loss: 0.0305, LR: 1.000e-04\n",
      "Final parameters: [[1.0361049  1.5758283  0.79532874 1.0925344  0.599422   0.72373724\n",
      "  1.0653688  0.7148552  0.76264215 1.542457  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [306/500], Cumulative Loss: 0.2643, LR: 1.000e-04\n",
      "Final parameters: [[1.2380501  1.1823862  0.49586296 1.0190517  1.4481071  1.3540506\n",
      "  0.7663231  0.9523722  1.4068716  0.8868544 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [307/500], Cumulative Loss: 0.5137, LR: 1.000e-04\n",
      "Final parameters: [[ 0.4893149  -0.6263801   2.7998219   0.89438856  0.89286786  0.9960539\n",
      "   1.5174284   2.0693383   0.8586465   0.36845532]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [308/500], Cumulative Loss: 8.4315, LR: 1.000e-04\n",
      "Final parameters: [[-0.592723    1.3693017   4.035294    1.4858152  -1.1784561   0.0115741\n",
      "   1.3206257   1.5173357  -0.74039096 -0.2537474 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [309/500], Cumulative Loss: 0.0387, LR: 1.000e-04\n",
      "Final parameters: [[1.1803074  1.2249035  0.75654423 1.0619588  1.1561992  1.1184506\n",
      "  0.93172944 0.9049424  1.1227739  1.0980678 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [310/500], Cumulative Loss: 1.1189, LR: 1.000e-04\n",
      "Final parameters: [[ 0.3966512   1.6989084   2.1816645   1.1134528  -1.1224847  -0.43451107\n",
      "   1.9504848   0.8702903  -0.5993577   2.7075977 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [311/500], Cumulative Loss: 0.1832, LR: 1.000e-04\n",
      "Final parameters: [[ 0.84031785 -0.22187245  1.8901114   0.89247996  1.49228     1.3567512\n",
      "   1.1928325   1.750971    1.2639766   0.2069773 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [312/500], Cumulative Loss: 0.2484, LR: 1.000e-04\n",
      "Final parameters: [[ 0.7654786  -0.09045691  1.7237736   0.89826214  1.3611029   1.2697948\n",
      "   1.1533291   1.6064322   1.1529727   0.3340791 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [313/500], Cumulative Loss: 0.2324, LR: 1.000e-04\n",
      "Final parameters: [[1.0675384 0.750821  1.1311663 0.9786137 1.3045074 1.2135463 0.9326029\n",
      "  1.1512237 1.1377201 0.6559774]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [314/500], Cumulative Loss: 0.2856, LR: 1.000e-04\n",
      "Final parameters: [[1.2417743  1.9305028  0.41521966 1.0791178  0.726416   0.79567885\n",
      "  0.808158   0.4864367  0.84174645 1.5002447 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [315/500], Cumulative Loss: 0.0906, LR: 1.000e-04\n",
      "Final parameters: [[1.1767722  1.8859749  0.21248628 1.0145642  0.7575137  0.7951573\n",
      "  0.67465603 0.4109366  0.9110595  1.4790199 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [316/500], Cumulative Loss: 0.4264, LR: 1.000e-04\n",
      "Final parameters: [[ 1.3492311   2.0595636  -0.1544172   1.1368095   1.3108418   1.1019603\n",
      "   0.43976107  0.3671331   1.3506671   0.95913666]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [317/500], Cumulative Loss: 0.3946, LR: 1.000e-04\n",
      "Final parameters: [[ 0.82672626  1.934098    1.0079284   1.0679507  -0.26032943  0.13417852\n",
      "   1.277957    0.5959846   0.2629414   2.1791704 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [318/500], Cumulative Loss: 0.0205, LR: 1.000e-04\n",
      "Final parameters: [[1.0161817  0.599406   1.353581   0.9567852  1.2672367  1.2083846\n",
      "  1.0189921  1.3200064  1.1747321  0.63280016]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [319/500], Cumulative Loss: 2.6159, LR: 1.000e-04\n",
      "Final parameters: [[1.1096829  0.51348174 0.67077845 1.3817288  1.8108987  1.6447885\n",
      "  0.86315185 1.1590866  2.1906283  0.52232236]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [320/500], Cumulative Loss: 0.1164, LR: 1.000e-04\n",
      "Final parameters: [[ 1.3375322   2.5195987  -0.10778056  1.1762986   0.59752715  0.71812665\n",
      "   0.8438176   0.20749174  0.9378626   2.0252757 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [321/500], Cumulative Loss: 0.0967, LR: 1.000e-04\n",
      "Final parameters: [[ 1.3106229   2.9447975  -0.1498457   1.1598408   0.15442589  0.37465042\n",
      "   0.76093835 -0.03935223  0.58435154  2.2140946 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [322/500], Cumulative Loss: 0.4649, LR: 1.000e-04\n",
      "Final parameters: [[1.4339422  1.295398   0.05609702 0.945108   1.5436479  1.3509663\n",
      "  0.6055155  0.7520473  1.4417601  0.86242473]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [323/500], Cumulative Loss: 0.4069, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0201588   2.655442   -0.00296849  1.2295021   0.23978043  0.47473338\n",
      "   0.80249846 -0.07415665  0.5669971   1.669118  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [324/500], Cumulative Loss: 0.2677, LR: 1.000e-04\n",
      "Final parameters: [[ 0.7237196   1.4564248   1.3401113   0.97551954 -0.16408819  0.18996394\n",
      "   1.3334264   0.80689216  0.22978202  1.8904264 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [325/500], Cumulative Loss: 0.2389, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1221693   2.9824681  -0.11657093  1.2686335  -0.04227956  0.26890844\n",
      "   0.97553396 -0.09450689  0.46074337  2.494786  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [326/500], Cumulative Loss: 0.0731, LR: 1.000e-04\n",
      "Final parameters: [[0.89085793 0.0121986  1.3654873  0.84056437 1.5612873  1.3468014\n",
      "  0.89617366 1.4085426  1.2844881  0.09369592]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [327/500], Cumulative Loss: 0.2137, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0666417   2.4151847   0.41882887  1.1266322  -0.04195486  0.2693444\n",
      "   1.1425308   0.2924125   0.39277273  2.380137  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [328/500], Cumulative Loss: 6.9649, LR: 1.000e-04\n",
      "Final parameters: [[ 2.1530025   3.39754    -1.9086779   1.0972505  -0.26120895 -0.04197454\n",
      "   1.7589717  -0.81569874  0.80477124  5.519456  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [329/500], Cumulative Loss: 0.8417, LR: 1.000e-04\n",
      "Final parameters: [[ 0.48129022  1.2440743   1.8843694   0.9910245  -0.45173144  0.04345039\n",
      "   1.6216928   1.0564605   0.04916067  1.9817594 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [330/500], Cumulative Loss: 1.6459, LR: 1.000e-04\n",
      "Final parameters: [[ 1.4805721   0.8528482  -0.46845105  1.1376662   2.70019     1.9914421\n",
      "   0.18579172  0.68232775  2.3893683   0.04499804]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [331/500], Cumulative Loss: 0.0564, LR: 1.000e-04\n",
      "Final parameters: [[0.9529008  1.030308   0.75504386 0.9357857  0.9612098  0.9410402\n",
      "  0.8946797  0.833484   0.957312   0.99550974]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [332/500], Cumulative Loss: 0.1754, LR: 1.000e-04\n",
      "Final parameters: [[1.1508732  1.8692387  0.286393   1.0486625  0.9424787  0.87816393\n",
      "  0.68543935 0.53354776 1.0126113  1.0738202 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [333/500], Cumulative Loss: 2.3614, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0601978   3.2373986  -0.7145635   1.6352296   0.62044704  0.62063813\n",
      "   0.6503805  -0.37049374  0.8941107   1.3520482 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [334/500], Cumulative Loss: 4.7604, LR: 1.000e-04\n",
      "Final parameters: [[ 1.8890314  1.7371688 -2.163723   1.1888212  2.3267179  1.5983506\n",
      "   0.5339151 -0.5628968  2.0133123  2.0427415]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [335/500], Cumulative Loss: 6.8539, LR: 1.000e-04\n",
      "Final parameters: [[-1.0764489   1.4424322   4.3025093   1.5888705  -2.5928192  -1.1062177\n",
      "   2.5929978   0.90458715 -1.8310721   2.888011  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [336/500], Cumulative Loss: 8.2348, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1187077  -0.30842522  0.16207533  1.2177747   1.5963919   0.8265672\n",
      "   1.7713706   1.0824122   1.2599458   2.332539  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [337/500], Cumulative Loss: 0.8201, LR: 1.000e-04\n",
      "Final parameters: [[ 1.005348    1.5934893   1.0917771   0.875417   -0.12848449  0.06724408\n",
      "   1.4682064   0.6007481   0.12016137  2.5255315 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [338/500], Cumulative Loss: 0.0956, LR: 1.000e-04\n",
      "Final parameters: [[0.9585846  1.3580493  0.6926501  1.0086677  0.63797843 0.68527126\n",
      "  0.9996898  0.65665936 0.72542816 1.4013703 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [339/500], Cumulative Loss: 13.7432, LR: 1.000e-04\n",
      "Final parameters: [[ 2.7718627  -0.42731205 -1.8912119   0.06973295  3.789325    2.2466524\n",
      "   0.98899776  0.8865663   2.9975538   2.1288712 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [340/500], Cumulative Loss: 27.4787, LR: 1.000e-04\n",
      "Final parameters: [[-1.3487222   3.2845752   4.6972327   1.5328609  -2.8530226  -1.6367108\n",
      "   1.2726475   0.7899245  -2.3550596  -0.96199125]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [341/500], Cumulative Loss: 189.9018, LR: 1.000e-04\n",
      "Final parameters: [[-6.642      -0.20397174  2.5829377   3.4069297   0.15291181  1.1490413\n",
      "   2.8679864   1.3859078   2.137188   -5.3499765 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [342/500], Cumulative Loss: 0.3639, LR: 1.000e-04\n",
      "Final parameters: [[1.0859226  1.5395061  0.24409932 1.0926391  1.1523888  1.0631276\n",
      "  0.6966616  0.47728822 1.1062367  1.051482  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [343/500], Cumulative Loss: 3.9119, LR: 1.000e-04\n",
      "Final parameters: [[ 0.48287612  2.3021111   2.2020626   0.97326016 -0.36040294  0.12837408\n",
      "   0.7851237   1.193933    0.03214708  0.6564972 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [344/500], Cumulative Loss: 20.1158, LR: 1.000e-04\n",
      "Final parameters: [[ 1.4765828   1.2986658   1.904636   -0.28847122 -0.82912123 -0.39331335\n",
      "   1.9276437   0.7246965  -1.2961906   2.9250064 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [345/500], Cumulative Loss: 232.8664, LR: 1.000e-04\n",
      "Final parameters: [[-6.6385536  -1.3115977   4.665806    5.0105906   3.105539    0.29528233\n",
      "   4.2733784  -0.890859   -1.1668385  -6.6085773 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [346/500], Cumulative Loss: 19.9301, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0282229   2.018025    1.6262245   1.1598606   0.59756315  0.76541436\n",
      "  -0.24768335 -0.7731042  -1.3604252   1.8701688 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [347/500], Cumulative Loss: 5.1757, LR: 1.000e-04\n",
      "Final parameters: [[ 1.685007    0.03150035 -0.4023323   0.6829974   2.5337293   1.6763409\n",
      "   1.1226146   1.1057843   1.9219713   1.6864128 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [348/500], Cumulative Loss: 84.9505, LR: 1.000e-04\n",
      "Final parameters: [[ 2.7569296   2.3331194  -3.081451   -0.07230905  4.9684362   4.951073\n",
      "  -2.094511   -1.2119763   0.59661806 -1.035286  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [349/500], Cumulative Loss: 0.5858, LR: 1.000e-04\n",
      "Final parameters: [[1.2832863  0.9135486  0.94652194 0.83509344 1.2368268  1.1150364\n",
      "  0.9626829  1.0784643  0.8425037  1.0913286 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [350/500], Cumulative Loss: 37.4190, LR: 1.000e-04\n",
      "Final parameters: [[ 1.6393673   1.5945916   2.644594   -0.85060006 -1.631498   -0.5604389\n",
      "   1.3729516   1.1291122  -0.51817775  1.9632132 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [351/500], Cumulative Loss: 2.0848, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0868336   2.6540716   1.1823194   0.96659064 -1.3340957  -0.7966504\n",
      "   1.8431271   0.0763697  -0.5811077   3.524137  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [352/500], Cumulative Loss: 278.7671, LR: 1.000e-04\n",
      "Final parameters: [[-2.3777385   0.86799294  6.878277    6.6521964  -2.8040307  -3.0239522\n",
      "   3.6683378   3.599934   -1.9545244   0.23249629]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [353/500], Cumulative Loss: 18.4519, LR: 1.000e-04\n",
      "Final parameters: [[ 1.9939796   1.6275219   0.06208365 -0.45713753  1.7527163   0.9999191\n",
      "   0.605876    0.37997186  0.8125484  -0.16203049]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [354/500], Cumulative Loss: 11.8796, LR: 1.000e-04\n",
      "Final parameters: [[ 0.5064971   0.77787757  3.8616235   0.5472996  -1.2799066  -0.32760972\n",
      "   1.9673564   1.9252206   0.04085271  0.07476547]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [355/500], Cumulative Loss: 0.7348, LR: 1.000e-04\n",
      "Final parameters: [[ 0.71812135  0.2724437   1.2897091   1.0987914   1.6091799   1.3294481\n",
      "   1.1102561   1.526734    1.3899101  -0.09919201]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [356/500], Cumulative Loss: 0.1750, LR: 1.000e-04\n",
      "Final parameters: [[0.941398   1.4739677  0.6541209  1.0728568  0.74596715 0.80456424\n",
      "  0.97451085 0.72818786 0.82254046 1.4520738 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [357/500], Cumulative Loss: 3.9953, LR: 1.000e-04\n",
      "Final parameters: [[ 0.22647461  0.16511849  2.2381384   1.5517803   1.1960564   1.3536842\n",
      "   1.114949    1.6041802   1.018312   -0.8251256 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [358/500], Cumulative Loss: 25.3275, LR: 1.000e-04\n",
      "Final parameters: [[ 3.0569978  1.8410984 -1.3987298  0.6456624  1.6483927  1.3775555\n",
      "   0.857677   1.3139477  1.8896955  5.7747226]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [359/500], Cumulative Loss: 18.7617, LR: 1.000e-04\n",
      "Final parameters: [[ 2.3061254  -1.1613296   0.67547864  0.78105676  3.0653417   3.2025483\n",
      "   0.3515888   1.9231789   3.467871    2.6691265 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [360/500], Cumulative Loss: 88.7757, LR: 1.000e-04\n",
      "Final parameters: [[-3.9692826   0.7604401   4.642781    3.2995236  -0.74445945 -0.37753844\n",
      "   2.2065582   2.7744844   1.3914154  -4.7052627 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [361/500], Cumulative Loss: 69.1279, LR: 1.000e-04\n",
      "Final parameters: [[ 4.2421393   0.730394   -3.8394995  -1.5166028   4.579008    3.6629212\n",
      "  -1.482867    0.45127642  4.4701      3.0963433 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [362/500], Cumulative Loss: 10.7614, LR: 1.000e-04\n",
      "Final parameters: [[ 3.4018283   1.182721   -3.664007    0.31349432  4.469587    2.7655802\n",
      "  -0.01723733 -0.291458    2.9463298   1.2429833 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [363/500], Cumulative Loss: 676.8730, LR: 1.000e-04\n",
      "Final parameters: [[-10.438465    -0.46563014  10.140754     9.238049     0.88982934\n",
      "   -2.60004      4.429388     6.000356    -0.50994384  -9.535035  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [364/500], Cumulative Loss: 50.3558, LR: 1.000e-04\n",
      "Final parameters: [[ 4.1136804   0.5207317  -1.8256427  -0.10727301  2.91064     2.0759146\n",
      "   0.55147064  1.897202    2.9292898   6.285161  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [365/500], Cumulative Loss: 12.2198, LR: 1.000e-04\n",
      "Final parameters: [[ 2.165742   1.3835204 -1.6809069  1.0718213  3.7067254  2.7820334\n",
      "  -0.5042147 -0.8962418  1.1549376  0.3532476]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [366/500], Cumulative Loss: 225.0340, LR: 1.000e-04\n",
      "Final parameters: [[-6.619251   -1.0500221   5.906435    5.3496046   1.4346906  -0.47396776\n",
      "   3.7283657   0.95521784 -0.21347672 -6.519296  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [367/500], Cumulative Loss: 3.8769, LR: 1.000e-04\n",
      "Final parameters: [[ 0.8418959   1.402404    1.550498    1.0470666  -0.30229294 -0.20042342\n",
      "   1.0439075   1.3621091   0.58081084  2.5309334 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [368/500], Cumulative Loss: 55.1491, LR: 1.000e-04\n",
      "Final parameters: [[ 1.6158046  -0.5855063   0.61460567  1.7858398   2.1626637   0.5513415\n",
      "   0.04305238  0.46114475  0.13861792  3.8488393 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [369/500], Cumulative Loss: 19.0054, LR: 1.000e-04\n",
      "Final parameters: [[-0.27445906  0.54431975  0.90647304  1.9151872   1.3540058   0.09300583\n",
      "   1.1769525   1.1372104   1.3549423  -0.1790245 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [370/500], Cumulative Loss: 32.1226, LR: 1.000e-04\n",
      "Final parameters: [[ 0.944077   3.0076537  3.0458171  0.462106  -2.08215   -1.0900668\n",
      "   1.8169988 -0.8715621 -1.5331656  1.0155593]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [371/500], Cumulative Loss: 21.0878, LR: 1.000e-04\n",
      "Final parameters: [[ 2.4831486   1.6097987  -0.55046135 -0.37226954  1.296433    1.7743695\n",
      "   0.49183255 -0.00335874  0.5695106   1.9467762 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [372/500], Cumulative Loss: 8.5388, LR: 1.000e-04\n",
      "Final parameters: [[ 1.2512639   1.9439117  -1.6021779   1.765617    2.298895    1.3713261\n",
      "   0.49407342 -0.29499128  1.5964996   1.5904028 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [373/500], Cumulative Loss: 6.2429, LR: 1.000e-04\n",
      "Final parameters: [[ 1.2979745   0.7429485   2.1894324   0.26206434 -0.14705867  0.7257945\n",
      "   1.2836415   1.4745507   0.07127701  1.9730709 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [374/500], Cumulative Loss: 9.6255, LR: 1.000e-04\n",
      "Final parameters: [[ 2.4704113   0.99734855 -1.4766705   0.11215911  2.3493657   1.5434461\n",
      "   0.54300267  0.49804628  2.200551    2.4025688 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [375/500], Cumulative Loss: 8.2698, LR: 1.000e-04\n",
      "Final parameters: [[-0.11954968  0.935606    2.0578828   1.5098928   0.51371187  1.0719697\n",
      "   0.8897402   0.79621667  0.7636026  -1.3625699 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [376/500], Cumulative Loss: 23.5845, LR: 1.000e-04\n",
      "Final parameters: [[-1.3344377   1.6890181   1.5914747   2.023582   -0.3987681   0.66799116\n",
      "   1.3124052   0.8199827   2.0867243  -0.31810257]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [377/500], Cumulative Loss: 17.7706, LR: 1.000e-04\n",
      "Final parameters: [[ 1.3154094   0.78546774 -1.8040193   1.1226145   2.5578036   2.07657\n",
      "   0.40640152  1.5834582   2.5621314   2.246039  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [378/500], Cumulative Loss: 9.6546, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0495816   1.5957292  -1.5235807   0.8685006   1.5765673   1.4598664\n",
      "   0.77597195  0.54397124  1.644079    2.5260026 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [379/500], Cumulative Loss: 24.4434, LR: 1.000e-04\n",
      "Final parameters: [[ 0.92609704  3.290186    0.394585   -0.05158415 -0.02277422 -0.10905629\n",
      "   1.2398665  -1.1674812  -0.37451392  0.03230455]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [380/500], Cumulative Loss: 30.6110, LR: 1.000e-04\n",
      "Final parameters: [[ 1.151196    0.6278169   0.2659403   0.78694236  2.7050855   2.5543785\n",
      "   0.2950618   0.22259569 -0.7654947  -0.31351095]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [381/500], Cumulative Loss: 122.4145, LR: 1.000e-04\n",
      "Final parameters: [[ 5.398132   2.9458153 -5.1538806 -2.39333    2.9751513  4.5382977\n",
      "  -1.9339406 -1.5765957  3.232473   4.2157683]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [382/500], Cumulative Loss: 12.6680, LR: 1.000e-04\n",
      "Final parameters: [[ 0.87741745 -0.20721954 -0.8986082   0.8267831   2.3423889   0.97842413\n",
      "   1.1251353   1.752353    2.733752    0.53022265]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [383/500], Cumulative Loss: 324.2450, LR: 1.000e-04\n",
      "Final parameters: [[ 9.694463    2.9806004  -4.425927   -4.455787   -0.6869649   1.2727844\n",
      "  -1.7047162   0.33035284  2.4745486   9.447246  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [384/500], Cumulative Loss: 23.7658, LR: 1.000e-04\n",
      "Final parameters: [[ 1.9060256   1.2224374   2.6684873  -0.00574917 -0.26491943  0.18285288\n",
      "   1.5151094   0.6905787  -0.54535556  1.5104175 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [385/500], Cumulative Loss: 102.6073, LR: 1.000e-04\n",
      "Final parameters: [[-3.021569   2.2369354  5.239675   2.9708037 -1.7019727 -1.2914685\n",
      "   2.1161427 -0.699334  -3.8944018 -5.093949 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [386/500], Cumulative Loss: 26.3436, LR: 1.000e-04\n",
      "Final parameters: [[ 3.887322    2.5443585  -2.8380964  -0.08972907  2.0802293   2.0827086\n",
      "  -0.05971628  1.0435568   2.2499745   4.7154384 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [387/500], Cumulative Loss: 87.6841, LR: 1.000e-04\n",
      "Final parameters: [[ 5.7663116   1.2615747  -1.562432   -1.6777608   1.6424519   1.6453263\n",
      "   0.10110784 -0.7290669   0.54852015  5.496008  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [388/500], Cumulative Loss: 18.9485, LR: 1.000e-04\n",
      "Final parameters: [[ 3.197709    1.5936458  -2.539938    0.60440564  2.832111    2.0720384\n",
      "   0.445769    0.83130527  2.6885388   4.3794284 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [389/500], Cumulative Loss: 16.0271, LR: 1.000e-04\n",
      "Final parameters: [[-1.2192326  -0.79080045  2.4218922   1.7536044   1.4578763   2.2002208\n",
      "   1.2494175   1.7989671   2.3005128  -1.6507607 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [390/500], Cumulative Loss: 4.2789, LR: 1.000e-04\n",
      "Final parameters: [[ 1.6944183  -0.16189998 -0.51753944  1.0277795   2.868464    2.124008\n",
      "   0.90848166  0.8103688   2.2043679   1.094811  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [391/500], Cumulative Loss: 6.8936, LR: 1.000e-04\n",
      "Final parameters: [[ 0.39077267  0.5207179   3.850679    0.96814483 -0.14802085  1.1392277\n",
      "   1.1392344   2.0081756   0.37477764 -0.2998259 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [392/500], Cumulative Loss: 94.1661, LR: 1.000e-04\n",
      "Final parameters: [[ 5.1158013   0.7924659  -3.5003057  -2.1566126   2.6494155   3.5242715\n",
      "  -0.32097518  0.12434687  2.2454455   4.5499096 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [393/500], Cumulative Loss: 1.9825, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0285085   1.082944   -0.07139414  1.1061096   1.9736471   1.6315434\n",
      "   0.6636493   0.57273436  1.601302   -0.45611152]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [394/500], Cumulative Loss: 31.2485, LR: 1.000e-04\n",
      "Final parameters: [[ 4.15773     2.3946464  -4.360271   -0.10401005  3.3917725   1.50186\n",
      "   0.44087863 -0.24365583  2.6065745   5.184809  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [395/500], Cumulative Loss: 0.4876, LR: 1.000e-04\n",
      "Final parameters: [[ 1.4098586  1.9401991 -0.4232993  1.0788479  1.3070782  1.163068\n",
      "   0.5283503  0.2853312  1.1822813  1.3351188]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [396/500], Cumulative Loss: 64.4190, LR: 1.000e-04\n",
      "Final parameters: [[ 5.3863406   1.3634651  -4.53927    -1.3311553   3.8272355   1.8063511\n",
      "   0.1595289  -0.32785785  2.6760342   5.356991  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [397/500], Cumulative Loss: 13.7470, LR: 1.000e-04\n",
      "Final parameters: [[ 2.3486745   2.6815462  -3.156538    0.88869554  2.4024067   2.045705\n",
      "   0.06887563 -0.22046742  2.3994277   3.8453465 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [398/500], Cumulative Loss: 21.3343, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0298735   0.46046853 -0.21782114  2.016358    1.0276887   1.7636914\n",
      "   0.9951808   0.1991297   3.2449348   2.238285  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [399/500], Cumulative Loss: 2.5407, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1616311   1.3193368  -0.05803297  1.4436401   2.3284302   1.8077298\n",
      "   0.2540228   0.80013156  1.7135274  -0.5430193 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [400/500], Cumulative Loss: 3.4599, LR: 1.000e-04\n",
      "Final parameters: [[ 1.6850604   1.9438882  -1.4458994   1.1974876   2.5910883   2.2310963\n",
      "   0.11611624  0.19947553  2.4340494   0.70400685]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [401/500], Cumulative Loss: 8.4929, LR: 1.000e-04\n",
      "Final parameters: [[ 3.177928    0.686095   -3.0357084   0.4597625   4.7450924   3.5514724\n",
      "  -0.5101904   0.6225734   3.717714    0.65751827]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [402/500], Cumulative Loss: 7.8913, LR: 1.000e-04\n",
      "Final parameters: [[ 1.5450448   2.4255695   1.240402    0.74889433 -0.2200434   1.0514485\n",
      "   1.0095971   0.8432192   0.4911072   1.9166737 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [403/500], Cumulative Loss: 15.6488, LR: 1.000e-04\n",
      "Final parameters: [[ 3.0246806   1.8288163  -0.9847182   0.18657148  1.4019887   1.682024\n",
      "  -0.10974465  0.15465866  1.5105994   3.8891387 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [404/500], Cumulative Loss: 13.1153, LR: 1.000e-04\n",
      "Final parameters: [[1.6667944  1.8974134  0.90545326 0.05954742 0.44410866 1.18374\n",
      "  0.6757282  0.79600865 0.73157156 0.7634584 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [405/500], Cumulative Loss: 3.3910, LR: 1.000e-04\n",
      "Final parameters: [[ 1.8656343   1.1192031  -1.2588471   1.2650169   3.2414207   2.3808095\n",
      "  -0.18483952  0.48449856  2.9194431   0.01380441]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [406/500], Cumulative Loss: 12.8278, LR: 1.000e-04\n",
      "Final parameters: [[ 2.658969    1.5115592  -1.0770686   0.50951827  1.6453402   1.3238945\n",
      "   0.814285    1.1067284   1.8261734   4.2572927 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [407/500], Cumulative Loss: 1.2635, LR: 1.000e-04\n",
      "Final parameters: [[1.5852125  1.3016064  0.17182776 0.7954054  1.4423532  1.3753525\n",
      "  0.73200333 0.6748262  1.0634874  1.2459345 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [408/500], Cumulative Loss: 0.0618, LR: 1.000e-04\n",
      "Final parameters: [[ 0.92509466 -0.31999132  1.7826011   0.87213236  1.8738374   1.5843744\n",
      "   0.8875077   1.695083    1.3840592  -0.26778114]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [409/500], Cumulative Loss: 0.1021, LR: 1.000e-04\n",
      "Final parameters: [[1.0362327  0.9103738  0.8953179  1.0579534  1.3846632  1.2586385\n",
      "  0.9273476  1.0317737  1.227669   0.77383804]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [410/500], Cumulative Loss: 67.6342, LR: 1.000e-04\n",
      "Final parameters: [[ 3.499955   2.297193  -2.1739385 -1.3914323  1.8751038  3.6274376\n",
      "  -0.9821277  0.3706982  2.3059103  3.2928584]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [411/500], Cumulative Loss: 5.6170, LR: 1.000e-04\n",
      "Final parameters: [[ 1.3614954   1.1952986   1.1929158   0.5248537   1.5145997   1.9853249\n",
      "   0.0270523   1.3933185   1.6928314  -0.38756832]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [412/500], Cumulative Loss: 0.7095, LR: 1.000e-04\n",
      "Final parameters: [[0.8371228  0.55017227 1.1233269  1.1880603  1.5932083  1.3690168\n",
      "  0.90419614 1.3124123  1.5299765  0.07520598]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [413/500], Cumulative Loss: 0.3337, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1448061 -0.0181424  1.2707907  0.8326339  1.9875818  1.7801781\n",
      "   0.7137536  1.5161303  1.7574303 -0.3437208]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [414/500], Cumulative Loss: 99.0331, LR: 1.000e-04\n",
      "Final parameters: [[ 4.4293184   3.0048947  -4.68622    -2.1647398   4.835651    3.055074\n",
      "  -2.059078   -0.76188684  3.833517   -0.48460734]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [415/500], Cumulative Loss: 0.2984, LR: 1.000e-04\n",
      "Final parameters: [[0.54623795 0.8841908  1.84335    0.99454147 0.26035327 0.5248273\n",
      "  1.3929418  1.2920165  0.43411583 1.2359546 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [416/500], Cumulative Loss: 13.1127, LR: 1.000e-04\n",
      "Final parameters: [[ 2.0269804   1.7470235   0.02983098  0.06288255  1.8852384   2.5379443\n",
      "  -0.22860372  1.1425501   1.7517661   0.3939317 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [417/500], Cumulative Loss: 11.8066, LR: 1.000e-04\n",
      "Final parameters: [[ 2.1833646   0.27028418 -0.92748237  0.6453534   2.926506    2.140782\n",
      "   0.7457767   1.5833523   2.4130487   2.5961525 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [418/500], Cumulative Loss: 1.3127, LR: 1.000e-04\n",
      "Final parameters: [[0.7895184  0.98509765 1.4680009  1.3127146  0.8937166  0.90402335\n",
      "  1.0725093  1.1920285  0.75962085 0.38089743]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [419/500], Cumulative Loss: 0.4329, LR: 1.000e-04\n",
      "Final parameters: [[1.2560103  0.6186385  0.59090555 0.86308205 1.8053118  1.5121927\n",
      "  0.62880695 1.0865743  1.6003356  0.38899168]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [420/500], Cumulative Loss: 18.3740, LR: 1.000e-04\n",
      "Final parameters: [[ 2.528865    0.42855915  0.130887   -0.35316294  1.6340841   2.2073658\n",
      "   0.38565412  0.89623743  1.0495113   2.2427318 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [421/500], Cumulative Loss: 0.3385, LR: 1.000e-04\n",
      "Final parameters: [[0.7914582  1.5817966  1.0010428  1.1741021  0.28714752 0.51646066\n",
      "  1.2934083  0.61591786 0.62875396 1.5651474 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [422/500], Cumulative Loss: 11.9196, LR: 1.000e-04\n",
      "Final parameters: [[ 2.2828984   1.6703588  -1.0052795   0.37960535  2.352122    2.4650779\n",
      "  -1.1077911   0.8089198   3.3200624   1.3512219 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [423/500], Cumulative Loss: 44.2756, LR: 1.000e-04\n",
      "Final parameters: [[ 3.847514    2.2538934  -0.51772326 -0.8702019   0.3208451   1.8330983\n",
      "   0.08421196  0.42587313  0.6793195   4.421996  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [424/500], Cumulative Loss: 8.9884, LR: 1.000e-04\n",
      "Final parameters: [[ 1.4307702   1.4965255  -1.2787044   1.387038    2.4161365   1.5174253\n",
      "   0.41762328 -0.05622474  1.4018048   2.331868  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [425/500], Cumulative Loss: 39.3115, LR: 1.000e-04\n",
      "Final parameters: [[ 3.132436    2.7993987   0.40319642 -0.51098144 -0.19830531  1.155715\n",
      "  -0.1593498   1.2413553   1.1217164   2.031699  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [426/500], Cumulative Loss: 0.0148, LR: 1.000e-04\n",
      "Final parameters: [[1.0153759  0.18073544 1.3877534  0.9131426  1.638129   1.4130812\n",
      "  0.9001902  1.3942869  1.2886821  0.11396758]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [427/500], Cumulative Loss: 17.6443, LR: 1.000e-04\n",
      "Final parameters: [[ 0.46389586 -0.6584343   1.025328    2.1179247   1.252301    1.3869927\n",
      "   1.494015    0.68017775  1.9585911   1.4742095 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [428/500], Cumulative Loss: 1.5232, LR: 1.000e-04\n",
      "Final parameters: [[ 1.679871    1.7848471  -0.56170547  0.77357566  1.3313965   1.4127859\n",
      "   0.45228705  0.6029496   1.6495832   1.8592227 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [429/500], Cumulative Loss: 25.9168, LR: 1.000e-04\n",
      "Final parameters: [[ 0.31663483  1.6817093   1.9176383   0.6380805  -1.0942702  -1.1353426\n",
      "   2.6076026   1.698468    0.8568194  -0.34332883]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [430/500], Cumulative Loss: 42.1931, LR: 1.000e-04\n",
      "Final parameters: [[ 4.119015    0.3835259  -3.8230524   0.17296107  4.9354024   3.223651\n",
      "   0.19901562  1.5327326   4.0623174   4.5770364 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [431/500], Cumulative Loss: 0.3784, LR: 1.000e-04\n",
      "Final parameters: [[0.98391485 1.5889556  0.5410101  1.1507523  0.8452896  0.91211355\n",
      "  0.89545107 0.63950825 0.94942516 1.3356068 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [432/500], Cumulative Loss: 1.0185, LR: 1.000e-04\n",
      "Final parameters: [[ 1.3119205   2.4880965  -0.26360983  1.0478956   0.9677997   1.1148767\n",
      "   0.54871845 -0.22499092  1.1030072   1.2694784 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [433/500], Cumulative Loss: 17.7682, LR: 1.000e-04\n",
      "Final parameters: [[ 3.2414892   0.69083405 -0.5797508  -0.31376195  2.5087118   1.9895161\n",
      "   0.40135908  0.7556211   1.0913204   1.9091097 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [434/500], Cumulative Loss: 46.4168, LR: 1.000e-04\n",
      "Final parameters: [[ 3.0797617   2.3494482  -2.3711665  -1.200027    3.7620609   1.4862591\n",
      "  -0.01865342 -0.28774178  1.7838621  -0.76137906]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [435/500], Cumulative Loss: 25.5454, LR: 1.000e-04\n",
      "Final parameters: [[ 3.1944153   0.53610384 -1.2074788  -0.65320003  2.3752902   1.9647065\n",
      "   0.06155483  0.5463636   2.129176    2.9416692 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [436/500], Cumulative Loss: 24.2647, LR: 1.000e-04\n",
      "Final parameters: [[ 1.687691    2.7610192   1.6594937  -0.08371182 -0.8216117   1.1881635\n",
      "   0.5810503   1.0170755   0.05876869  2.0621462 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [437/500], Cumulative Loss: 12.7028, LR: 1.000e-04\n",
      "Final parameters: [[ 0.94910806  0.58371174 -0.32747185  1.981949    1.6301665   1.5442953\n",
      "   1.2607604  -0.0688257   1.6375217   2.073554  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [438/500], Cumulative Loss: 0.3318, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1895535   2.5738983  -0.17867666  1.1864115   0.50277764  0.6436147\n",
      "   0.78338075  0.2168392   1.0534421   1.8640517 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [439/500], Cumulative Loss: 192.3604, LR: 1.000e-04\n",
      "Final parameters: [[ 3.5209458   3.227447   -2.7387352  -3.1380005   3.9809167   4.999144\n",
      "  -2.2592967  -0.063336    2.7448864  -0.34396976]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [440/500], Cumulative Loss: 84.8695, LR: 1.000e-04\n",
      "Final parameters: [[ 5.5203795   3.2292864  -3.2653372  -0.94581306  0.6619451   3.7604744\n",
      "  -1.0042572   1.1287768   2.2922916   7.784008  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [441/500], Cumulative Loss: 61.4884, LR: 1.000e-04\n",
      "Final parameters: [[ 3.9475472   2.3306196   2.0317614  -0.40065512 -0.9623614  -0.9962104\n",
      "   1.3310294   1.4829047  -0.23847333  2.7342637 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [442/500], Cumulative Loss: 2.8943, LR: 1.000e-04\n",
      "Final parameters: [[ 1.6119189   1.9950145  -0.9355572   1.3646762   1.4401231   1.1887869\n",
      "   0.4929205  -0.04247808  2.0123873   2.0159388 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [443/500], Cumulative Loss: 80.3646, LR: 1.000e-04\n",
      "Final parameters: [[ 5.923332   1.2175635 -2.963511  -1.1311392  2.8912616  2.4727252\n",
      "  -0.3707911  0.5755729  2.132046   7.0215554]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [444/500], Cumulative Loss: 2.6049, LR: 1.000e-04\n",
      "Final parameters: [[ 1.4290915   0.9383689  -0.25589365  1.3545762   2.7075822   2.0585332\n",
      "   0.14247659  0.8867944   2.348802   -0.08958168]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [445/500], Cumulative Loss: 141.5939, LR: 1.000e-04\n",
      "Final parameters: [[ 7.298544   1.3176097 -4.432765  -1.0291654  5.137181   5.543592\n",
      "  -2.842401  -3.043455   2.6369166  6.7283807]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [446/500], Cumulative Loss: 21.0515, LR: 1.000e-04\n",
      "Final parameters: [[ 3.5788343   0.08664948 -2.8325782  -0.19291602  4.2907004   2.4972363\n",
      "   0.34182966  0.884736    3.3313282   2.6711462 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [447/500], Cumulative Loss: 31.5289, LR: 1.000e-04\n",
      "Final parameters: [[ 2.9954834   2.7881434  -2.4547873  -0.42741877  2.416385    3.4494696\n",
      "  -0.81303036  0.2578249   2.5676098   1.6850399 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [448/500], Cumulative Loss: 26.1897, LR: 1.000e-04\n",
      "Final parameters: [[ 1.7976723   2.7526057  -0.17311502  0.28843048  1.7395976   2.6005778\n",
      "  -0.30302545  0.17206094  0.21372405  0.5967331 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [449/500], Cumulative Loss: 41.0229, LR: 1.000e-04\n",
      "Final parameters: [[ 4.1838183   2.3916624  -1.7824634   0.2989831   1.7127588   2.0589771\n",
      "  -0.46899226  1.0241183   2.0372477   6.7009687 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [450/500], Cumulative Loss: 1.7442, LR: 1.000e-04\n",
      "Final parameters: [[ 1.6652739   2.047198   -0.7822021   1.3036182   1.682261    1.4856057\n",
      "   0.21533218  0.39039904  1.6909772   1.7354093 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [451/500], Cumulative Loss: 0.1209, LR: 1.000e-04\n",
      "Final parameters: [[1.0448159  1.0798746  0.716367   0.9647163  1.0636449  1.0514644\n",
      "  0.899036   0.89965343 1.0534093  0.9255984 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [452/500], Cumulative Loss: 3.6675, LR: 1.000e-04\n",
      "Final parameters: [[1.583172   0.7373098  0.99819773 0.675179   0.9339139  0.89373416\n",
      "  1.1957722  1.4485102  0.98388666 2.5869417 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [453/500], Cumulative Loss: 1.5149, LR: 1.000e-04\n",
      "Final parameters: [[ 1.8113292   0.78456837 -0.66548866  0.9615611   2.7672594   2.1101072\n",
      "   0.2386752   0.54071337  2.2223969   0.6492908 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [454/500], Cumulative Loss: 0.0943, LR: 1.000e-04\n",
      "Final parameters: [[ 0.8958193  -0.59177536  1.5440439   0.7710726   2.1533673   1.790585\n",
      "   0.80121416  1.7688301   1.6345009  -0.522578  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [455/500], Cumulative Loss: 74.2488, LR: 1.000e-04\n",
      "Final parameters: [[ 5.8782063   0.9472994  -4.5856953  -0.8581449   4.235563    2.6905751\n",
      "  -0.14592701  0.66773075  3.595377    6.591294  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [456/500], Cumulative Loss: 9.4323, LR: 1.000e-04\n",
      "Final parameters: [[ 1.2378932  -0.95329773  0.19849211  1.5853024   3.0446918   2.555611\n",
      "   0.6654439   1.0416865   2.948243    0.11584587]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [457/500], Cumulative Loss: 1.5584, LR: 1.000e-04\n",
      "Final parameters: [[ 1.3188764   0.52533805  1.1220405   0.77978605  2.0807986   1.8534629\n",
      "   0.31448966  1.5700109   1.8788538  -0.6174283 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [458/500], Cumulative Loss: 1.1989, LR: 1.000e-04\n",
      "Final parameters: [[1.5379125  0.01742219 0.22707781 0.7342277  2.3230307  1.8016393\n",
      "  0.913457   1.304703   1.9467874  0.8347937 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [459/500], Cumulative Loss: 11.1298, LR: 1.000e-04\n",
      "Final parameters: [[ 2.2957695  1.8312857 -1.0370158  0.9058553  0.7395598  0.9692179\n",
      "   1.3112221  1.2772996  1.6669673  4.767383 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [460/500], Cumulative Loss: 6.0757, LR: 1.000e-04\n",
      "Final parameters: [[ 0.9350606   1.3581412   2.0852003   0.66600496 -0.28205338 -0.43772998\n",
      "   2.4262402   0.7631505  -0.7867135   1.4989272 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [461/500], Cumulative Loss: 0.6565, LR: 1.000e-04\n",
      "Final parameters: [[1.333969   0.7553673  0.12309176 1.0638264  2.1632292  1.8038598\n",
      "  0.6036982  0.7421495  1.6822562  0.4791794 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [462/500], Cumulative Loss: 0.2641, LR: 1.000e-04\n",
      "Final parameters: [[0.8666376  0.7787431  1.442323   0.9783964  0.840907   0.8853457\n",
      "  1.2114495  1.2875444  0.90518594 0.9828359 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [463/500], Cumulative Loss: 1.5132, LR: 1.000e-04\n",
      "Final parameters: [[0.6352391  1.921572   0.5350122  1.4827783  0.4385262  0.8182646\n",
      "  1.0118225  0.40681303 1.0029461  1.4902263 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [464/500], Cumulative Loss: 107.3368, LR: 1.000e-04\n",
      "Final parameters: [[ 6.421855    3.489209   -6.1429358  -2.079204    2.578688    1.1373332\n",
      "   0.08002788 -1.9774071   1.1444374   7.163181  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [465/500], Cumulative Loss: 27.8384, LR: 1.000e-04\n",
      "Final parameters: [[ 3.6244118   0.5749267  -2.35491    -0.02280428  3.2768242   2.2304132\n",
      "   0.4984277   1.063188    3.1666358   4.353836  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [466/500], Cumulative Loss: 1.4232, LR: 1.000e-04\n",
      "Final parameters: [[ 1.394453    0.8164289   0.4414565   0.8898609   2.5594141   2.1601715\n",
      "  -0.0058595   1.2452462   2.1498404  -0.75089157]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [467/500], Cumulative Loss: 22.9936, LR: 1.000e-04\n",
      "Final parameters: [[ 2.449992    2.2348008   0.15200105 -0.5577845  -0.57439995 -0.06815112\n",
      "   1.2076657   0.15778789 -0.05701352  3.7382424 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [468/500], Cumulative Loss: 0.2179, LR: 1.000e-04\n",
      "Final parameters: [[ 0.8287062   1.5286058   1.1581678   1.0459448  -0.01432913  0.35936192\n",
      "   1.4195646   0.80969596  0.44829845  2.1486328 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [469/500], Cumulative Loss: 0.2874, LR: 1.000e-04\n",
      "Final parameters: [[1.3976517  1.709661   0.00661713 1.0149685  1.3675071  1.2070413\n",
      "  0.53351855 0.6031424  1.4447798  0.96136385]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [470/500], Cumulative Loss: 0.2298, LR: 1.000e-04\n",
      "Final parameters: [[1.1365842  1.5583352  0.7033726  1.0412472  0.8368417  0.86016643\n",
      "  0.87833583 0.7281823  0.9519629  1.1817148 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [471/500], Cumulative Loss: 0.4679, LR: 1.000e-04\n",
      "Final parameters: [[1.3850883  0.86566025 0.43488356 0.98207486 2.0803087  1.7103134\n",
      "  0.4864664  0.99635565 1.668229   0.05503853]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [472/500], Cumulative Loss: 1.0790, LR: 1.000e-04\n",
      "Final parameters: [[ 1.4275606   1.0202823  -0.05534377  1.0806319   2.1393902   1.6576618\n",
      "   0.40015018  0.7712969   1.9886274   0.33652198]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [473/500], Cumulative Loss: 0.1757, LR: 1.000e-04\n",
      "Final parameters: [[1.087181   1.4223212  0.686417   1.0305841  0.96506274 0.9538906\n",
      "  0.9055711  0.77629495 1.0076486  1.2515751 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [474/500], Cumulative Loss: 3.3846, LR: 1.000e-04\n",
      "Final parameters: [[1.0210016  0.2654628  0.6380063  1.4087801  1.5182672  1.537391\n",
      "  0.99595666 0.99595475 2.010387   0.9900403 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [475/500], Cumulative Loss: 0.2528, LR: 1.000e-04\n",
      "Final parameters: [[ 1.0992689   0.17271349  1.1670572   0.9086616   1.9265488   1.6320243\n",
      "   0.8186921   1.4374759   1.5118282  -0.03432266]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [476/500], Cumulative Loss: 3.6174, LR: 1.000e-04\n",
      "Final parameters: [[ 2.3949049   2.142836   -0.9414077   0.55692464  1.3593478   0.849372\n",
      "   0.6466994   0.12175975  0.99617815  2.2406385 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [477/500], Cumulative Loss: 5.1128, LR: 1.000e-04\n",
      "Final parameters: [[ 0.38804823  2.7454543   0.9928194   1.8585936  -0.08543801  0.41293687\n",
      "   0.9543506   0.26638958  0.18502228  0.75912195]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [478/500], Cumulative Loss: 6.0824, LR: 1.000e-04\n",
      "Final parameters: [[ 0.93969434 -0.42489868  0.9900388   0.9230195   1.4095811   0.19780791\n",
      "   1.8915818   1.5157095   0.6827588   1.5266635 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [479/500], Cumulative Loss: 0.5800, LR: 1.000e-04\n",
      "Final parameters: [[ 0.84423363  2.8778636   1.0400681   1.12778    -0.9673249  -0.21685854\n",
      "   1.2225196   0.427942   -0.03041748  2.6008446 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [480/500], Cumulative Loss: 4.8139, LR: 1.000e-04\n",
      "Final parameters: [[1.3783516  0.99314874 0.5811746  1.1364113  0.9097005  1.150431\n",
      "  0.98927885 1.5586512  1.2795004  2.785345  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [481/500], Cumulative Loss: 1.0885, LR: 1.000e-04\n",
      "Final parameters: [[1.0907209  0.41362935 0.52860713 1.0985906  1.5664657  1.3440216\n",
      "  1.1351264  0.93959594 1.3686588  1.2347091 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [482/500], Cumulative Loss: 42.1162, LR: 1.000e-04\n",
      "Final parameters: [[ 3.7295287   2.6306012  -1.8319724  -1.1492434   1.1207571   0.7852016\n",
      "   0.20479482 -0.38949877  0.7280392   3.3945193 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [483/500], Cumulative Loss: 1.0179, LR: 1.000e-04\n",
      "Final parameters: [[ 0.70416486 -0.19064823  1.4115355   0.86876637  1.9415712   1.6010538\n",
      "   0.9028668   1.3903974   1.439626   -0.97868526]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [484/500], Cumulative Loss: 12.0594, LR: 1.000e-04\n",
      "Final parameters: [[ 1.4505625   3.312111    1.0017782   0.45308882 -0.125462    0.8042792\n",
      "  -0.12897408  1.1542462   1.0304322   0.80156744]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [485/500], Cumulative Loss: 1.4312, LR: 1.000e-04\n",
      "Final parameters: [[ 1.514543    1.1321397  -0.23312406  1.0037932   1.7817384   1.3811545\n",
      "   0.747536    0.586354    1.5155447   1.6882918 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [486/500], Cumulative Loss: 19.8025, LR: 1.000e-04\n",
      "Final parameters: [[ 3.3216736   2.3167791  -2.4036696  -0.2345493   1.6374515   1.2918235\n",
      "   0.12069964 -0.51655436  1.6859602   3.989385  ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [487/500], Cumulative Loss: 0.3133, LR: 1.000e-04\n",
      "Final parameters: [[0.70197284 1.2029876  1.7246349  1.074188   0.08922693 0.351424\n",
      "  1.4474581  0.96356785 0.2065211  1.7114135 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [488/500], Cumulative Loss: 6.0583, LR: 1.000e-04\n",
      "Final parameters: [[2.1024997  0.2110662  0.52568007 0.11729893 1.7727338  1.4117831\n",
      "  0.69907737 1.3320388  1.4447435  1.7079434 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [489/500], Cumulative Loss: 17.5736, LR: 1.000e-04\n",
      "Final parameters: [[ 1.4349241   1.1478596  -0.70495445  0.7632153   2.444937    3.0378768\n",
      "   0.14553422 -0.7541928   0.96043754  0.18811734]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [490/500], Cumulative Loss: 0.6350, LR: 1.000e-04\n",
      "Final parameters: [[1.2341073  1.4903369  0.550715   0.88285655 1.2589129  1.1682111\n",
      "  0.582638   0.7406217  1.2094414  0.68854344]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [491/500], Cumulative Loss: 10.3452, LR: 1.000e-04\n",
      "Final parameters: [[ 2.5963995   3.0628839  -2.0260255   1.0501183   0.9299949   1.1593314\n",
      "   0.5841537   0.14321534  1.7443475   5.1326156 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [492/500], Cumulative Loss: 32.0566, LR: 1.000e-04\n",
      "Final parameters: [[ 3.9517455   1.3365543  -3.988013   -0.36705375  3.822559    1.7048699\n",
      "   0.5564146  -0.05958614  2.861074    4.4086103 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [493/500], Cumulative Loss: 0.1403, LR: 1.000e-04\n",
      "Final parameters: [[0.7177973  0.26979214 1.460368   0.98955125 1.1440008  1.1793115\n",
      "  1.1247838  1.3630301  1.2048429  0.49605137]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [494/500], Cumulative Loss: 3.4488, LR: 1.000e-04\n",
      "Final parameters: [[ 2.0277958   1.3681604  -0.8800044   0.704588    2.4743037   2.3541687\n",
      "  -0.4279278   0.66779375  2.8777628   0.27392206]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [495/500], Cumulative Loss: 0.5491, LR: 1.000e-04\n",
      "Final parameters: [[0.9473927  0.6951925  0.73552096 1.1553744  1.517818   1.3481967\n",
      "  0.8675624  1.0687402  1.4869993  0.5072668 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [496/500], Cumulative Loss: 1.9834, LR: 1.000e-04\n",
      "Final parameters: [[ 1.6356894   2.6177752  -0.2696631   1.1426219   0.5952044   1.0729262\n",
      "   0.160797    0.21266234  1.2178224   2.7829998 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [497/500], Cumulative Loss: 4.0834, LR: 1.000e-04\n",
      "Final parameters: [[ 1.235694    1.4768076   1.5943505   0.44835237 -0.1953761   0.53837746\n",
      "   1.1970416   0.9171276   0.07194542  2.2004778 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [498/500], Cumulative Loss: 0.1658, LR: 1.000e-04\n",
      "Final parameters: [[ 1.1020592  -0.01526282  1.0456139   0.91750336  2.2178273   1.8357333\n",
      "   0.8318403   1.4196272   1.679409   -0.15146288]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [499/500], Cumulative Loss: 0.0398, LR: 1.000e-04\n",
      "Final parameters: [[0.99515015 1.3361537  0.8676997  0.96071744 0.6280567  0.70883065\n",
      "  1.0542719  0.83329976 0.7759617  1.3815199 ]]\n",
      "Param Shape torch.Size([10, 1])\n",
      "Epoch [500/500], Cumulative Loss: 5.3644, LR: 1.000e-04\n",
      "Final parameters: [[ 2.2087233   0.38165468 -1.6149552   0.8103303   3.2506137   2.2560718\n",
      "   0.5779786   0.34688413  2.6611772   1.5339882 ]]\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "n = 10\n",
    "W = np.random.randn(n, n)\n",
    "theta0 = np.ones((n, 1))\n",
    "lstm_optimizer = LSTMConcurrent(num_optims=1)\n",
    "writer = SummaryWriter(\"train/LSTMC_gamma_0_e4\") \n",
    "meta_optimizer = optim.Adam(lstm_optimizer.parameters(), lr=0.0001)\n",
    "lstm_optimizer = train_LSTM(lstm_optimizer, meta_optimizer, QuadraticOptimizee, {\"W\": W, \"theta0\": theta0}, num_epochs=500, time_horizon=500, discount=None, writer=writer)\n",
    "writer = SummaryWriter(\"runs/LSTMC_gamma_0_e4\")\n",
    "params = test_LSTM(lstm_optimizer, QuadraticOptimizee, {\"W\": W, \"theta0\": theta0}, time_horizon=1000, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Optimizee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNNOptimizee(Optimizee):\n",
    "    \"\"\"\n",
    "    Class for a generic linear neural network optimizee.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dataloader = dataloader\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.model = nn.Sequential(nn.Linear(input_size, hidden_size), nn.ReLU(), nn.Linear(hidden_size, output_size))\n",
    "        self.num_params = sum(p.numel() for p in self.model.parameters())\n",
    "    \n",
    "    \n",
    "    def set_params(self, params=None):\n",
    "        \"\"\"\n",
    "        Given a tensor of shape (d,1), sets the parameters of the optimizee.\n",
    "        \"\"\"\n",
    "        if params is not None:\n",
    "            params = torch.flatten(params)\n",
    "            i = 0\n",
    "            for param in self.model.parameters():\n",
    "                param_size = param.numel()\n",
    "                param.data = params[i:i + param_size].view_as(param)\n",
    "                i += param_size\n",
    "\n",
    "\n",
    "    def compute_loss(self, params, num_samples=10, return_grad=True):\n",
    "        self.set_params(params)  # Set model parameters\n",
    "        total_loss = None\n",
    "        dataloader_iter = iter(self.dataloader)\n",
    "        for _ in range(num_samples):\n",
    "            try: inputs, targets = next(dataloader_iter)  # Get a batch\n",
    "            except StopIteration: dataloader_iter = iter(self.dataloader); inputs, targets = next(dataloader_iter)\n",
    "            outputs = self.model(inputs.flatten())  # Forward pass\n",
    "            targets_oh = torch.zeros_like(outputs)\n",
    "            targets_oh[targets] = 1\n",
    "            loss = torch.norm((outputs - targets_oh) ** 2)\n",
    "            total_loss = loss if total_loss is None else total_loss + loss\n",
    "        total_loss = total_loss / num_samples\n",
    "\n",
    "        if return_grad:\n",
    "            grads = torch.autograd.grad(total_loss, self.model.parameters(), create_graph=True)\n",
    "            # grads = torch.autograd.grad(total_loss, self.model.parameters(), grad_outputs=torch.ones_like(total_loss), retain_graph=True, create_graph=True)\n",
    "            grads = torch.cat([g.flatten() for g in grads]).unsqueeze(-1)\n",
    "            return total_loss, grads.detach()\n",
    "        else:\n",
    "            return total_loss\n",
    "\n",
    "    \n",
    "    def all_parameters(self):\n",
    "        \"\"\"\n",
    "        Returns all parameters of the optimizee, as a tensor of shape (d,1).\n",
    "        \"\"\"\n",
    "        return torch.cat([p.flatten() for p in self.model.parameters()]).unsqueeze(-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape torch.Size([1, 1, 28, 28])\n",
      "Target Shape torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform (convert images to tensors and normalize)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training dataset\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "dataloader_iter = iter(train_loader)\n",
    "inputs, targets = next(dataloader_iter)\n",
    "print(\"Input Shape\", inputs.shape)\n",
    "print(\"Target Shape\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"dataloader\": train_loader, \"input_size\": 784, \"hidden_size\": 20, \"output_size\": 10}\n",
    "\n",
    "lstm_optimizer = LSTMConcurrent(num_optims=1, preproc=True)\n",
    "meta_optimizer = optim.Adam(lstm_optimizer.parameters(), lr=0.01)\n",
    "# lstm_optimizer = train_LSTM(lstm_optimizer, meta_optimizer, LinearNNOptimizee, kwargs, num_epochs=10, time_horizon=200, discount=1e-3)\n",
    "# params = test_LSTM(lstm_optimizer, LinearNNOptimizee, kwargs, time_horizon=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Optimizee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "y = (y-np.mean(y))/np.std(y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLOptimizee(Optimizee):\n",
    "    \"\"\"\n",
    "    Class for a generic linear neural network optimizee.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.input_size = X.shape[1]\n",
    "        try: self.output_size = y.shape[1]\n",
    "        except: self.output_size = 1\n",
    "        self.model = nn.Linear(self.input_size, self.output_size)\n",
    "        # self.num_params = sum(p.numel() for p in self.model.parameters())\n",
    "    \n",
    "    \n",
    "    def set_params(self, params=None):\n",
    "        \"\"\"\n",
    "        Given a tensor of shape (d,1), sets the parameters of the optimizee.\n",
    "        \"\"\"\n",
    "        if params is not None:\n",
    "            params = params.squeeze(-1)\n",
    "            # params.requires_grad = True\n",
    "            # print(\"Params_0\", torch.nn.utils.parameters_to_vector(self.model.parameters()))\n",
    "            torch.nn.utils.vector_to_parameters(params, self.model.parameters())\n",
    "            # print(\"Params_1\", torch.nn.utils.parameters_to_vector(self.model.parameters()))\n",
    "\n",
    "    def compute_loss(self, params, return_grad=True):\n",
    "        self.set_params(params)  # Set model parameters\n",
    "        outputs = self.model(self.X)\n",
    "        # print(\"Outputs\", outputs[:10])\n",
    "        loss = torch.norm((outputs - self.y))/len(self.X)\n",
    "        # print(loss)\n",
    "        \n",
    "        if return_grad:\n",
    "            grads = torch.autograd.grad(loss, self.model.parameters(), create_graph=True)\n",
    "            grads = torch.cat([g.flatten() for g in grads]).unsqueeze(-1)\n",
    "            detached_grads = torch.tensor(grads.data, requires_grad=True)\n",
    "            # print(\"Detached Grads\", detached_grads)\n",
    "            return loss, detached_grads\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def all_parameters(self):\n",
    "        \"\"\"\n",
    "        Returns all parameters of the optimizee, as a tensor of shape (d,1).\n",
    "        \"\"\"\n",
    "        params = self.model.parameters()\n",
    "        param_vector = torch.nn.utils.parameters_to_vector(params)\n",
    "        # print(\"Param Vector\", param_vector.shape)\n",
    "        return param_vector.unsqueeze(-1)\n",
    "    \n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "    \n",
    "    def eval(self):\n",
    "        self.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params torch.Size([11, 1])\n",
      "torch.Size([11, 1])\n",
      "Loss tensor(1.0315, grad_fn=<DivBackward0>)\n",
      "Grad tensor([[0.0066],\n",
      "        [0.0020],\n",
      "        [0.0047],\n",
      "        [0.0077],\n",
      "        [0.0050],\n",
      "        [0.0035],\n",
      "        [0.0005],\n",
      "        [0.0024],\n",
      "        [0.0047],\n",
      "        [0.0049],\n",
      "        [0.1396]], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_8360\\3985852619.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  detached_grads = torch.tensor(grads.data, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update tensor([[0.1088],\n",
      "        [0.0961],\n",
      "        [0.0869],\n",
      "        [0.0799],\n",
      "        [0.0746],\n",
      "        [0.0706],\n",
      "        [0.0676],\n",
      "        [0.0651],\n",
      "        [0.0630],\n",
      "        [0.0616],\n",
      "        [0.0603]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_8360\\690785197.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(preprocessed).to(gradients.device)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "n = 10\n",
    "W = np.random.randn(n,1)\n",
    "b = np.random.randn(1)\n",
    "params = torch.cat([torch.tensor(p, requires_grad=True, dtype=torch.float32).flatten() for p in [W, b]]).unsqueeze(-1)\n",
    "print(\"Params\", params.shape)\n",
    "\n",
    "optimizee = MLOptimizee(X, y)\n",
    "optimizee.set_params(params)\n",
    "print(optimizee.all_parameters().shape)\n",
    "l_a,grad_a = optimizee.compute_loss(params, return_grad=True)\n",
    "\n",
    "print(\"Loss\", l_a)\n",
    "print(\"Grad\", grad_a)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "lstm_optimizer = LSTMConcurrent(num_optims=1, preproc=True)\n",
    "meta_optimizer = optim.Adam(lstm_optimizer.parameters(), lr=0.01)\n",
    "h = lstm_optimizer.initialize_hidden_state()\n",
    "update, h = lstm_optimizer(grad_a, h)\n",
    "print(\"Update\", update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8181417cc7541068222fd69e828aafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Shape torch.Size([11, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_14784\\3985852619.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  detached_grads = torch.tensor(grads.data, requires_grad=True)\n",
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_14784\\690785197.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(preprocessed).to(gradients.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Loss tensor(638.8634, grad_fn=<AddBackward0>)\n",
      "Gradients None\n",
      "Gradients None\n",
      "Gradients None\n",
      "Epoch [1/10], Cumulative Loss: 638.8634, LR: 1.000e-01\n",
      "Final parameters: [[108.90109   95.8711    86.76418   79.97159   74.91464   70.7601\n",
      "   63.504707  62.144447  62.54211   62.329365  61.46543 ]]\n",
      "Param Shape torch.Size([11, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# meta_optimizer = optim.SGD(lstm_optimizer.parameters(), lr=0.1)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiabetes_logs_train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m lstm_optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_LSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMLOptimizee\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiabetes_logs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m params \u001b[38;5;241m=\u001b[39m test_LSTM(lstm_optimizer, MLOptimizee, kwargs, time_horizon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, writer\u001b[38;5;241m=\u001b[39mwriter)\n",
      "Cell \u001b[1;32mIn[40], line 40\u001b[0m, in \u001b[0;36mtrain_LSTM\u001b[1;34m(lstm_optimizer, meta_optimizer, optimizee_class, optimizee_kwargs, num_optimizees, num_epochs, time_horizon, discount, scheduler, noise, writer)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_optimizees):\n\u001b[0;32m     39\u001b[0m     optimizee \u001b[38;5;241m=\u001b[39m optimizees[i]\n\u001b[1;32m---> 40\u001b[0m     loss, grad_params \u001b[38;5;241m=\u001b[39m \u001b[43moptimizee\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m discount: cumulative_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m*\u001b[39mdiscount\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(time_horizon\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m cumulative_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m cumulative_loss \u001b[38;5;241m+\u001b[39m loss\u001b[38;5;241m*\u001b[39mdiscount\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(time_horizon\u001b[38;5;241m-\u001b[39mt\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m i\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m: cumulative_loss \u001b[38;5;241m=\u001b[39m loss\n",
      "Cell \u001b[1;32mIn[16], line 37\u001b[0m, in \u001b[0;36mMLOptimizee.compute_loss\u001b[1;34m(self, params, return_grad)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# print(loss)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_grad:\n\u001b[1;32m---> 37\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     grads \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([g\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     39\u001b[0m     detached_grads \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(grads\u001b[38;5;241m.\u001b[39mdata, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\miche\\anaconda3\\envs\\MLAI\\Lib\\site-packages\\torch\\autograd\\__init__.py:411\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[0;32m    408\u001b[0m         grad_outputs_\n\u001b[0;32m    409\u001b[0m     )\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 411\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    422\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[0;32m    424\u001b[0m     ):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Delete folders if present\n",
    "try:\n",
    "    shutil.rmtree(\"diabetes_logs_train\")\n",
    "    shutil.rmtree(\"diabetes_logs\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "kwargs = {\"X\": X, \"y\": y}\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "lstm_optimizer = LSTMConcurrent(num_optims=1, preproc=True)\n",
    "meta_optimizer = optim.Adam(lstm_optimizer.parameters(), lr=0.1)\n",
    "# meta_optimizer = optim.SGD(lstm_optimizer.parameters(), lr=0.1)\n",
    "writer = SummaryWriter(\"diabetes_logs_train\")\n",
    "lstm_optimizer = train_LSTM(lstm_optimizer, meta_optimizer, MLOptimizee, kwargs, num_epochs=10, time_horizon=1000, discount=0.9, writer=writer)\n",
    "writer = SummaryWriter(\"diabetes_logs\")\n",
    "params = test_LSTM(lstm_optimizer, MLOptimizee, kwargs, time_horizon=1000, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate But Explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLOptimizee2(Optimizee):\n",
    "    \"\"\"\n",
    "    Class for a generic linear neural network optimizee.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.input_size = X.shape[1]\n",
    "        try: self.output_size = y.shape[1]\n",
    "        except: self.output_size = 1\n",
    "        self.W = torch.randn(self.input_size, self.output_size, requires_grad=True)\n",
    "        self.b = torch.randn(self.output_size, requires_grad=True)\n",
    "        # self.num_params = sum(p.numel() for p in self.model.parameters())\n",
    "    \n",
    "    \n",
    "    def set_params(self, params=None):\n",
    "        \"\"\"\n",
    "        Given a tensor of shape (d,1), sets the parameters of the optimizee.\n",
    "        \"\"\"\n",
    "        if params is not None:\n",
    "            params = params.squeeze(-1)\n",
    "            # print(\"Params\", params.shape)\n",
    "            # print(\"Input Size\", self.input_size)\n",
    "            # print(\"Output Size\", self.output_size)\n",
    "            self.W = params[:self.input_size*self.output_size].view(self.input_size, self.output_size)\n",
    "            self.b = params[self.input_size*self.output_size:].view(self.output_size)\n",
    "\n",
    "    def compute_loss(self, params, return_grad=True):\n",
    "        self.set_params(params)  # Set model parameters\n",
    "        outputs = self.X @ self.W + self.b\n",
    "        # print(\"Outputs\", outputs[:10])\n",
    "        loss = torch.norm((outputs - self.y))/len(self.X)\n",
    "        # print(loss)\n",
    "        \n",
    "        if return_grad:\n",
    "            grads = torch.autograd.grad(loss, [self.W, self.b], create_graph=True)\n",
    "            # grads = torch.autograd.grad(loss, self.model.parameters(), create_graph=True)\n",
    "            grads = torch.cat([g.flatten() for g in grads]).unsqueeze(-1)\n",
    "            detached_grads = torch.tensor(grads.data, requires_grad=True)\n",
    "            # print(\"Detached Grads\", detached_grads)\n",
    "            return loss, detached_grads\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def all_parameters(self):\n",
    "        \"\"\"\n",
    "        Returns all parameters of the optimizee, as a tensor of shape (d,1).\n",
    "        \"\"\"\n",
    "        params = [self.W, self.b]\n",
    "        param_vector = torch.cat([p.flatten() for p in params])\n",
    "        # print(\"Param Vector\", param_vector.shape)\n",
    "        return param_vector.unsqueeze(-1)\n",
    "    \n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    def eval(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params torch.Size([11, 1])\n",
      "Loss tensor(1.0315, grad_fn=<DivBackward0>)\n",
      "Grad tensor([[0.0066],\n",
      "        [0.0020],\n",
      "        [0.0047],\n",
      "        [0.0077],\n",
      "        [0.0050],\n",
      "        [0.0035],\n",
      "        [0.0005],\n",
      "        [0.0024],\n",
      "        [0.0047],\n",
      "        [0.0049],\n",
      "        [0.1396]], requires_grad=True)\n",
      "Loss Equality: tensor(True)\n",
      "Grad Equality: True\n",
      "Update tensor([[0.1088],\n",
      "        [0.0961],\n",
      "        [0.0869],\n",
      "        [0.0799],\n",
      "        [0.0746],\n",
      "        [0.0706],\n",
      "        [0.0676],\n",
      "        [0.0651],\n",
      "        [0.0630],\n",
      "        [0.0616],\n",
      "        [0.0603]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_8360\\4019566987.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  detached_grads = torch.tensor(grads.data, requires_grad=True)\n",
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_8360\\690785197.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(preprocessed).to(gradients.device)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "n = 10\n",
    "W = np.random.randn(n,1)\n",
    "b = np.random.randn(1)\n",
    "params = torch.cat([torch.tensor(p, requires_grad=True, dtype=torch.float32).flatten() for p in [W, b]]).unsqueeze(-1)\n",
    "print(\"Params\", params.shape)\n",
    "\n",
    "optimizee = MLOptimizee2(X, y)\n",
    "optimizee.set_params(params)\n",
    "l_b,grad_b = optimizee.compute_loss(params, return_grad=True)\n",
    "\n",
    "print(\"Loss\", l_b)\n",
    "print(\"Grad\", grad_b)\n",
    "\n",
    "print(\"Loss Equality:\", l_a==l_b)\n",
    "print(\"Grad Equality:\", all(grad_a==grad_b))\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "lstm_optimizer = LSTMConcurrent(num_optims=1, preproc=True)\n",
    "meta_optimizer = optim.Adam(lstm_optimizer.parameters(), lr=0.01)\n",
    "h = lstm_optimizer.initialize_hidden_state()\n",
    "update, h = lstm_optimizer(grad_b, h)\n",
    "print(\"Update\", update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28039949179749f1bcdeab1afb171905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Shape torch.Size([11, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_14784\\4019566987.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  detached_grads = torch.tensor(grads.data, requires_grad=True)\n",
      "C:\\Users\\miche\\AppData\\Local\\Temp\\ipykernel_14784\\690785197.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(preprocessed).to(gradients.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Loss tensor(638.8801, grad_fn=<AddBackward0>)\n",
      "Gradients tensor([[-8.2694e+00,  2.2519e+01],\n",
      "        [ 1.2429e+01, -2.6161e+01],\n",
      "        [-1.1729e+01,  2.2701e+01],\n",
      "        [ 2.0954e+00, -1.0450e+00],\n",
      "        [ 2.3422e+00, -6.4323e+00],\n",
      "        [-5.8192e+00,  1.9537e+00],\n",
      "        [-3.5288e-01, -7.0682e+00],\n",
      "        [-7.2662e+00,  1.7907e+01],\n",
      "        [ 4.9376e+00, -8.6743e+00],\n",
      "        [ 1.5881e+00, -8.2688e+00],\n",
      "        [ 9.4228e+00, -7.1600e+00],\n",
      "        [ 2.1644e+01, -3.4812e+01],\n",
      "        [-9.0719e+00,  1.5027e+01],\n",
      "        [ 2.5435e+00, -4.7904e-01],\n",
      "        [-2.5219e+00,  3.9381e+00],\n",
      "        [ 1.2774e+00, -4.3193e+00],\n",
      "        [ 1.6063e+00, -2.0071e+00],\n",
      "        [-9.8706e+00,  2.9679e+01],\n",
      "        [ 7.5756e-01,  1.4232e+00],\n",
      "        [-1.4419e-02, -4.1741e-01],\n",
      "        [-7.5414e+00,  1.9022e+01],\n",
      "        [ 1.0789e+01, -1.3917e+01],\n",
      "        [-1.1831e+01,  2.0995e+01],\n",
      "        [ 2.1610e+00,  1.2172e+00],\n",
      "        [ 2.1705e+00, -4.8427e+00],\n",
      "        [-4.3608e+00,  8.1299e+00],\n",
      "        [-1.3928e+00,  3.3203e+00],\n",
      "        [-6.5218e+00,  1.1108e+01],\n",
      "        [ 6.5609e+00, -1.6440e+01],\n",
      "        [ 6.2567e-01, -2.5105e+00],\n",
      "        [ 1.0400e+01, -2.2671e+01],\n",
      "        [ 2.0152e+01, -3.4967e+01],\n",
      "        [-8.8596e+00,  1.5235e+01],\n",
      "        [ 2.0905e+00, -3.9370e+00],\n",
      "        [-3.0535e+00,  6.7184e+00],\n",
      "        [ 1.6797e+00, -1.9467e+00],\n",
      "        [ 1.6821e+00,  9.1967e-01],\n",
      "        [-6.9357e+00,  2.0205e+01],\n",
      "        [ 4.1432e-01,  2.6214e+00],\n",
      "        [ 4.7779e-02,  1.5623e+00],\n",
      "        [-2.8689e+01,  7.1352e+01],\n",
      "        [-5.9743e+01,  7.0963e+01],\n",
      "        [ 9.2130e+01, -1.6004e+02],\n",
      "        [-2.0779e+01,  4.5880e+00],\n",
      "        [-2.0415e+01,  4.6193e+01],\n",
      "        [ 9.8005e+01, -1.7370e+02],\n",
      "        [ 1.3234e+02, -2.7990e+02],\n",
      "        [ 5.9515e+01, -1.0260e+02],\n",
      "        [-1.1323e+02,  3.0389e+02],\n",
      "        [-3.8849e+01,  1.1128e+02],\n",
      "        [-1.3097e+02,  2.9752e+02],\n",
      "        [ 9.3366e+01, -1.7893e+02],\n",
      "        [-4.6628e+01,  8.2618e+01],\n",
      "        [ 4.3410e+01, -7.5797e+01],\n",
      "        [ 1.0085e+02, -2.0358e+02],\n",
      "        [ 3.6614e+01, -5.7178e+01],\n",
      "        [ 1.2747e+01, -7.3692e-01],\n",
      "        [ 6.1114e+01, -1.5772e+02],\n",
      "        [ 6.4570e+00,  9.7932e+00],\n",
      "        [ 4.1946e+01,  1.2595e+01],\n",
      "        [-5.8308e+00,  2.4955e+01],\n",
      "        [ 1.0205e+01, -1.6496e+01],\n",
      "        [-1.0047e+01,  2.3311e+01],\n",
      "        [ 3.9332e+00,  5.5420e-01],\n",
      "        [ 2.0202e+00, -7.5038e+00],\n",
      "        [-4.5059e+00,  6.3118e+00],\n",
      "        [-5.0308e-01, -3.8070e+00],\n",
      "        [-8.0482e+00,  1.9916e+01],\n",
      "        [ 4.8059e+00, -1.7553e+01],\n",
      "        [ 5.2629e-01, -4.7710e+00],\n",
      "        [ 7.0839e+00, -1.7536e+01],\n",
      "        [ 2.5446e+01, -5.4502e+01],\n",
      "        [-9.3943e+00,  1.9047e+01],\n",
      "        [ 2.6815e+00, -2.3286e+00],\n",
      "        [-1.8629e+00,  5.5303e+00],\n",
      "        [ 1.8937e+00, -4.4672e+00],\n",
      "        [ 2.7442e+00,  5.9397e-02],\n",
      "        [-4.8535e+00,  2.5695e+01],\n",
      "        [ 1.8336e+00,  2.7704e+00],\n",
      "        [ 4.9199e-01,  6.1140e-01]])\n",
      "Gradients tensor([[ 4.6678, -4.1348, -2.9338,  ..., -2.5108,  3.4957,  0.3670],\n",
      "        [-4.5896,  4.0598,  2.9053,  ...,  2.3267, -3.4981, -0.1047],\n",
      "        [ 5.0883, -4.4418, -3.2337,  ..., -2.6157,  3.9657,  0.2523],\n",
      "        ...,\n",
      "        [ 5.3578, -4.7925, -3.3344,  ..., -3.0417,  3.8919,  0.6382],\n",
      "        [ 0.2140, -0.1861, -0.1583,  ..., -0.1516,  0.1493,  0.1225],\n",
      "        [ 0.2779, -0.2665, -0.1479,  ..., -0.1974,  0.1687,  0.0524]])\n",
      "Gradients tensor([[  191.4532,  -552.5734,  1598.1254,   538.3757,  -296.1580, -1445.5527,\n",
      "          -469.3866,     3.9981,  -634.3381, -1543.1274,  -983.8257,  -553.9545,\n",
      "           435.2648,   936.3775,   -35.1349, -1426.6066,  -226.0676,     4.9197,\n",
      "         -1215.0159,   916.2312]])\n",
      "Epoch [1/10], Cumulative Loss: 638.8801, LR: 1.000e-01\n",
      "Final parameters: [[108.915     95.47977   84.034706  80.78988   74.53403   71.65892\n",
      "   62.32721   61.650063  63.087353  61.86004   61.47912 ]]\n",
      "Param Shape torch.Size([11, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# meta_optimizer = optim.SGD(lstm_optimizer.parameters(), lr=0.1)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiabetes_logs_train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m lstm_optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_LSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMLOptimizee2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiabetes_logs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m params \u001b[38;5;241m=\u001b[39m test_LSTM(lstm_optimizer, MLOptimizee2, kwargs, time_horizon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, writer\u001b[38;5;241m=\u001b[39mwriter)\n",
      "Cell \u001b[1;32mIn[40], line 37\u001b[0m, in \u001b[0;36mtrain_LSTM\u001b[1;34m(lstm_optimizer, meta_optimizer, optimizee_class, optimizee_kwargs, num_optimizees, num_epochs, time_horizon, discount, scheduler, noise, writer)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(time_horizon):\n\u001b[0;32m     36\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 37\u001b[0m     hidden_state \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_hidden_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_optimizees):\n\u001b[0;32m     39\u001b[0m         optimizee \u001b[38;5;241m=\u001b[39m optimizees[i]\n",
      "Cell \u001b[1;32mIn[6], line 70\u001b[0m, in \u001b[0;36mLSTMConcurrent.initialize_hidden_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize_hidden_state\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Initialize hidden & cell states for LSTM (one per parameter)\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh0 \u001b[38;5;241m=\u001b[39m to_cuda(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# self.h0 = torch.randn(2, self.hidden_size)\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc0 \u001b[38;5;241m=\u001b[39m to_cuda(torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Delete folders if present\n",
    "try:\n",
    "    shutil.rmtree(\"diabetes_logs_train\")\n",
    "    shutil.rmtree(\"diabetes_logs\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "kwargs = {\"X\": X, \"y\": y}\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "lstm_optimizer = LSTMConcurrent(num_optims=1, preproc=True)\n",
    "meta_optimizer = optim.Adam(lstm_optimizer.parameters(), lr=0.1)\n",
    "# meta_optimizer = optim.SGD(lstm_optimizer.parameters(), lr=0.1)\n",
    "writer = SummaryWriter(\"diabetes_logs_train\")\n",
    "lstm_optimizer = train_LSTM(lstm_optimizer, meta_optimizer, MLOptimizee2, kwargs, num_epochs=10, time_horizon=1000, discount=0.9, writer=writer)\n",
    "writer = SummaryWriter(\"diabetes_logs\")\n",
    "params = test_LSTM(lstm_optimizer, MLOptimizee2, kwargs, time_horizon=1000, writer=writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
