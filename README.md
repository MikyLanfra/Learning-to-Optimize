# Learning-to-Optimize

## Abstract
Learning to Optimize (L2O) is a novel Machine Learning approach which aims to substitute the laborious hand-engineering part of definition of optimization methods for Machine Learning Tasks, by formulating the generation of the updates as a task learnable by a Recurrent NN architecture, in this case, an LSTM.   
In this Project and Repository, I aim to provide an implementation of the framework as introduced by the paper [Learning to learn by gradient descent by gradient descent](https://arxiv.org/abs/1606.04474), while further extending the results to a Concurrent Learning Framework where several Optimizees are used in order to cooperate in order to produce better updates for our specific task.

## Table of Contents

- [Results](#results)
- [Bibliography](#bibliography)


## Results

## Bibliography

- Andrychowicz, M., Denil, M., Gomez, S., Hoffman, M. W., Pfau, D., Schaul, T., & de Freitas, N. (2016). [Learning to learn by gradient descent by gradient descent](https://arxiv.org/abs/1606.04474). Advances in Neural Information Processing Systems (NeurIPS), 29.